<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E7%BB%84%E5%90%88%E5%BA%94%E7%94%A8%EF%BC%9A%E7%BC%96%E5%86%99%20Docker%20Compose%20%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[编写 Docker Compose 项目通过阅读之前的小节，相信大家对 Docker 在开发中的应用已经有了一定的了解。作为一款实用的软件，我们必须回归到实践中来，这样才能更好地理解 Docker 的实用逻辑和背后的原理。在这一小节里，我们就举一个完整的例子，让大家跟随这个项目的脉络，熟悉如何通过 Docker 和 Docker Compose 来搭建应用开发环境。 设计项目的目录结构在这一小节里，我们以一个由 MySQL、Redis、PHP-FPM 和 Nginx 组成的小型 PHP 网站为例，介绍通过 Docker 搭建运行这套程序运行环境的方法。 既然我们说到这个小型网站是由 MySQL、Redis、PHP-FPM 和 Nginx 四款软件所组成的，那么自然在 Docker 里，我们要准备四个容器分别来运行它们。而为了更好地管理这四个容器所组成的环境，我们这里还会使用到 Docker Compose。 与搭建一个软件开发项目类似，我们提倡将 Docker Compose 项目的组成内容聚集到一个文件目录中，这样更利于我们进行管理和迁移。 这里我已经建立好了一个目录结构，虽然我们在实践的过程中不一定要按照这样的结构，但我相信这个结构一定对你有所启发。 简单说明一下这个结构中主要目录和文件的功能和作用。在这个结构里，我们可以将根目录下的几个目录分为四类： 第一类是 Docker 定义目录，也就是 compose 这个目录。在这个目录里，包含了 docker-compose.yml 这个用于定义 Docker Compose 项目的配置文件。此外，还包含了我们用于构建自定义镜像的内容。 第二类是程序文件目录，在这个项目里是 mysql、nginx、phpfpm、redis 这四个目录。这些目录分别对应着 Docker Compose 中定义的服务，在其中主要存放对应程序的配置，产生的数据或日志等内容。 第三类是代码目录，在这个项目中就是存放 Web 程序的 website 目录。我们将代码统一放在这个目录中，方便在容器中挂载。 第四类是工具命令目录，这里指 bin 这个目录。我们在这里存放一些自己编写的命令脚本，我们通过这些脚本可以更简洁地操作整个项目。 编写 Docker Compose 配置文件接下来我们就要编写 docker-compose.yml 文件来定义组成这个环境的所有 Docker 容器以及与它们相关的内容了。docker-compose.yml 规则和编写的方法在前两小节中已经谈到，这里我们就不再展开，直接来看看编写好的 docker-compose.yml 配置文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758version: &quot;3&quot;networks: frontend: backend:services: redis: image: redis:3.2 networks: - backend volumes: - ../redis/redis.conf:/etc/redis/redis.conf:ro - ../redis/data:/data command: [&quot;redis-server&quot;, &quot;/etc/redis/redis.conf&quot;] ports: - &quot;6379:6379&quot; mysql: image: mysql:5.7 networks: - backend volumes: - ../mysql/my.cnf:/etc/mysql/my.cnf:ro - ../mysql/data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: my-secret-pw ports: - &quot;3306:3306&quot; phpfpm: build: ./phpfpm networks: - frontend - backend volumes: - ../phpfpm/php.ini:/usr/local/etc/php/php.ini:ro - ../phpfpm/php-fpm.conf:/usr/local/etc/php-fpm.conf:ro - ../phpfpm/php-fpm.d:/usr/local/etc/php-fpm.d:ro - ../phpfpm/crontab:/etc/crontab:ro - ../website:/website depends_on: - redis - mysql nginx: image: nginx:1.12 networks: - frontend volumes: - ../nginx/nginx.conf:/etc/nginx/nginx.conf:ro - ../nginx/conf.d:/etc/nginx/conf.d:ro - ../website:/website depends_on: - phpfpm ports: - &quot;80:80&quot; 使用合适的镜像是提高工作效率的途径之一，这里讲解一下我们在这个项目中选择镜像的原由。 在这个项目里，我们直接采用了 MySQL、Redis 和 Nginx 三个官方镜像，而对于 PHP-FPM 的镜像，我们需要增加一些功能，所以我们通过 Dockerfile 构建的方式来生成。 对于 MySQL 来说，我们需要为它们设置密码，所以原则上我们是需要对它们进行改造并生成新的镜像来使用的。而由于 MySQL 镜像可以通过我们之前在镜像使用方法一节所提到的环境变量配置的方式，来直接指定 MySQL 的密码及其他一些关键性内容，所以我们就无须单独构建镜像，可以直接采用官方镜像并配合使用环境变量来达到目的。 对于 Redis 来说，出于安全考虑，我们一样需要设置密码。Redis 设置密码的方法是通过配置文件来完成的，所以我们需要修改 Redis 的配置文件并挂载到 Redis 容器中。这个过程也相对简单，不过需要注意的是，在官方提供的 Redis 镜像里，默认的启动命令是 redis-server，其并没有指定加载配置文件。所以在我们定义 Redis 容器时，要使用 command 配置修改容器的启动命令，使其读取我们挂载到容器的配置文件。 自定义镜像相比较于 MySQL、Redis 这样可以通过简单配置即可直接使用的镜像不同，PHP 的镜像中缺乏了一些我们程序中必要的元素，而这些部分我们推荐使用自定义镜像的方式将它们加入其中。 在这个例子里，因为需要让 PHP 连接到 MySQL 数据库中，所以我们要为镜像中的 PHP 程序安装和开启 pdo_mysql 这个扩展。 了解如何安装扩展，这就要考验我们之前在 Docker Hub 镜像使用一节中学到的知识了。我们通过阅读 PHP 镜像的介绍页面，可以找到 PHP 镜像中已经为我们准备好了扩展的安装和启用命令，这让我们可以很轻松地在镜像中加入扩展。 在准备好这些使用方法之后，我们就可以开始编写构建 PHP 镜像的 Dockerfile 文件了。这里我已经编写好了一份，供大家参考。 12345678910111213141516FROM php:7.2-fpmMAINTAINER You Ming &lt;youming@funcuter.org&gt;RUN apt-get update \ &amp;&amp; apt-get install -y --no-install-recommends cronRUN docker-php-ext-install pdo_mysqlCOPY docker-entrypoint.sh /usr/local/bin/RUN chmod +x /usr/local/bin/docker-entrypoint.shENTRYPOINT [&quot;docker-entrypoint.sh&quot;]CMD [&quot;php-fpm&quot;] 由于 Docker 官方所提供的镜像比较精简，所以在这个 Dockerfile 里，我们还执行了 cron 的安装命令，来确保我们可以使用定时任务。 大家注意到，这里除了我们进行功能安装外，还将一个脚本拷入了镜像中，并将其作为 ENTRYPOINT 启动入口。这个文件的作用主要是为了启动 cron 服务，以便我们在容器中可以正常使用它。 12345#!/bin/bashservice cron startexec &quot;$@&quot; 在 docker-entrypoint.sh 里，除了启动 cron 服务的命令外，我们在脚本的最后看到的是 exec &quot;$@&quot; 这行命令。$@ 是 shell 脚本获取参数的符号，这里获得的是所有传入脚本的参数，而 exec 是执行命令，直接执行这些参数。 如果直接看这条命令大家会有些疑惑，参数怎么拿来执行，这不是有问题么？ 请大家回顾一下，我们之前提到的，如果在镜像里同时定义了 ENTRYPOINT 和 CMD 两个指令，CMD 指令的内容会以参数的形式传递给 ENTRYPOINT 指令。所以，这里脚本最终执行的，是 CMD 中所定义的命令。 目录挂载在这个例子里，我们会把项目中的一些目录或文件挂载到容器里，这样的挂载主要有三种目的： 将程序的配置通过挂载的方式覆盖容器中对应的文件，这让我们可以直接在容器外修改程序的配置，并通过直接重启容器就能应用这些配置； 把目录挂载到容器中应用数据的输出目录，就可以让容器中的程序直接将数据输出到容器外，对于 MySQL、Redis 中的数据，程序的日志等内容，我们可以使用这种方法来持久保存它们； 把代码或者编译后的程序挂载到容器中，让它们在容器中可以直接运行，这就避免了我们在开发中反复构建镜像带来的麻烦，节省出大量宝贵的开发时间。 上述的几种方法，对于线上部署来说都是不适用的，但在我们的开发过程中，却可以为我们免去大量不必要的工作，因此建议在开发中使用这些挂载结构。 编写辅助脚本我们知道，虽然 Docker Compose 简化了许多操作流程，但我们还是需要使用 docker-compose 命令来管理项目。对于这个例子来说，我们要启动它就必须使用这样的 docker-compose 命令来管理项目。对于这个例子来说，我们要启动它就必须使用这样的： 1$ sudo docker-compose -p website up -d 而执行的目录必须是 docker-compose.yml 文件所在的目录，这样才能正确地读取 Docker Compose 项目的配置内容。 我编写了一个 compose 脚本，用来简化 docker-compose 的操作命令。 12345#!/bin/bashroot=$(cd `dirname $0`; dirname `pwd`)docker-compose -p website -f $&#123;root&#125;/compose/docker-compose.yml &quot;$@&quot; 在这个脚本里，我把一些共性的东西包含进去，这样我们就不必每次传入这些参数或选项了。同时，这个脚本还能自适应调用的目录，准确找到 docker-compose.yml 文件，更方便我们直接调用。 通过这个脚本来操作项目，我们的命令就可以简化为： 12345$ sudo ./bin/compose up -d$ sudo ./bin/compose logs nginx$ sudo ./bin/compose down 当然，我们还可以编写像代码部署、服务重启等脚本，来提高我们的开发效率。 留言互动在本节中，我们展示了编写一个用于开发的完整 Docker Compose 项目的方法。这里给大家留一道实践题： 尝试自己编写适用于自己应用的 Docker Compose 项目，并将它提供给测试同事，进行测试环境的部署。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对编写 Docker Compose 项目还有疑问，或者有编写的心得要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 本小节中的示例，已经更新到了： https://github.com/youmingdot/docker-book-for-developer-samples]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E7%BB%84%E5%90%88%E5%BA%94%E7%94%A8%EF%BC%9A%E5%BA%94%E7%94%A8%E4%BA%8E%E6%9C%8D%E5%8A%A1%E5%8C%96%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[应用于服务化开发上一节里我们谈到了小型的独立项目如何使用 Docker Compose 来搭建程序的运行环境，对于由多人或多部门参与的中大型服务化架构的项目，仅由一个 Docker Compose 项目来管理它们的运行环境显然是不切实际的。在这一小节里，我们就谈谈如何在服务化开发中合理利用 Docker 来搭建环境。 服务开发环境在开始之前，我们依然来设定一个场景。在这里，假定我们处于一个 Dubbo 治下的微服务系统，而工作是开发系统中某一项微服务。 微服务开发与上一节里我们提到的小型项目开发在环境搭建上有一定的区别，我们要合理地调整 Docker 的使用方法和策略，就必须先了解这些区别。 在微服务开发中，我们所开发的功能都不是完整的系统，很多功能需要与其他服务之间配合才能正常运转，而我们开发所使用的机器时常无法满足我们在一台机器上将这些相关服务同时运行起来。 我们仅仅是开发某一部分服务的内容，既对其他服务的运转机制不太了解，又完全没有必要在自己的机器上运行其他的服务。所以我们最佳的实践自然就是让参与系统中服务开发的同事，各自维护自己开发服务的环境，而直接提供给我们对应的连接地址使用服务即可。 更确切地说，我们在开发中，只需要在本地搭建起自己所开发服务的运行环境，再与其他开发者搭建的环境互联即可。 搭建本地环境在我们的开发机器上，我们只需要运行我们正在开发的服务，这个过程依然可以使用 Docker Compose 来完成。这里我给出了一个简单的例子，表示一个简单的小服务运行环境。 1234567891011121314151617181920212223242526272829version: &quot;3&quot;networks: backend: mesh:services: mysql: image: mysql:5.7 networks: - backend volumes: - ../mysql/my.cnf:/etc/mysql/my.cnf:ro - ../mysql/data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: my-secret-pw ports: - &quot;3306:3306&quot; app: build: ./spring networks: - mesh - backend volumes: - ../app:/app depends_on: - mysql 关于这里 Spring 镜像的使用和改造方法，我就不展开了，大家可以通过 Docker Hub 以及 Spring 官方所提供的镜像，练习如何改造它，使它适配自己的服务。 跨主机网络搭建好本地的环境，我们就需要考虑如何与朋友们所搭建的环境进行互联了。 这时候大家也许会想到，可以将服务涉及的相关端口通过映射的方式暴露到我们机器的端口上，接着我们只需要通过各服务机器的 IP 与对应的端口就可以连接了。 然而这种方法还不算特别方便，一来除了处理映射外，我们还需要配置防火墙等才能使其他的机器正确访问到容器，二来是这种方式我们依然要记录各个服务的网络地址等配置，而开发中切换它们是个烦琐的过程。 在介绍 Docker Compose 的小节里，我们知道了可以通过设置网络别名 ( alias ) 的方式来更轻松地连接其他容器，如果我们在服务化开发里也能这么做就能减少很多烦琐操作了。 要实现设置网络别名的目的，自然要先确保所有涉及的容器位于同一个网络中，这时候就需要引出我们之前在网络小节里说到的 Overlay 网络了。 Overlay Network 能够跨越物理主机的限制，让多个处于不同 Docker daemon 实例中的容器连接到同一个网络，并且让这些容器感觉这个网络与其他类型的网络没有区别。 Docker Swarm要搭建 Overlay Network 网络，我们就要用到 Docker Swarm 这个工具了。Docker Swarm 是 Docker 内置的集群工具，它能够帮助我们更轻松地将服务部署到 Docker daemon 的集群之中。 在真实的服务部署里，我们通常是使用 Docker Compose 来定义集群，而通过 Docker Swarm 来部署集群。 如果熟悉 Docker 周边知识的朋友，相信这时候已经想到了另外一个工具，即 Kubernetes ( K8s )。没错，Kubernetes 与这两者的组合相比，功能要丰富强大很多，也正因此，与它相关的内容完全足以另辟一本小册来说。而在开发里，我们几乎使用不到 Kubernetes，所以我们这里就不做介绍了。如果大家有想要了解的 Kubernetes 知识点，可以通过小册的微信群向我提出，我会挑选大家关注的内容补充到小册的后面。 Docker Swarm 最初是独立的项目，不过目前已经集成到了 Docker 之中，我们通过 docker CLI 的命令就能够直接操控它。 对于 Docker Swarm 来说，每一个 Docker daemon 的实例都可以成为集群中的一个节点，而在 Docker daemon 加入到集群成为其中的一员后，集群的管理节点就能对它进行控制。我们要搭建的 Overlay 网络正是基于这样的集群实现的。 既然要将 Docker 加入到集群，我们就必须先有一个集群，我们在任意一个 Docker 实例上都可以通过 docker swarm init 来初始化集群。 1234567$ sudo docker swarm initSwarm initialized: current node (t4ydh2o5mwp5io2netepcauyl) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-4dvxvx4n7magy5zh0g0de0xoues9azekw308jlv6hlvqwpriwy-cb43z26n5jbadk024tx0cqz5r 192.168.1.5:2377 在集群初始化后，这个 Docker 实例就自动成为了集群的管理节点，而其他 Docker 实例可以通过运行这里所打印的 docker swarm join 命令来加入集群。 加入到集群的节点默认为普通节点，如果要以管理节点的身份加入到集群中，我们可以通过 docker swarm join-token 命令来获得管理节点的加入命令。 1234$ sudo docker swarm join-token managerTo add a manager to this swarm, run the following command: docker swarm join --token SWMTKN-1-60am9y6axwot0angn1e5inxrpzrj5d6aa91gx72f8et94wztm1-7lz0dth35wywekjd1qn30jtes 192.168.1.5:2377 我们通过这些命令来建立用于我们服务开发的 Docker 集群，并将相关开发同事的 Docker 加入到这个集群里，就完成了搭建跨主机网络的第一步。 建立跨主机网络接下来，我们就通过 docker network create 命令来建立 Overlay 网络。 1$ sudo docker network create --driver overlay --attachable mesh 在创建 Overlay 网络时，我们要加入 --attachable 选项以便不同机器上的 Docker 容器能够正常使用到它。 在创建了这个网络之后，我们可以在任何一个加入到集群的 Docker 实例上使用 docker network ls 查看一下其下的网络列表。我们会发现这个网络定义已经同步到了所有集群中的节点上。 12345$ sudo docker network lsNETWORK ID NAME DRIVER SCOPE## ......y89bt74ld9l8 mesh overlay swarm## ...... 接下来我们要修改 Docker Compose 的定义，让它使用这个我们已经定义好的网络，而不是再重新创建网络。 我们只需要在 Docker Compose 配置文件的网络定义部分，将网络的 external 属性设置为 true，就可以让 Docker Compose 将其建立的容器都连接到这个不属于 Docker Compose 的项目上了。 123networks: mesh: external: true 通过这个实现，我们在开发中就使整个服务都处于一个可以使用别名映射网络中，避免了要对不同功能联调时切换服务 IP 的烦琐流程。在这种结构下，我们只需要让我们开发的 Docker 退出和加入不同的集群，就能马上做到切换不同联调项目。 留言互动在本节中，我们展示了使用 Docker 进行多人协同开发的方法。这里给大家留一道实践题： 尝试使用本小节中的知识，与同事搭建一套协同开发环境。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker 在服务化开发中的应用还有疑问，或者有自己的实践心得要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E7%BB%84%E5%90%88%E5%BA%94%E7%94%A8%EF%BC%9A%E4%BD%BF%E7%94%A8%20Docker%20Compose%20%E7%AE%A1%E7%90%86%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[使用 Docker Compose 管理容器通过之前的介绍，我们已经基本掌握了构建、运行容器的方法，但这还远远不够，由于 Docker 采用轻量级容器的设计，每个容器一般只运行一个软件，而目前绝大多数应用系统都绝不是一个软件所能组成的。虽然我们之前提到了容器间互相连接、交换数据的各种方法，通过这些方法足以搭建起完整的用于应用系统运行的容器群，但是这显然还不够，这个容器群的搭建需要执行太多命令，更重要的是需要考虑太多应用和容器间的依赖关系处理，是一波令人头大的操作。在这一节中，我们就来介绍如何解决这些问题。 解决容器管理问题拿任何一个相对完整的应用系统来说，都不可能是由一个程序独立支撑的，而对于使用 Docker 来部署的分布式计算服务更是这样。随着时代的发展和技术演进，我们越来越推崇将大型服务拆分成较小的微服务，分别部署到独立的机器或容器中。也就是说，我们的应用系统往往由数十个甚至上百个应用程序或微服务组成。即使是一个小的微服务模块，通常都需要多个应用协作完成工作。 我们编写一个小型的微服务模块，虽然我们编写代码主要针对的是其中的应用部分，但如果我们要完整的进行开发、测试，与应用相关的周边软件必然是必不可少的。 虽然 Docker Engine 帮助我们完成了对应用运行环境的封装，我们可以不需要记录复杂的应用环境搭建过程，通过简单的配置便可以将应用运行起来了，但这只是针对单个容器或单个应用程序来说的。如果延伸到由多个应用组成的应用系统，那情况就稍显复杂了。 就拿最简单的例子来说吧，如果我们要为我们的应用容器准备一个 MySQL 容器和一个 Redis 容器，那么在每次启动时，我们先要将 MySQL 容器和 Redis 容器启动起来，再将应用容器运行起来。这其中还不要忘了在创建应用容器时将容器网络连接到 MySQL 容器和 Redis 容器上，以便应用连接上它们并进行数据交换。 这还不够，如果我们还对容器进行了各种配置，我们最好还得将容器创建和配置的命令保存下来，以便下次可以直接使用。 如果我们要想让这套体系像 docker run 和 docker rm 那样自如的进行无痕切换，那就更加麻烦了，我们可能需要编写一些脚本才能不至于被绕到命令的毛线球里。 说了这么多，其实核心还是缺少一个对容器组合进行管理的东西。 Docker Compose针对这种情况，我们就不得不引出在我们开发中最常使用的多容器定义和运行软件，也就是 Docker Compose 了。 如果说 Dockerfile 是将容器内运行环境的搭建固化下来，那么 Docker Compose 我们就可以理解为将多个容器运行的方式和配置固化下来。 在 Docker Compose 里，我们通过一个配置文件，将所有与应用系统相关的软件及它们对应的容器进行配置，之后使用 Docker Compose 提供的命令进行启动，就能让 Docker Compose 将刚才我们所提到的那些复杂问题解决掉。 安装 Docker Compose虽然 Docker Compose 目前也是由 Docker 官方主要维护，但其却不属于 Docker Engine 的一部分，而是一个独立的软件。所以如果我们要在 Linux 中使用它，还必须要单独下载使用。 Docker Compose 是一个由 Python 编写的软件，在拥有 Python 运行环境的机器上，我们可以直接运行它，不需要其它的操作。 我们可以通过下面的命令下载 Docker Compose 到应用执行目录，并附上运行权限，这样 Docker Compose 就可以在机器中使用了。 12345678$ sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.22.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose$ sudo chmod +x /usr/local/bin/docker-compose$$ sudo docker-compose versiondocker-compose version 1.21.2, build a133471docker-py version: 3.3.0CPython version: 3.6.5OpenSSL version: OpenSSL 1.0.1t 3 May 2016 我们也能够通过 Python 的包管理工具 pip 来安装 Docker Compose。 1$ sudo pip install docker-compose 在 Windows 和 macOS 中的 Docker Compose在我们更常用于开发的 Windows 和 macOS 中，使用 Docker Compose 会来得更加方便。不论你是使用 Docker for Win 还是 Docker for Mac，亦或是 Docker Toolbox 来搭建 Docker 运行环境，你都可以直接使用 docker-compose 这个命令。这三款软件都已经将 Docker Compose 内置在其中，供我们使用。 Docker Compose 的基本使用逻辑如果将使用 Docker Compose 的步骤简化来说，可以分成三步。 如果需要的话，编写容器所需镜像的 Dockerfile；( 也可以使用现有的镜像 ) 编写用于配置容器的 docker-compose.yml； 使用 docker-compose 命令启动应用。 准备镜像这一过程我们之前已经掌握了，这里我们就简单来看看后面两个步骤。 编写 Docker Compose 配置配置文件是 Docker Compose 的核心部分，我们正是通过它去定义组成应用服务容器群的各项配置，而编写配置文件，则是使用 Docker Compose 过程中最核心的一个步骤。 Docker Compose 的配置文件是一个基于 YAML 格式的文件。关于 YAML 的语法大家可以在网上找到，这里不再细说，总的来说，YAML 是一种清晰、简单的标记语言，你甚至都可以在看过几个例子后摸索出它的语法。 与 Dockerfile 采用 Dockerfile 这个名字作为镜像构建定义的默认文件名一样，Docker Compose 的配置文件也有一个缺省的文件名，也就是 docker-compose.yml，如非必要，我建议大家直接使用这个文件名来做 Docker Compose 项目的定义。 这里我们来看一个简单的 Docker Compose 配置文件内容。 12345678910111213141516171819202122232425version: &apos;3&apos;services: webapp: build: ./image/webapp ports: - &quot;5000:5000&quot; volumes: - ./code:/code - logvolume:/var/log links: - mysql - redis redis: image: redis:3.2 mysql: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=my-secret-pwvolumes: logvolume: &#123;&#125; Docker Compose 配置文件里可以包含许多内容，从每个容器的各个细节控制，到网络、数据卷等的定义。 这里我们看几个主要的细节。首先是 version 这个配置，这代表我们定义的 docker-compose.yml 文件内容所采用的版本，目前 Docker Compose 的配置文件已经迭代至了第三版，其所支持的功能也越来越丰富，所以我们建议使用最新的版本来定义。 接下来我们来看 services 这块，这是整个 docker-compose.yml 的核心部分，其定义了容器的各项细节。 在 Docker Compose 里不直接体现容器这个概念，这是把 service 作为配置的最小单元。虽然我们看上去每个 service 里的配置内容就像是在配置容器，但其实 service 代表的是一个应用集群的配置。每个 service 定义的内容，可以通过特定的配置进行水平扩充，将同样的容器复制数份形成一个容器集群。而 Docker Compose 能够对这个集群做到黑盒效果，让其他的应用和容器无法感知它们的具体结构。 对于 docker-compose.yml 配置的具体细节，我们在下一节中还会专门讲解。 启动和停止对于开发来说，最常使用的 Docker Compose 命令就是 docker-compose up 和 docker-compose down 了。 docker-compose up 命令类似于 Docker Engine 中的 docker run，它会根据 docker-compose.yml 中配置的内容，创建所有的容器、网络、数据卷等等内容，并将它们启动。与 docker run 一样，默认情况下 docker-compose up 会在“前台”运行，我们可以用 -d 选项使其“后台”运行。事实上，我们大多数情况都会加上 -d 选项。 1$ sudo docker-compose up -d 需要注意的是，docker-compose 命令默认会识别当前控制台所在目录内的 docker-compose.yml 文件，而会以这个目录的名字作为组装的应用项目的名称。如果我们需要改变它们，可以通过选项 -f 来修改识别的 Docker Compose 配置文件，通过 -p 选项来定义项目名。 1$ sudo docker-compose -f ./compose/docker-compose.yml -p myapp up -d 与 docker-compose up 相反，docker-compose down 命令用于停止所有的容器，并将它们删除，同时消除网络等配置内容，也就是几乎将这个 Docker Compose 项目的所有影响从 Docker 中清除。 1$ sudo docker-compose down 如果条件允许，我更建议大家像容器使用一样对待 Docker Compose 项目，做到随用随启，随停随删。也就是使用的时候通过 docker-compose up 进行，而短时间内不再需要时，通过 docker-compose down 清理它。 借助 Docker 容器的秒级启动和停止特性，我们在使用 docker-compose up 和 docker-compose down 时可以非常快的完成操作。这就意味着，我们可以在不到半分钟的时间内停止一套环境，切换到另外一套环境，这对于经常进行多个项目开发的朋友来说，绝对是福音。 通过 Docker 让我们能够在开发过程中搭建一套不受干扰的独立环境，让开发过程能够基于稳定的环境下进行。而 Docker Compose 则让我们更近一步，同时让我们处理好多套开发环境，并进行快速切换。 容器命令除了启动和停止命令外，Docker Compose 还为我们提供了很多直接操作服务的命令。之前我们说了，服务可以看成是一组相同容器的集合，所以操作服务就有点像操作容器一样。 这些命令看上去都和 Docker Engine 中对单个容器进行操作的命令类似，我们来看几个常见的。 在 Docker Engine 中，如果我们想要查看容器中主进程的输出内容，可以使用 docker logs 命令。而由于在 Docker Compose 下运行的服务，其命名都是由 Docker Compose 自动完成的，如果我们直接使用 docker logs 就需要先找到容器的名字，这显然有些麻烦了。我们可以直接使用 docker-compose logs 命令来完成这项工作。 1$ sudo docker-compose logs nginx 在 docker-compose logs 衔接的是 Docker Compose 中所定义的服务的名称。 同理，在 Docker Compose 还有几个类似的命令可以单独控制某个或某些服务。 通过 docker-compose create，docker-compose start 和 docker-compose stop 我们可以实现与 docker create，docker start 和 docker stop 相似的效果，只不过操作的对象由 Docker Engine 中的容器变为了 Docker Compose 中的服务。 123$ sudo docker-compose create webapp$ sudo docker-compose start webapp$ sudo docker-compose stop webapp 留言互动在本节中，我们展示了 Docker Compose 这个用于管理容器的工具。这里给大家留一道思考题： 在我们的开发中，我们应该如何的合理利用 Docker Compose 进行容器管理呢？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker Compose 和容器管理还有什么疑惑，或者有自己的想法要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E7%BB%84%E5%90%88%E5%BA%94%E7%94%A8%EF%BC%9A%E5%B8%B8%E7%94%A8%E7%9A%84%20Docker%20Compose%20%E9%85%8D%E7%BD%AE%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[常用的 Docker Compose 配置项与 Dockerfile 一样，编写 Docker Compose 的配置文件是掌握和使用好 Docker Compose 的前提。编写 Docker Compose 配置文件，其本质就是根据我们所设计的应用架构，对不同应用容器进行配置并加以组合。在这一节中，我们就来谈谈如何编写 Docker Compose 的配置文件，了解其中常见配置项的使用方法。 定义服务为了理解在开发中常用的 Docker Compose 配置，我们通过一个在开发中使用的 Docker Compose 文件来进行下面的讲解。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657version: &quot;3&quot;services: redis: image: redis:3.2 networks: - backend volumes: - ./redis/redis.conf:/etc/redis.conf:ro ports: - &quot;6379:6379&quot; command: [&quot;redis-server&quot;, &quot;/etc/redis.conf&quot;] database: image: mysql:5.7 networks: - backend volumes: - ./mysql/my.cnf:/etc/mysql/my.cnf:ro - mysql-data:/var/lib/mysql environment: - MYSQL_ROOT_PASSWORD=my-secret-pw ports: - &quot;3306:3306&quot; webapp: build: ./webapp networks: - frontend - backend volumes: - ./webapp:/webapp depends_on: - redis - database nginx: image: nginx:1.12 networks: - frontend volumes: - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro - ./nginx/conf.d:/etc/nginx/conf.d:ro - ./webapp/html:/webapp/html depends_on: - webapp ports: - &quot;80:80&quot; - &quot;443:443&quot;networks: frontend: backend:volumes: mysql-data: 在这个 Docker Compose 的示例中，我们看到占有大量篇幅的就是 services 部分，也就是服务定义的部分了。在上一节里，我们已经说到了，Docker Compose 中的服务，是对一组相同容器集群统一配置的定义，所以可见，在 Docker Compose 里，主要的内容也是对容器配置的定义。 这里我们依然要声明一下，这本小册主要以开发中使用 Docker 的方法为主，所以在关于 Docker Compose 的内容里，依然以开发中的使用为主。由于我们开发中，鉴于本地机器性能和易管理性等的考虑，不会为服务进行集群配置，通常就是一个服务对应一个容器，所以这里均以这种方式来进行讲解。 在 Docker Compose 的配置文件里，对服务的定义与我们之前谈到的创建和启动容器中的选项非常相似，或者说 Docker Compose 就是从配置文件中读取出这些内容，代我们创建和管理这些容器的。 在使用时，我们首先要为每个服务定义一个名称，用以区别不同的服务。在这个例子里，redis、database、webapp、nginx 就是服务的名称。 指定镜像容器最基础的就是镜像了，所以每个服务必须指定镜像。在 Docker Compose 里，我们可以通过两种方式为服务指定所采用的镜像。一种是通过 image 这个配置，这个相对简单，给出能在镜像仓库中找到镜像的名称即可。 另外一种指定镜像的方式就是直接采用 Dockerfile 来构建镜像，通过 build 这个配置我们能够定义构建的环境目录，这与 docker build 中的环境目录是同一个含义。如果我们通过这种方式指定镜像，那么 Docker Compose 先会帮助我们执行镜像的构建，之后再通过这个镜像启动容器。 当然，在 docker build 里我们还能通过选项定义许多内容，这些在 Docker Compose 里我们依然可以。 12345678## ...... webapp: build: context: ./webapp dockerfile: webapp-dockerfile args: - JAVA_VERSION=1.6## ...... 在配置文件里，我们还能用 Map 的形式来定义 build，在这种格式下，我们能够指定更多的镜像构建参数，例如 Dockerfile 的文件名，构建参数等等。 当然，对于一些可以不通过重新构建镜像的方式便能修改的内容，我们还是不建议重新构建镜像，而是使用原有的镜像做简单的修改。 例如上面的配置里，我们希望修改 Redis 的启动命令，加入配置文件以便对 Redis 服务进行配置，那么我们可以直接通过 command 配置来修改。而在 MySQL 的定义，我们通过 environment 配置为 MySQL 设置了初始密码。 这些对镜像的使用方法我们在之前都已经谈到过了，只不过我们之前用的是 Docker Engine 的命令以及其选项来控制的，而在 Docker Compose 里，我们直接通过配置文件来定义它们。 由于 Docker Compose 的配置已经固化下来，所以我们不需要担心忘记之前执行了哪些命令来启动容器，当每次需要开启或关闭环境时，只需要 docker-compose up -d 和 docker-compose down 命令，就能轻松完成操作。 依赖声明虽然我们在 Docker Compose 的配置文件里定义服务，在书写上有由上至下的先后关系，但实际在容器启动中，由于各种因素的存在，其顺序还是无法保障的。 所以，如果我们的服务间有非常强的依赖关系，我们就必须告知 Docker Compose 容器的先后启动顺序。只有当被依赖的容器完全启动后，Docker Compose 才会创建和启动这个容器。 定义依赖的方式很简单，在上面的例子里我们已经看到了，也就是 depends_on 这个配置项，我们只需要通过它列出这个服务所有依赖的其他服务即可。在 Docker Compose 为我们启动项目的时候，会检查所有依赖，形成正确的启动顺序并按这个顺序来依次启动容器。 文件挂载在 Docker Compose 里定义文件挂载的方式与 Docker Engine 里也并没有太多的区别，使用 volumes 配置可以像 docker CLI 里的 -v 选项一样来指定外部挂载和数据卷挂载。 在上面的例子里，我们看到了定义几种常用挂载的方式。我们能够直接挂载宿主机文件系统中的目录，也可以通过数据卷的形式挂载内容。 在使用外部文件挂载的时候，我们可以直接指定相对目录进行挂载，这里的相对目录是指相对于 docker-compose.yml 文件的目录。 由于有相对目录这样的机制，我们可以将 docker-compose.yml 和所有相关的挂载文件放置到同一个文件夹下，形成一个完整的项目文件夹。这样既可以很好的整理项目文件，也利于完整的进行项目迁移。 虽然 Docker 提倡将代码或编译好的程序通过构建镜像的方式打包到镜像里，随整个 CI 流部署到服务器中，但对于开发者来说，每次修改程序进行简单测试都要重新构建镜像简直是浪费生命的操作。所以在开发时，我们推荐直接将代码挂载到容器里，而不是通过镜像构建的方式打包成镜像。 同时，在开发过程中，对于程序的配置等内容，我们也建议直接使用文件挂载的形式挂载到容器里，避免经常修改所带来的麻烦。 使用数据卷如果我们要在项目中使用数据卷来存放特殊的数据，我们也可以让 Docker Compose 自动完成对数据卷的创建，而不需要我们单独进行操作。 在上面的例子里，独立于 services 的 volumes 配置就是用来声明数据卷的。定义数据卷最简单的方式仅需要提供数据卷的名称，对于我们在 Docker Engine 中创建数据卷时能够使用的其他定义，也能够放入 Docker Compose 的数据卷定义中。 如果我们想把属于 Docker Compose 项目以外的数据卷引入进来直接使用，我们可以将数据卷定义为外部引入，通过 external 这个配置就能完成这个定义。 12345## ......volumes: mysql-data: external: true## ...... 在加入 external 定义后，Docker Compose 在创建项目时不会直接创建数据卷，而是优先从 Docker Engine 中已有的数据卷里寻找并直接采用。 配置网络网络也是容器间互相访问的桥梁，所以网络的配置对于多个容器组成的应用系统来说也是非常重要的。在 Docker Compose 里，我们可以为整个应用系统设置一个或多个网络。 要使用网络，我们必须先声明网络。声明网络的配置同样独立于 services 存在，是位于根配置下的 networks 配置。在上面的例子里，我们已经看到了声明 frontend 和 backend 这两个网络最简单的方式。 除了简单的声明网络名称，让 Docker Compose 自动按默认形式完成网络配置外，我们还可以显式的指定网络的参数。 12345678networks: frontend: driver: bridge ipam: driver: default config: - subnet: 10.10.1.0/24## ...... 在这里，我们为网络定义了网络驱动的类型，并指定了子网的网段。 使用网络别名直接使用容器名或服务名来作为连接其他服务的网络地址，因为缺乏灵活性，常常还不能满足我们的需要。这时候我们可以为服务单独设置网络别名，在其他容器里，我们将这个别名作为网络地址进行访问。 网络别名的定义方式很简单，这里需要将之前简单的网络 List 定义结构修改成 Map 结构，以便在网络中加入更多的定义。 12345678910111213141516## ...... database: networks: backend: aliases: - backend.database## ...... webapp: networks: backend: aliases: - backend.webapp frontend: aliases: - frontend.webapp## ...... 在我们进行这样的配置后，我们便可以使用这里我们所设置的网络别名对其他容器进行访问了。 端口映射在 Docker Compose 的每个服务配置里，我们还看到了 ports 这个配置项，它是用来定义端口映射的。 我们可以利用它进行宿主机与容器端口的映射，这个配置与 docker CLI 中 -p 选项的使用方法是近似的。 需要注意的是，由于 YAML 格式对 xx:yy 这种格式的解析有特殊性，在设置小于 60 的值时，会被当成时间而不是字符串来处理，所以我们最好使用引号将端口映射的定义包裹起来，避免歧义。 留言互动在本节中，我们展示了 Docker Compose 中常见定义和配置的方法。这里给大家留一道实践题： 尝试利用 Docker Compose 以及之前所学习的 Docker 知识，为自己正在开发的应用搭建一个 Docker 运行环境。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker Compose 的配置方法还有疑问，或者有自己的使用技巧要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E7%99%BE%E5%B0%BA%E7%AB%BF%E5%A4%B4%EF%BC%8C%E6%9B%B4%E8%BF%9B%E4%B8%80%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[百尺竿头，更进一步在这本小册里，我们从 Docker 最基础的知识谈起，介绍了 Docker 的核心组成部分以及操作这些功能的命令与方法，其后又讲解了开发中最常用的 Docker Compose，并完整的展示了通过它们搭建开发环境的过程。 然而 Docker 的生态太过丰富，不仅是 Docker 相关的知识浩如烟海，就连开发中所能使用到的技巧也不可胜数。虽然我尽心总结，但这本小册里肯定还存在许多欠缺和匮乏之处。 好在小册的结构经过我精心编排，形成了一条有逻辑的脉络，这能够帮助大家由浅入深的逐步掌握 Docker 及其与它相关的知识。 大家可以在阅读每一小节后，对其中仍有疑惑之处，可以直接加入到这本小册的微信群中，直接向大家提问并参与我们的交流。同时，如果你在开发中还有对工作效率或其他方面有提高的 Docker 使用经验技巧，也欢迎加入到微信群中，与大家分享。 另外，大家可以通过留言或在微信群中提问的方式，说出你还想了解的知识点或使用技巧，在这本小册后面，我会选择大家比较关注的一些知识或问题专门开辟篇幅进行讲解。 知识延伸在小册里我们谈到了很多关于 docker 命令和 docker-compose 命令的使用方法，但这两个命令中还包含了大量的使用方法，大家可以通过阅读这两个命令的手册来获得更详细的解读。 docker : https://docs.docker.com/engine/reference/run/ docker-compose : https://docs.docker.com/compose/reference/overview/ 如果还希望了解更多关于 Docker 的知识，我想下面的这些社区会对你很有帮助。 掘金 Segmentfault 开源中国 我的专栏最后，友情推荐下我自己的微信公众号「虞山脚下」，更多有关技术的知识我会逐渐更新到公众号中。使用微信扫一扫下面的二维码即可到访。 也欢迎到访：虞山脚下 : https://youmingdot.com]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E6%93%8D%E4%BD%9C%E9%95%9C%E5%83%8F%EF%BC%9A%E9%80%9A%E8%BF%87%20Dockerfile%20%E5%88%9B%E5%BB%BA%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[通过 Dockerfile 创建镜像由于 Docker 镜像的结构优势，使它的占用空间远小于普通的虚拟机镜像，而这就大幅减少了 Docker 镜像在网络或者其他介质中转移所花费的时间，进而提高了我们进行迁移部署的效率。不过，你要是以为这就是 Docker 能够快速部署的终极大招那就大错特错了。在这一小节里，我们将谈到 Docker 特有的镜像构建定义文件，也就是 Dockerfile。通过了解它，你能真正体验一种进行秒级镜像迁移的乐趣。 关于 DockerfileDockerfile 是 Docker 中用于定义镜像自动化构建流程的配置文件，在 Dockerfile 中，包含了构建镜像过程中需要执行的命令和其他操作。通过 Dockerfile 我们可以更加清晰、明确的给定 Docker 镜像的制作过程，而由于其仅是简单、小体积的文件，在网络等其他介质中传递的速度极快，能够更快的帮助我们实现容器迁移和集群部署。 通常来说，我们对 Dockerfile 的定义就是针对一个名为 Dockerfile 的文件，其虽然没有扩展名，但本质就是一个文本文件，所以我们可以通过常见的文本编辑器或者 IDE 创建和编辑它。 Dockerfile 的内容很简单，主要以两种形式呈现，一种是注释行，另一种是指令行。 12# CommentINSTRUCTION arguments 在 Dockerfile 中，拥有一套独立的指令语法，其用于给出镜像构建过程中所要执行的过程。Dockerfile 里的指令行，就是由指令与其相应的参数所组成。 环境搭建与镜像构建如果具体来说 Dockerfile 的作用和其实际运转的机制，我们可以用一个我们开发中的常见流程来比较。 在一个完整的开发、测试、部署过程中，程序运行环境的定义通常是由开发人员来进行的，因为他们更加熟悉程序运转的各个细节，更适合搭建适合程序的运行环境。 在这样的前提下，为了方便测试和运维搭建相同的程序运行环境，常用的做法是由开发人员编写一套环境搭建手册，帮助测试人员和运维人员了解环境搭建的流程。 而 Dockerfile 就很像这样一个环境搭建手册，因为其中包含的就是一个构建容器的过程。 而比环境搭建手册更好的是，Dockerfile 在容器体系下能够完成自动构建，既不需要测试和运维人员深入理解环境中各个软件的具体细节，也不需要人工执行每一个搭建流程。 编写 Dockerfile相对于之前我们介绍的提交容器修改，再进行镜像迁移的方式相比，使用 Dockerfile 进行这项工作有很多优势，我总结了几项尤为突出的。 Dockerfile 的体积远小于镜像包，更容易进行快速迁移和部署。 环境构建流程记录了 Dockerfile 中，能够直观的看到镜像构建的顺序和逻辑。 使用 Dockerfile 来构建镜像能够更轻松的实现自动部署等自动化流程。 在修改环境搭建细节时，修改 Dockerfile 文件要比从新提交镜像来的轻松、简单。 事实上，在实际使用中，我们也很少会选择容器提交这种方法来构建镜像，而是几乎都采用 Dockerfile 来制作镜像。所以说，学会 Dockerfile 的编写是所有熟练使用 Docker 的开发者必须掌握的能力。 纸上得来终觉浅，光说很多关于 Dockerfile 的概念其实对我们开发使用来说意义不大，这里我们直接学习如何编写一个用于构建镜像的 Dockerfile。 首先我们来看一个完整的 Dockerfile 的例子，这是用于构建 Docker 官方所提供的 Redis 镜像的 Dockerfile 文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283FROM debian:stretch-slim# add our user and group first to make sure their IDs get assigned consistently, regardless of whatever dependencies get addedRUN groupadd -r redis &amp;&amp; useradd -r -g redis redis# grab gosu for easy step-down from root# https://github.com/tianon/gosu/releasesENV GOSU_VERSION 1.10RUN set -ex; \ \ fetchDeps=&quot; \ ca-certificates \ dirmngr \ gnupg \ wget \ &quot;; \ apt-get update; \ apt-get install -y --no-install-recommends $fetchDeps; \ rm -rf /var/lib/apt/lists/*; \ \ dpkgArch=&quot;$(dpkg --print-architecture | awk -F- &apos;&#123; print $NF &#125;&apos;)&quot;; \ wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch&quot;; \ wget -O /usr/local/bin/gosu.asc &quot;https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch.asc&quot;; \ export GNUPGHOME=&quot;$(mktemp -d)&quot;; \ gpg --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4; \ gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu; \ gpgconf --kill all; \ rm -r &quot;$GNUPGHOME&quot; /usr/local/bin/gosu.asc; \ chmod +x /usr/local/bin/gosu; \ gosu nobody true; \ \ apt-get purge -y --auto-remove $fetchDepsENV REDIS_VERSION 3.2.12ENV REDIS_DOWNLOAD_URL http://download.redis.io/releases/redis-3.2.12.tar.gzENV REDIS_DOWNLOAD_SHA 98c4254ae1be4e452aa7884245471501c9aa657993e0318d88f048093e7f88fd# for redis-sentinel see: http://redis.io/topics/sentinelRUN set -ex; \ \ buildDeps=&apos; \ wget \ \ gcc \ libc6-dev \ make \ &apos;; \ apt-get update; \ apt-get install -y $buildDeps --no-install-recommends; \ rm -rf /var/lib/apt/lists/*; \ \ wget -O redis.tar.gz &quot;$REDIS_DOWNLOAD_URL&quot;; \ echo &quot;$REDIS_DOWNLOAD_SHA *redis.tar.gz&quot; | sha256sum -c -; \ mkdir -p /usr/src/redis; \ tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1; \ rm redis.tar.gz; \ \# disable Redis protected mode [1] as it is unnecessary in context of Docker# (ports are not automatically exposed when running inside Docker, but rather explicitly by specifying -p / -P)# [1]: https://github.com/antirez/redis/commit/edd4d555df57dc84265fdfb4ef59a4678832f6da grep -q &apos;^#define CONFIG_DEFAULT_PROTECTED_MODE 1$&apos; /usr/src/redis/src/server.h; \ sed -ri &apos;s!^(#define CONFIG_DEFAULT_PROTECTED_MODE) 1$!\1 0!&apos; /usr/src/redis/src/server.h; \ grep -q &apos;^#define CONFIG_DEFAULT_PROTECTED_MODE 0$&apos; /usr/src/redis/src/server.h; \# for future reference, we modify this directly in the source instead of just supplying a default configuration flag because apparently &quot;if you specify any argument to redis-server, [it assumes] you are going to specify everything&quot;# see also https://github.com/docker-library/redis/issues/4#issuecomment-50780840# (more exactly, this makes sure the default behavior of &quot;save on SIGTERM&quot; stays functional by default) \ make -C /usr/src/redis -j &quot;$(nproc)&quot;; \ make -C /usr/src/redis install; \ \ rm -r /usr/src/redis; \ \ apt-get purge -y --auto-remove $buildDepsRUN mkdir /data &amp;&amp; chown redis:redis /dataVOLUME /dataWORKDIR /dataCOPY docker-entrypoint.sh /usr/local/bin/ENTRYPOINT [&quot;docker-entrypoint.sh&quot;]EXPOSE 6379CMD [&quot;redis-server&quot;] 其中可以很明确的见到我们之前说的 Dockerfile 文件的两种行结构，也就是指令行和注释行，接下来我们着重关注指令行，因为这是构建镜像的关键。 Dockerfile 的结构总体上来说，我们可以将 Dockerfile 理解为一个由上往下执行指令的脚本文件。当我们调用构建命令让 Docker 通过我们给出的 Dockerfile 构建镜像时，Docker 会逐一按顺序解析 Dockerfile 中的指令，并根据它们不同的含义执行不同的操作。 如果进行细分，我们可以将 Dockerfile 的指令简单分为五大类。 基础指令：用于定义新镜像的基础和性质。 控制指令：是指导镜像构建的核心部分，用于描述镜像在构建过程中需要执行的命令。 引入指令：用于将外部文件直接引入到构建镜像内部。 执行指令：能够为基于镜像所创建的容器，指定在启动时需要执行的脚本或命令。 配置指令：对镜像以及基于镜像所创建的容器，可以通过配置指令对其网络、用户等内容进行配置。 这五类命令并非都会出现在一个 Dockerfile 里，但却对基于这个 Dockerfile 所构建镜像形成不同的影响。 常见 Dockerfile 指令熟悉 Dockerfile 的指令是编写 Dockerfile 的前提，这里我们先来介绍几个最常见的 Dockerfile 指令，它们基本上囊括了所有 Dockerfile 中 90% 以上的工作。 FROM通常来说，我们不会从零开始搭建一个镜像，而是会选择一个已经存在的镜像作为我们新镜像的基础，这种方式能够大幅减少我们的时间。 在 Dockerfile 里，我们可以通过 FROM 指令指定一个基础镜像，接下来所有的指令都是基于这个镜像所展开的。在镜像构建的过程中，Docker 也会先获取到这个给出的基础镜像，再从这个镜像上进行构建操作。 FROM 指令支持三种形式，不管是哪种形式，其核心逻辑就是指出能够被 Docker 识别的那个镜像，好让 Docker 从那个镜像之上开始构建工作。 123FROM &lt;image&gt; [AS &lt;name&gt;]FROM &lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;]FROM &lt;image&gt;[@&lt;digest&gt;] [AS &lt;name&gt;] 既然选择一个基础镜像是构建新镜像的根本，那么 Dockerfile 中的第一条指令必须是 FROM 指令，因为没有了基础镜像，一切构建过程都无法开展。 当然，一个 Dockerfile 要以 FROM 指令作为开始并不意味着 FROM 只能是 Dockerfile 中的第一条指令。在 Dockerfile 中可以多次出现 FROM 指令，当 FROM 第二次或者之后出现时，表示在此刻构建时，要将当前指出镜像的内容合并到此刻构建镜像的内容里。这对于我们直接合并两个镜像的功能很有帮助。 RUN镜像的构建虽然是按照指令执行的，但指令只是引导，最终大部分内容还是控制台中对程序发出的命令，而 RUN 指令就是用于向控制台发送命令的指令。 在 RUN 指令之后，我们直接拼接上需要执行的命令，在构建时，Docker 就会执行这些命令，并将它们对文件系统的修改记录下来，形成镜像的变化。 12RUN &lt;command&gt;RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] RUN 指令是支持 \ 换行的，如果单行的长度过长，建议对内容进行切割，方便阅读。而事实上，我们会经常看到 \ 分割的命令，例如在上面我们贴出的 Redis 镜像的 Dockerfile 里。 ENTRYPOINT 和 CMD基于镜像启动的容器，在容器启动时会根据镜像所定义的一条命令来启动容器中进程号为 1 的进程。而这个命令的定义，就是通过 Dockerfile 中的 ENTRYPOINT 和 CMD 实现的。 123456ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]ENTRYPOINT command param1 param2CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]CMD [&quot;param1&quot;,&quot;param2&quot;]CMD command param1 param2 ENTRYPOINT 指令和 CMD 指令的用法近似，都是给出需要执行的命令，并且它们都可以为空，或者说是不在 Dockerfile 里指出。 当 ENTRYPOINT 与 CMD 同时给出时，CMD 中的内容会作为 ENTRYPOINT 定义命令的参数，最终执行容器启动的还是 ENTRYPOINT 中给出的命令。 关于 ENTRYPOINT 和 CMD 的更详细对比，在后一节里我们会提到。 EXPOSE在第 9 节：为容器配置网络中，在未做特殊定义的前提下，我们直接连接容器网络，只能访问容器明确暴露的端口。而我们之前介绍的是在容器创建时通过选项来暴露这些端口。 由于我们构建镜像时更了解镜像中应用程序的逻辑，也更加清楚它需要接收和处理来自哪些端口的请求，所以在镜像中定义端口暴露显然是更合理的做法。 通过 EXPOSE 指令就可以为镜像指定要暴露的端口。 1EXPOSE &lt;port&gt; [&lt;port&gt;/&lt;protocol&gt;...] 当我们通过 EXPOSE 指令配置了镜像的端口暴露定义，那么基于这个镜像所创建的容器，在被其他容器通过 --link 选项连接时，就能够直接允许来自其他容器对这些端口的访问了。 VOLUME在一些程序里，我们需要持久化一些数据，比如数据库中存储数据的文件夹就需要单独处理。在之前的小节里，我们提到可以通过数据卷来处理这些问题。 但使用数据卷需要我们在创建容器时通过 -v 选项来定义，而有时候由于镜像的使用者对镜像了解程度不高，会漏掉数据卷的创建，从而引起不必要的麻烦。 还是那句话，制作镜像的人是最清楚镜像中程序工作的各项流程的，所以它来定义数据卷也是最合适的。所以在 Dockerfile 里，提供了 VOLUME 指令来定义基于此镜像的容器所自动建立的数据卷。 1VOLUME [&quot;/data&quot;] 在 VOLUME 指令中定义的目录，在基于新镜像创建容器时，会自动建立为数据卷，不需要我们再单独使用 -v 选项来配置了。 COPY 和 ADD在制作新的镜像的时候，我们可能需要将一些软件配置、程序代码、执行脚本等直接导入到镜像内的文件系统里，使用 COPY 或 ADD 指令能够帮助我们直接从宿主机的文件系统里拷贝内容到镜像里的文件系统中。 12345COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;ADD [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]ADD [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] COPY 与 ADD 指令的定义方式完全一样，需要注意的仅是当我们的目录中存在空格时，可以使用后两种格式避免空格产生歧义。 对比 COPY 与 ADD，两者的区别主要在于 ADD 能够支持使用网络端的 URL 地址作为 src 源，并且在源文件被识别为压缩包时，自动进行解压，而 COPY 没有这两个能力。 虽然看上去 COPY 能力稍弱，但对于那些不希望源文件被解压或没有网络请求的场景，COPY 指令是个不错的选择。 构建镜像在编写好 Dockerfile 之后，我们就可以构建我们所定义的镜像了，构建镜像的命令为 docker build。 1$ sudo docker build ./webapp docker build 可以接收一个参数，需要特别注意的是，这个参数为一个目录路径 ( 本地路径或 URL 路径 )，而并非 Dockerfile 文件的路径。在 docker build 里，这个我们给出的目录会作为构建的环境目录，我们很多的操作都是基于这个目录进行的。 例如，在我们使用 COPY 或是 ADD 拷贝文件到构建的新镜像时，会以这个目录作为基础目录。 在默认情况下，docker build 也会从这个目录下寻找名为 Dockerfile 的文件，将它作为 Dockerfile 内容的来源。如果我们的 Dockerfile 文件路径不在这个目录下，或者有另外的文件名，我们可以通过 -f 选项单独给出 Dockerfile 文件的路径。 1$ sudo docker build -t webapp:latest -f ./webapp/a.Dockerfile ./webapp 当然，在构建时我们最好总是携带上 -t 选项，用它来指定新生成镜像的名称。 1$ sudo docker build -t webapp:latest ./webapp 留言互动在本节中，我们介绍了关于 Dockerfile 以及关于它基本使用方面的内容。这里给大家留一道实践题： 编写一个你自己的程序的 Dockerfile，并将它共享给测试和运维人员。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Dockerfile 的基本使用还有疑问，或者有更好的实践角度，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E6%93%8D%E4%BD%9C%E9%95%9C%E5%83%8F%EF%BC%9A%E5%B8%B8%E8%A7%81%E7%9A%84%20Dockerfile%20%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[常见 Dockerfile 使用技巧在掌握 Dockerfile 的基本使用方法后，我们再来了解一些在开发中使用 Dockerfile 的技巧。这一小节的展现方式与之前的略有不同，其主要来自阅读收集和我自身在使用中的最佳实践。也许这里面介绍的不是最为标准或是合乎规范的方式，但一定是能够直接帮助大家在开发中使用 Docker 提升生产力的方式。下面就让我们来看看这些关于 Dockerfile 的使用技巧吧。 构建中使用变量在实际编写 Dockerfile 时，与搭建环境相关的指令会是其中占有大部分比例的指令。在搭建程序所需运行环境时，难免涉及到一些可变量，例如依赖软件的版本，编译的参数等等。我们可以直接将这些数据写入到 Dockerfile 中完全没有问题，有问题的是这些可变量我们会经常调整，在调整时就需要我们到 Dockerfile 中找到它们并进行更改，如果只是简单的 Dockerfile 文件尚且好说，但如果是相对复杂或是存在多处变量的 Dockerfile 文件，这个工作就变得繁琐而让人烦躁了。 在 Dockerfile 里，我们可以用 ARG 指令来建立一个参数变量，我们可以在构建时通过构建指令传入这个参数变量，并且在 Dockerfile 里使用它。 例如，我们希望通过参数变量控制 Dockerfile 中某个程序的版本，在构建时安装我们指定版本的软件，我们可以通过 ARG 定义的参数作为占位符，替换版本定义的部分。 123456789101112FROM debian:stretch-slim## ......ARG TOMCAT_MAJORARG TOMCAT_VERSION## ......RUN wget -O tomcat.tar.gz &quot;https://www.apache.org/dyn/closer.cgi?action=download&amp;filename=tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz&quot;## ...... 在这个例子里，我们将 Tomcat 的版本号通过 ARG 指令定义为参数变量，在调用下载 Tomcat 包时，使用变量替换掉下载地址中的版本号。通过这样的定义，就可以让我们在不对 Dockerfile 进行大幅修改的前提下，轻松实现对 Tomcat 版本的切换并重新构建镜像了。 如果我们需要通过这个 Dockerfile 文件构建 Tomcat 镜像，我们可以在构建时通过 docker build 的 --build-arg 选项来设置参数变量。 1$ sudo docker build --build-arg TOMCAT_MAJOR=8 --build-arg TOMCAT_VERSION=8.0.53 -t tomcat:8.0 ./tomcat 环境变量环境变量也是用来定义参数的东西，与 ARG 指令相类似，环境变量的定义是通过 ENV 这个指令来完成的。 12345678910FROM debian:stretch-slim## ......ENV TOMCAT_MAJOR 8ENV TOMCAT_VERSION 8.0.53## ......RUN wget -O tomcat.tar.gz &quot;https://www.apache.org/dyn/closer.cgi?action=download&amp;filename=tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz&quot; 环境变量的使用方法与参数变量一样，也都是能够直接替换指令参数中的内容。 与参数变量只能影响构建过程不同，环境变量不仅能够影响构建，还能够影响基于此镜像创建的容器。环境变量设置的实质，其实就是定义操作系统环境变量，所以在运行的容器里，一样拥有这些变量，而容器中运行的程序也能够得到这些变量的值。 另一个不同点是，环境变量的值不是在构建指令中传入的，而是在 Dockerfile 中编写的，所以如果我们要修改环境变量的值，我们需要到 Dockerfile 修改。不过即使这样，只要我们将 ENV 定义放在 Dockerfile 前部容易查找的地方，其依然可以很快的帮助我们切换镜像环境中的一些内容。 由于环境变量在容器运行时依然有效，所以运行容器时我们还可以对其进行覆盖，在创建容器时使用 -e 或是 --env 选项，可以对环境变量的值进行修改或定义新的环境变量。 1$ sudo docker run -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:5.7 事实上，这种用法在我们开发中是非常常见的。也正是因为这种允许运行时配置的方法存在，环境变量和定义它的 ENV 指令，是我们更常使用的指令，我们会优先选择它们来实现对变量的操作。 关于环境变量是如何能够帮助我们更轻松的处理 Docker 镜像和容器使用等问题，我们会在下一节中进行实际展示，通过例子大家能够更容易理解它的原理。 另外需要说明一点，通过 ENV 指令和 ARG 指令所定义的参数，在使用时都是采用 $ + NAME 这种形式来占位的，所以它们之间的定义就存在冲突的可能性。对于这种场景，大家只需要记住，ENV 指令所定义的变量，永远会覆盖 ARG 所定义的变量，即使它们定时的顺序是相反的。 合并命令在上一节我们展示的完整的官方 Redis 镜像的 Dockerfile 中，我们会发现 RUN 等指令里会聚合下大量的代码。 事实上，下面两种写法对于搭建的环境来说是没有太大区别的。 123RUN apt-get update; \ apt-get install -y --no-install-recommends $fetchDeps; \ rm -rf /var/lib/apt/lists/*; 123RUN apt-get updateRUN apt-get install -y --no-install-recommends $fetchDepsRUN rm -rf /var/lib/apt/lists/* 那为什么我们更多见的是第一种形式而非第二种呢？这就要从镜像构建的过程说起了。 看似连续的镜像构建过程，其实是由多个小段组成。每当一条能够形成对文件系统改动的指令在被执行前，Docker 先会基于上条命令的结果启动一个容器，在容器中运行这条指令的内容，之后将结果打包成一个镜像层，如此反复，最终形成镜像。 所以说，我们之前谈到镜像是由多个镜像层叠加而得，而这些镜像层其实就是在我们 Dockerfile 中每条指令所生成的。 了解了这个原理，大家就很容易理解为什么绝大多数镜像会将命令合并到一条指令中，因为这种做法不但减少了镜像层的数量，也减少了镜像构建过程中反复创建容器的次数，提高了镜像构建的速度。 构建缓存Docker 在镜像构建的过程中，还支持一种缓存策略来提高镜像的构建速度。 由于镜像是多个指令所创建的镜像层组合而得，那么如果我们判断新编译的镜像层与已经存在的镜像层未发生变化，那么我们完全可以直接利用之前构建的结果，而不需要再执行这条构建指令，这就是镜像构建缓存的原理。 那么 Docker 是如何判断镜像层与之前的镜像间不存在变化的呢？这主要参考两个维度，第一是所基于的镜像层是否一样，第二是用于生成镜像层的指令的内容是否一样。 基于这个原则，我们在条件允许的前提下，更建议将不容易发生变化的搭建过程放到 Dockerfile 的前部，充分利用构建缓存提高镜像构建的速度。另外，指令的合并也不宜过度，而是将易变和不易变的过程拆分，分别放到不同的指令里。 在另外一些时候，我们可能不希望 Docker 在构建镜像时使用构建缓存，这时我们可以通过 --no-cache 选项来禁用它。 1$ sudo docker build --no-cache ./webapp 搭配 ENTRYPOINT 和 CMD上一节我们谈到了 ENTRYPOINT 和 CMD 这两个命令，也解释了这两个命令的目的，即都是用来指定基于此镜像所创建容器里主进程的启动命令的。 两个指令的区别在于，ENTRYPOINT 指令的优先级高于 CMD 指令。当 ENTRYPOINT 和 CMD 同时在镜像中被指定时，CMD 里的内容会作为 ENTRYPOINT 的参数，两者拼接之后，才是最终执行的命令。 为了更好的让大家理解，这里索性列出所有的 ENTRYPOINT 与 CMD 的组合，供大家参考。 ENTRYPOINT CMD 实际执行 ENTRYPOINT [“/bin/ep”, “arge”] /bin/ep arge ENTRYPOINT /bin/ep arge /bin/sh -c /bin/ep arge CMD [“/bin/exec”, “args”] /bin/exec args CMD /bin/exec args /bin/sh -c /bin/exec args ENTRYPOINT [“/bin/ep”, “arge”] CMD [“/bin/exec”, “argc”] /bin/ep arge /bin/exec argc ENTRYPOINT [“/bin/ep”, “arge”] CMD /bin/exec args /bin/ep arge /bin/sh -c /bin/exec args ENTRYPOINT /bin/ep arge CMD [“/bin/exec”, “argc”] /bin/sh -c /bin/ep arge /bin/exec argc ENTRYPOINT /bin/ep arge CMD /bin/exec args /bin/sh -c /bin/ep arge /bin/sh -c /bin/exec args 有的读者会存在疑问，既然两者都是用来定义容器启动命令的，为什么还要分成两个，合并为一个指令岂不是更方便吗？ 这其实在于 ENTRYPOINT 和 CMD 设计的目的是不同的。ENTRYPOINT 指令主要用于对容器进行一些初始化，而 CMD 指令则用于真正定义容器中主程序的启动命令。 另外，我们之前谈到创建容器时可以改写容器主程序的启动命令，而这个覆盖只会覆盖 CMD 中定义的内容，而不会影响 ENTRYPOINT 中的内容。 我们依然以之前的 Redis 镜像为例，这是 Redis 镜像中对 ENTRYPOINT 和 CMD 的定义。 123456789## ......COPY docker-entrypoint.sh /usr/local/bin/ENTRYPOINT [&quot;docker-entrypoint.sh&quot;]## ......CMD [&quot;redis-server&quot;] 可以很清晰的看到，CMD 指令定义的正是启动 Redis 的服务程序，而 ENTRYPOINT 使用的是一个外部引入的脚本文件。 事实上，使用脚本文件来作为 ENTRYPOINT 的内容是常见的做法，因为对容器运行初始化的命令相对较多，全部直接放置在 ENTRYPOINT 后会特别复杂。 我们来看看 Redis 中的 ENTRYPOINT 脚本，可以看到其中会根据脚本参数进行一些处理，而脚本的参数，其实就是 CMD 中定义的内容。 12345678910111213141516#!/bin/shset -e# first arg is `-f` or `--some-option`# or first arg is `something.conf`if [ &quot;$&#123;1#-&#125;&quot; != &quot;$1&quot; ] || [ &quot;$&#123;1%.conf&#125;&quot; != &quot;$1&quot; ]; then set -- redis-server &quot;$@&quot;fi# allow the container to be started with `--user`if [ &quot;$1&quot; = &apos;redis-server&apos; -a &quot;$(id -u)&quot; = &apos;0&apos; ]; then find . \! -user redis -exec chown redis &apos;&#123;&#125;&apos; + exec gosu redis &quot;$0&quot; &quot;$@&quot;fiexec &quot;$@&quot; 这里我们要关注脚本最后的一条命令，也就是 exec &quot;$@&quot;。在很多镜像的 ENTRYPOINT 脚本里，我们都会看到这条命令，其作用其实很简单，就是运行一个程序，而运行命令就是 ENTRYPOINT 脚本的参数。反过来，由于 ENTRYPOINT 脚本的参数就是 CMD 指令中的内容，所以实际执行的就是 CMD 里的命令。 所以说，虽然 Docker 对容器启动命令的结合机制为 CMD 作为 ENTRYPOINT 的参数，合并后执行 ENTRYPOINT 中的定义，但实际在我们使用中，我们还会在 ENTRYPOINT 的脚本里代理到 CMD 命令上。 相对来说，Redis 的 ENTRYPOINT 内容还是简单的，在掌握了 ENTRYPOINT 的相关作用后，大家可以尝试阅读和编写一些复杂的 ENTRYPOINT 脚本。 临摹案例上面提及的几项只是几个比较常见的 Dockerfile 最佳实践，其实在编写 Dockerfile 时，还有很多不成文的小技巧。 想要学好 Dockerfile 的编写，阅读和思考前人的作品是必不可少的。 前面我们介绍了，Docker 官方提供的 Docker Hub 是 Docker 镜像的中央仓库，它除了镜像丰富之外，给我们带来的另一项好处就是其大部分镜像都是能够直接提供 Dockerfile 文件给我们参考的。 要得到镜像的 Dockerfile 文件，我们可以进入到镜像的详情页面，在介绍中，镜像作者们通常会直接把 Dockerfile 的连接放在那里。 除此之外，进入到 Dockerfile 这个栏目下，我们也能够直接看到镜像 Dockerfile 的内容。在页面的右侧，还有进入 Dockerfile 源文件的连接，如果在 Dockerfile 中有引入其他的文件，我们可以通过这个连接访问到。 另外，我自己也制作了一些软件的镜像，大家可以访问 GitHub 上的项目地址，查阅其中的 Dockerfile 内容：https://github.com/cogset 。 留言互动在本节中，我们介绍了在开发中使用 Dockerfile 的一些技巧。这里给大家留一道思考题： 在常见的镜像构建中，我们如何合理组合 ENTRYPOINT 和 CMD 并分配它们的工作呢？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对上述我们提及的 Dockerfile 使用技巧还有不理解的地方，或者有其他的技巧想要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E6%93%8D%E4%BD%9C%E9%95%9C%E5%83%8F%EF%BC%9A%E4%BF%9D%E5%AD%98%E5%92%8C%E5%85%B1%E4%BA%AB%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[保存和共享镜像让 Docker 引以为傲的是它能够实现相比于其他虚拟化软件更快的环境迁移和部署，在这件事情上，轻量级的容器和镜像结构的设计无疑发挥了巨大的作用。通过将容器打包成镜像，再利用体积远小于其他虚拟化软件的 Docker 镜像，我们可以更快的将它们复制到其他的机器上。在这一节中，我们就专门来谈谈如何进行这样的迁移。 提交容器更改之前我们已经介绍过了，Docker 镜像的本质是多个基于 UnionFS 的镜像层依次挂载的结果，而容器的文件系统则是在以只读方式挂载镜像后增加的一个可读可写的沙盒环境。 基于这样的结构，Docker 中为我们提供了将容器中的这个可读可写的沙盒环境持久化为一个镜像层的方法。更浅显的说，就是我们能够很轻松的在 Docker 里将容器内的修改记录下来，保存为一个新的镜像。 将容器修改的内容保存为镜像的命令是 docker commit，由于镜像的结构很像代码仓库里的修改记录，而记录容器修改的过程又像是在提交代码，所以这里我们更形象的称之为提交容器的更改。 12$ sudo docker commit webappsha256:0bc42f7ff218029c6c4199ab5c75ab83aeaaed3b5c731f715a3e807dda61d19e Docker 执行将容器内沙盒文件系统记录成镜像层的时候，会先暂停容器的运行，以保证容器内的文件系统处于一个相对稳定的状态，确保数据的一致性。 在使用 docker commit 提交镜像更新后，我们可以得到 Docker 创建的新镜像的 ID，之后我们也能够从本地镜像列表中找到它。 1234$ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 0bc42f7ff218 3 seconds ago 372MB## ...... 像通过 Git 等代码仓库软件提交代码一样，我们还能在提交容器更改的时候给出一个提交信息，方便以后查询。 1$ sudo docker commit -m &quot;Configured&quot; webapp 为镜像命名在上面的例子里，我们发现提交容器更新后产生的镜像并没 REPOSITORY 和 TAG 的内容，也就是说，这个新的镜像还没有名字。 之前我们谈到过，使用没有名字的镜像并不是很好的选择，因为我们无法直观的看到我们正在使用什么。好在 Docker 为我们提供了一个为镜像取名的命令，也就是 docker tag 命令。 1$ sudo docker tag 0bc42f7ff218 webapp:1.0 使用 docker tag 能够为未命名的镜像指定镜像名，也能够对已有的镜像创建一个新的命名。 1$ sudo docker tag webapp:1.0 webapp:latest 当我们对未命名的镜像进行命名后，Docker 就不会在镜像列表里继续显示这个镜像，取而代之的是我们新的命名。而如果我们对以后镜像使用 docker tag，旧的镜像依然会存在于镜像列表中。 12345$ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEwebapp 1.0 0bc42f7ff218 29 minutes ago 372MBwebapp latest 0bc42f7ff218 29 minutes ago 372MB## ...... 由于镜像是对镜像层的引用记录，所以我们对镜像进行命名后，虽然能够在镜像列表里同时看到新老两个镜像，实质是它们其实引用着相同的镜像层，这个我们能够从镜像 ID 中看得出来 ( 因为镜像 ID 就是最上层镜像层的 ID )。正是这个原因，我们虽然创建了新的镜像，但对物理存储的占用空间却不是镜像大小直接翻倍，并且创建也在霎那之间。 除了使用 docker tag 在容器提交为新的镜像后为镜像命名这种方式外，我们还可以直接在 docker commit 命令里指定新的镜像名，这种方式在使用容器提交时会更加方便。 1$ sudo docker commit -m &quot;Upgrade&quot; webapp webapp：2.0 镜像的迁移在我们将更新导出为镜像后，就可以开始迁移镜像的工作了。 由于 Docker 是以集中的方式管理镜像的，所以在迁移之前，我们要先从 Docker 中取出镜像。docker save 命令可以将镜像输出，提供了一种让我们保存镜像到 Docker 外部的方式。 1$ sudo docker save webapp:1.0 &gt; webapp-1.0.tar 在默认定义下，docker save 命令会将镜像内容放入输出流中，这就需要我们使用管道进行接收 ( 也就是命令中的 &gt; 符号 )，这属于 Linux 等系统控制台中的用法，这里我们不做详细讲解。 管道这种用法有时候依然不太友好，docker save 命令还为我们提供了 -o 选项，用来指定输出文件，使用这个选项可以让命令更具有统一性。 1$ sudo docker save -o ./webapp-1.0.tar webapp:1.0 在镜像导出之后，我们就可以找到已经存储镜像内容的 webapp-1.0.tar 这个文件了。有兴趣的朋友，可以使用解压软件查看其中的内容，你会看到里面其实就是镜像所基于的几个镜像层的记录文件。 导入镜像我们可以通过很多种方式将导出的镜像文件复制到另一台机器上，在这么操作之后，我们就要将镜像导入到这台新机器中运行的 Docker 中。 导入镜像的方式也很简单，使用与 docker save 相对的 docker load 命令即可。 1$ sudo docker load &lt; webapp-1.0.tar 相对的，docker load 命令是从输入流中读取镜像的数据，所以我们这里也要使用管道来传输内容。当然，我们也能够使用 -i 选项指定输入文件。 1$ sudo docker load -i webapp-1.0.tar 镜像导入后，我们就可以通过 docker images 看到它了，导入的镜像会延用原有的镜像名称。 批量迁移通过 docker save 和 docker load 命令我们还能够批量迁移镜像，只要我们在 docker save 中传入多个镜像名作为参数，它就能够将这些镜像都打成一个包，便于我们一次性迁移多个镜像。 1$ sudo docker save -o ./images.tar webapp:1.0 nginx:1.12 mysql:5.7 装有多个镜像的包可以直接被 docker load 识别和读取，我们将这个包导入后，所有其中装载的镜像都会被导入到 Docker 之中。 导出和导入容器也许 Docker 的开发者认为，提交镜像修改，再导出镜像进行迁移的方法还不够效率，所以还为我们提供了一个导出容器的方法。 使用 docker export 命令我们可以直接导出容器，我们可以把它简单的理解为 docker commit 与 docker save 的结合体。 1$ sudo docker export -o ./webapp.tar webapp 相对的，使用 docker export 导出的容器包，我们可以使用 docker import 导入。这里需要注意的是，使用 docker import 并非直接将容器导入，而是将容器运行时的内容以镜像的形式导入。所以导入的结果其实是一个镜像，而不是容器。在 docker import 的参数里，我们可以给这个镜像命名。 1$ sudo docker import ./webapp.tar webapp:1.0 在开发的过程中，使用 docker save 和 docker load，或者是使用 docker export 和 docker import 都可以达到迁移容器或者镜像的目的。 留言互动在本节中，我们介绍了关于对 Docker 容器和镜像进行迁移的一些方法。这里给大家留一道思考题： 通过 Docker 进行的集群部署和其他虚拟化形式中的集群部署有怎样的区别，在部署过程中 Docker 又是如何发挥它优势的？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对保存和共享镜像还有疑问，或者有更好的实践角度，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E6%93%8D%E4%BD%9C%E9%95%9C%E5%83%8F%EF%BC%9A%E4%BD%BF%E7%94%A8%20Docker%20Hub%20%E4%B8%AD%E7%9A%84%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[使用 Docker Hub 中的镜像自己编写 Dockerfile 能够很好的实现我们想要的程序运行环境，不过如果装有我们想要环境的镜像已经由热心的开发者构建好并共享在 Docker Hub 上，直接使用它们就会远比自己编写 Dockerfile 并进行构建要来的简单的多了。事实上，在开发过程中我们用到的镜像大部分还是直接采用 Docker Hub 中已经存在的镜像的，即使自己编写 Dockerfile，也只是对已有镜像进行简单的改动，很少会从零开始搭建镜像。在这一节中，我们要来看看如何更好地使用 Docker Hub 上由其他开发者共享的镜像。 选择镜像与程序版本由于 Docker 的容器设计是程序即容器的，所以组成我们服务系统的多个程序一般会搭建在多个容器里，互相之间协作提供服务。例如一套最简单的 Web 服务，我们可能会需要 Java 容器来运行基于 Spring Boot 的程序，需要 MySQL 容器来提供数据库支持，需要 Redis 容器来作为高速 KV 存储等等。装有这些程序的镜像我们都可以很容易的在 Docker Hub 上找到并直接使用，但在我们使用前，光选择镜像还是不够的，我们还得根据需要选择对应程序版本的镜像。 虽然我们常把软件的版本放在 Tag 里作为镜像名的一部分，但对于一些复杂的应用，除了版本外，还存在很多的变量，镜像的维护者们也喜欢将这些变量一同组合到镜像的 Tag 里，所以我们在使用镜像前，一定要先了解不同 Tag 对应的不同内容。 这里我们来看个例子，下面是由 Docker 官方提供的 OpenJDK 镜像的说明页面。 通常来说，镜像的维护者会在镜像介绍中展示出镜像所有的 Tag，如果没有，我们也能够从页面上的 Tags 导航里进入到镜像标签列表页面。 在 OpenJDK 镜像的 Tag 列表里，我们可以看到同样版本号的镜像就存在多种标签。在这些不同的标签上，除了定义 OpenJDK 的版本，还有操作系统，软件提供者等信息。 镜像维护者为我们提供这么多的标签进行选择，其实方便了我们在不同场景下选择不同环境实现细节时，都能直接用到这个镜像，而不需要再单独编写 Dockerfile 并构建。 但是换句话说，正是有这么多不同标签的镜像存在，所以我们在选择的时候，更要仔细认真，找到我们想要的那个镜像。 Alpine 镜像如果大家多接触几个镜像，就会发现带有 Alpine 的版本是许多镜像中都常见的标签。带有 Alpine 标签的镜像到底是什么样的存在呢？它与相同软件不同标签的镜像又有什么样的区别呢？ 镜像标签中的 Alpine 其实指的是这个镜像内的文件系统内容，是基于 Alpine Linux 这个操作系统的。Alpine Linux 是一个相当精简的操作系统，而基于它的 Docker 镜像可以仅有数 MB 的尺寸。如果软件基于这样的系统镜像之上构建而得，可以想象新的镜像也是十分小巧的。 在 Docker 里，Alpine 系统的镜像到底有多小，我们不妨来与其他系统镜像做一个比较。 操作系统镜像 占用空间 alpine:latest 4.4 MB ubuntu:latest 84.1 MB debian:latest 101 MB centos:latest 200 MB 可以看到，Alpine 系统镜像的尺寸要远小于其他常见的系统镜像。让我们再来比较同一个软件在基于普通系统的镜像和基于 Alpine 系统的镜像后尺寸上的区别。 镜像标签 占用空间 python:3.6-alpine 74.2 MB python:3.6-jessie 697 MB 由于基于 Alpine 系统建立的软件镜像远远小于基于其他系统的软件镜像，它在网络传输上的优势尤为明显。如果我们选择这类的镜像，不但可以节约网络传输的时间，也能减少镜像对硬盘空间的占用。 当然，有优点也会有缺点，Alpine 镜像的缺点就在于它实在过于精简，以至于麻雀虽小，也无法做到五脏俱全了。在 Alpine 中缺少很多常见的工具和类库，以至于如果我们想基于软件 Alpine 标签的镜像进行二次构建，那搭建的过程会相当烦琐。所以如果你想要对软件镜像进行改造，并基于其构建新的镜像，那么 Alpine 镜像不是一个很好的选择 (这时候我们更提倡基于 Ubuntu、Debian、CentOS 这类相对完整的系统镜像来构建)。 对容器进行配置除了合理选择镜像外，许多镜像还为我们提供了更加方便的功能，这些细节我们通常都可以在镜像的详情里阅读到。 这里我们以 MySQL 为例，看看通常我们是怎样阅读和使用镜像的特殊功能的。 自己安装过 MySQL 的朋友一定知道，搭建 MySQL 最麻烦的地方并不是安装的过程，而是安装后进行初始化配置的过程。就拿更改 root 账号的密码来说，在初始的 MySQL 里就要耗费不少工作量。 如果我们拿到一个 MySQL 镜像，运行起来的 MySQL 也就约等于一个刚刚安装好的程序，面临的正好是复杂的初始化过程。 好在 MySQL 镜像的维护者们为我们打造了一些自动化脚本，通过它们，我们只需要简单的传入几个参数，就能够快速实现对 MySQL 数据库的初始化。 在 MySQL 镜像的详情里，描述了我们要如何传入这些参数来启动 MySQL 容器。 对于 MySQL 镜像来说，进行软件配置的方法是通过环境变量的方式来实现的 ( 在其他的镜像里，还有通过启动命令、挂载等方式来实现的 )。我们只需要通过这些给出的环境变量，就可以初始化 MySQL 的配置了。 例如，我们可以通过下面的命令来直接建立 MySQL 中的用户和数据库。 1$ sudo docker run --name mysql -e MYSQL_DATABASE=webapp -e MYSQL_USER=www -e MYSQL_PASSWORD=my-secret-pw -d mysql:5.7 通过这条命令启动的 MySQL 容器，在内部就已经完成了用户的创建和数据库的创建，我们通过 MySQL 客户端就能够直接登录这个用户和访问对应的数据库了。 如果深究 MySQL 是如何实现这样复杂的功能的，大家可以到 MySQL 镜像的 Dockerfile 源码库里，找到 docker-entrypoint.sh 这个脚本，所有的秘密正暗藏在其中。MySQL 正是利用了 ENTRYPOINT 指令进行初始化这种任务安排，对容器中的 MySQL 进行初始化的。 通过 MySQL 镜像这样的逻辑，大家还可以举一反三，了解其他镜像所特用的使用方法，甚至可以参考编写、构建一些能够提供这类方法的 Dockerfile 和镜像。 共享自己的镜像如果我们希望将我们镜像公开给网络上的开发者们，那通过 Docker Hub 无疑是最佳的方式。 要在 Docker Hub 上共享镜像，我们必须有一个 Docker Hub 的账号，这自不必说了。在登录到我们账号的控制面板后，我们能够找到创建的按钮，在这里选择 Create Automated Build ( 创建自动构建 )。 自动构建镜像是 Docker Hub 为我们提供的一套镜像构建服务，我们只需要提供 Dockerfile 和相关的基本文件，Docker Hub 就能够在云端自动将它们构建成镜像，之后便可以让其他开发者通过 docker pull 命令拉取到这一镜像。 自动构建让不需要我们再用本机进行镜像的构建，既能节约时间，又能享受高速的云端机器构建。 在 Docker Hub 中并不直接存放我们用于构建的 Dockerfile 和相关文件，我们必须将 Docker Hub 账号授权到 GitHub 或是 Bitbucket 来从这些代码库中获取 Dockerfile 和相关文件。 在连接到 GitHub 或 Bitbucket 后，我们就可以选择我们存放 Dockerfile 和相关文件的代码仓库用来创建自动构建了。 在基本信息填写完成，点击创建按钮后，Docker Hub 就会开始根据我们 Dockerfile 的内容构建镜像了。而此时，我们也能够访问我们镜像专有的详情页面了。 在 Build Details 页面里，我们可以看到镜像构建的进度和详细的构建情况。 留言互动在本节中，我们介绍了如何掌握对 Docker Hub 中不同镜像的使用。这里给大家留一道思考题： 在实际开发中使用网络中由他人共享的 Docker 镜像，我们可以通过哪些内容快速了解这些镜像的使用？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对使用 Docker Hub 由其他网友提供的镜像还有什么不解之处，或者有具体的方法想要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%B7%AF%EF%BC%9A%E6%90%AD%E5%BB%BA%20Java%20Web%20%E9%A1%B9%E7%9B%AE%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[搭建 Java Web 项目运行环境Java Web 泛指以 Java 程序为基础向外提供 Web 服务的技术及相关工具，狭义上来说，我们也可以说 Java Web 是由 Servlet 程序提供的 Web 服务。 对我们而言，Tomcat 无疑是最常见的 Servlet 容器，所以在这个小节里，我们来搭建一个以 Tomcat 为核心的 Web 应用运行环境。 在这个环境中，我们还要组合进 MySQL 作为数据存储，Redis 作为 KV 存储。 定义项目结构与之前我们提及的一样，要搭建这样的由多个程序所协作组成的开发环境，使用 Docker Compose 是最佳的选择。 建立 Docker Compose 项目之前，我们先来规划一下项目的目录结构。 在开发过程中，我们倾向于将与项目有关的内容集合到同一个文件夹下，这样的做有几点好处： 项目内容清晰明确，复制、迁移和与他人共享的过程中，不会发生遗漏的情况； 在定义 Docker Compose 项目时可以使用相对路径，让共享、迁移后整个项目可以不需要额外操作就能运行。 在这些的基础上，我给出一个建议性的目录结构，供大家参考。 1234567891011└─ project ├─ app ├─ compose │ └─ docker-compose.yml ├─ mysql │ └─ my.cnf ├─ redis │ └─ redis.conf └─ tomcat ├─ server.xml └─ web.xml 设计这样一个目录结构的主要目的是将不同程序的配置进行区分，这与我们之后会通过多个程序所关联的镜像及容器来组合这套环境的脉络是相契合的。 在这个目录结构中，区分了 5 个顶层目录： app ：用于存放程序工程，即代码、编译结果以及相关的库、工具等； compose ：用于定义 Docker Compose 项目； mysql ：与 MySQL 相关配置等内容； redis ：与 Redis 相关配置等内容； tomcat ：与 Tomcat 相关配置等内容。 准备程序配置为了更方便在开发过程中对 MySQL、Redis、Tomcat 程序本身，所以我们会将它们的核心配置放置到项目里，再通过挂载的方式映射到容器中。 这样一来，我们就可以直接在我们宿主操作系统里直接修改这些配置，无须再进入到容器中了。 基于此，我们在完成目录的设计之后，首要解决的问题就是准备好这些程序中会经常变动的配置，并把它们放置在程序对应的目录之中。 我们常用下列几种方式来获得程序的配置文件： 借助配置文档直接编写 下载程序源代码中的配置样例 通过容器中的默认配置获得 下面我们来展示一下这几种获取配置的方式。 借助配置文档直接编写这里我们利用 MySQL 文档中配置文件的介绍部分，来编写一个 MySQL 的配置文件。 我们先找到 MySQL 文档中关于配置文件的参考，也就是下面这个地址： https://dev.mysql.com/doc/refman/5.7/en/server-options.html 我们根据这些内容，选取跟我们程序运行有影响的几项需要修改的参数，编写成 MySQL 的配置文件。 123456789101112131415161718192021222324252627# ./mysql/my.cnf[mysqld_safe]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.socknice = 0[mysqld]skip-host-cacheskip-name-resolveexplicit_defaults_for_timestampbind-address = 0.0.0.0port = 3306user = mysqlpid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.socklog-error = /var/log/mysql/error.logbasedir = /usrdatadir = /var/lib/mysqltmpdir = /tmpsql_mode = NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLESlc-messages-dir = /usr/share/mysqlsymbolic-links = 0 使用软件的文档来编写配置文件，其优势在于在编写的过程实际上也是我们熟悉软件的过程，通过配置加文档形式的阅读，你一定会从中收获很多。 当然，这种方法也有很大的劣势，即需要仔细阅读文档，劳神劳力，对于常规开发中的使用来说，成效比很低。 下载程序源代码中的配置样例除了通过配置文档来了解软件的配置外，大部分软件，特别是开源软件都会直接给出一份示例配置文件作为参考。 我们可以直接拿到这份配置，达到我们的目的。 这里我们以 Redis 为例，在 Redis 源代码中，就包含了一份默认的配置文件，我们可以直接拿来使用： https://github.com/antirez/redis/blob/3.2/redis.conf 在拿到这是默认的配置后，我们还可以根据需要对其中的部分配置进行修改，以更好的满足我们的需求。 这里我们以修改 Redis 的密码为例。 打开配置文件，找到定义 Redis 授权授权的地方，将密码修改为我们需要的内容。 1234567891011121314151617# ./redis/redis.conf##...################################## SECURITY #################################### Require clients to issue AUTH &lt;PASSWORD&gt; before processing any other# commands. This might be useful in environments in which you do not trust# others with access to the host running redis-server.## This should stay commented out for backward compatibility and because most# people do not need auth (e.g. they run their own servers).## Warning: since Redis is pretty fast an outside user can try up to# 150k passwords per second against a good box. This means that you should# use a very strong password otherwise it will be very easy to break.#requirepass my-secret-pw##... 相对于通过配置文档获得配置，从配置示例里获得配置要来得更为简单容易。 但其也有一定的限制，既要对于的程序能够提供这样的示例配置，又要我们能够顺利找到这些配置文件。 通过容器中的默认配置获得除了从官方手册或者配置示例中获得配置文件外，我们还有一种远在天边近在眼前的获取配置文件的方法。 大多数 Docker 镜像为了实现自身能够直接启动为容器并马上提供服务，会把默认配置直接打包到镜像中，以便让程序能够直接读取。 所以说，我们可以直接从镜像里拿到这份配置，拷贝到宿主机里备用。 那么我们就以最后一个尚未出场的 Tomcat 为例，说说如何从 Tomcat 镜像里拿到配置文件。 要拿到 Tomcat 中的配置文件，我们需要先创建一个临时的 Tomcat 容器。 1# docker run --rm -d --name temp-tomcat tomcat:8.5 这里我们将容器命名为 temp-tomcat 以便我们之后的操作。 对于 Tomcat 来说，在开发过程中我们可能会经常改动的配置主要是 server.xml 和 web.xml 这两个文件，所以接下来我们就把这两个文件从容器中复制到宿主机里。 这里我们会用到 docker cp 这个命令，docker cp 能够在容器与宿主机的文件系统间拷贝文件和目录。 12# docker cp temp-tomcat:/usr/local/tomcat/conf/server.xml ./server.xml# docker cp temp-tomcat:/usr/local/tomcat/conf/web.xml ./web.xml 在这个命令的使用中，几个参数的含义如下： temp-tomcat : 操作的容器。这里我们使用刚才创建的临时容器的容器名来指定。 /usr/local/tomcat/conf/server.xml : 需要拷贝的路径。也就是容器中配置文件的路径，这个路径可以通过 docker exec 等命令进到容器里寻觅一下就能获得。 ./server.xml : 是目标路径。即选择将文件拷贝到宿主机的什么位置上。 熟悉 Linux 中 cp 命令的朋友会非常容易看懂这个命令，这两者传参的方式是基本一致的。 主要的区别在于 docker cp 命令由于是在容器与宿主机间进行拷贝，所以来源目录或者目标目录中需要指定一下容器。 上述的命令是从容器中向宿主机里拷贝文件，我们还可以从宿主机中向容器里拷贝文件，只需要调换一下参数的位置即可。 1# docker cp ./server.xml temp-tomcat:/usr/local/tomcat/conf/server.xml 回过头来看我们的配置，在执行了上述的命令之后，两个配置文件已经出现在我们系统的目录中了。 另外，别忘了在完成上面的操作后清理我们创建的临时容器。 1# docker stop temp-tomcat 由于我们在创建临时容器的时候增加了 --rm 选项，所以我们在这里只需要使用 docker stop 停止容器，就可以在停止容器的同时直接删除容器，实现直接清理的目的。 编写 Docker Compose 定义文件准备好了程序的配置，我们就可以来编写我们的 Docker Compose 项目定义文件了。 这里是我编写好的一份 Docker Compose 项目定义文件。 12345678910111213141516171819202122232425262728293031version: &quot;3&quot;services: redis: image: redis:3.2 volumes: - ../redis/redis.conf:/etc/redis/redis.conf:ro - ../redis/data:/data command: - redis-server - /etc/redis/redis.conf ports: - 6379:6379 mysql: image: mysql:5.7 volumes: - ../mysql/my.cnf:/etc/mysql/my.cnf:ro - ../mysql/data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: my-secret-pw ports: - 3306:3306 tomcat: image: tomcat:8.5 volumes: - ../app:/usr/local/tomcat/webapps/ROOT ports: - 80:8080 在这个项目里，我将 Redis 和 MySQL 的数据存储目录，也就是 Redis 容器中的 /data 目录和 MySQL 容器中的 /var/lib/mysql 目录通过挂载的方式绑定到了宿主机上的目录中。 这么做的目的是为了让 Redis 和 MySQL 的数据能够持久化存储，避免我们在创建和移除容器时造成数据的流失。 同时，这种将数据挂载出来的方法，可以直接方便我们打包数据并传送给其他开发者，方便开发过程中进行联调。 在 Tomcat 这个服务中，我们将程序直接挂载到 webapps/ROOT 目录下，这样我们就能够借助 Tomcat 访问我们的应用了。 如果大家有多个项目，也可以进行适当调整，将它们挂载到 webapps 下面的子目录中，实现同时访问多个应用的目的。 另外，这里我还把 Tomcat 默认的 8080 端口映射到了宿主机的 80 端口上，这样便于我们直接通过地址访问网站，不需要经常人工补充端口号了。 启动项目一切就绪，我们就可以直接通过 Docker Compose 的命令来启动开发环境了。 1# docker-compose -p javaweb -f ./compose/docker-compose.yml up -d 留言互动在这节中，我们展示了通过 Docker 搭建一个 Java Web 开发环境的过程，下面就是大家自己动手进行实践的时候了。 本小节中的示例，已经更新到了： https://github.com/youmingdot/docker-book-for-developer-samples 大家可以在实践过程中的用其作为参考。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果大家在实践过程中遇到困难，或者有自己的实践心得要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%B7%AF%EF%BC%9A%E5%9C%A8%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[在开发环境中使用服务发现服务发现应用是很多服务化系统的组成部分，所以在开发、测试环境中也就有必要配备一套服务发现体系来配合我们的开发、测试工作。在这一小节里，我们就来谈谈如何在 Docker 环境下部署服务发现应用。 使用 Docker Compose 模拟 Zookeeper 集群实现服务发现的方法有很多种，其中较为常见的一种是利用分布式注册中心，解决服务之间协调的问题。 在众多注册中心应用中，Zookeeper 是较为常见和常用的一款程序，这里我们就以 Zookeeper 为例，介绍如何使用 Docker 搭建 Zookeeper 的运行环境。 设计目录结构由于 Zookeeper 的运行并不需要太多的关注配置和调整，这里我们就以最基础的形式来设计 Docker Compose 项目的结构。 12345└─ project ├─ bin │ └─ compose.sh └─ compose └─ docker-compose.yml 为了方便日常操作，我们依然编写了 compose.sh 这个脚本来辅助我们控制 Docker Compose 项目。 编写 docker-compose.yml很多读者会问到一个问题，怎么样才能通过 Docker 的虚拟化技术实现在一个机器上模拟出多台机器的效果。或者说一个我们这里会涉及的具体问题，如何只用一个 Docker 来模拟一个高可用的 Zookeeper 集群。 我们知道，要实现 Zookeeper 的高可用，至少需要三个 Zookeeper 节点进行协作，所以这里我们用三个单独的 Docker Compose 服务定义来分别定义这三个节点。 123456789101112131415161718192021222324252627282930313233version: &apos;3&apos;services: zk1: image: zookeeper:3.4 restart: always hostname: zk1 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zk2:2888:3888 server.3=zk3:2888:3888 ports: - 2181:2181 zk2: image: zookeeper:3.4 restart: always hostname: zk2 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zk1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zk3:2888:3888 ports: - 2182:2181 zk3: image: zookeeper:3.4 restart: always hostname: zk3 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zk1:2888:3888 server.2=zk2:2888:3888 server.3=0.0.0.0:2888:3888 ports: - 2183:2181 在这个 Docker Compose 项目中，我们定义的三个 Zookeeper 服务都直接使用了官方制作的 zookeeper 镜像。 在这个镜像里，我们可以留意定制 ZOO_MY_ID 和 ZOO_SERVERS 这两个环境变量。这两个变量主要是用来识别 Zookeeper 集群中不同 Zookeeper 程序的。 其中 ZOO_MY_ID 是 Zookeeper 在集群中的编号，而 ZOO_SERVERS 用来定义集群中的所有 Zookeeper 及它们的连接方式。 我们以 zk1 这个服务为例来解释一下 ZOO_SERVERS 的定义方法。 1server.1=0.0.0.0:2888:3888 server.2=zk2:2888:3888 server.3=zk3:2888:3888 我们可以在 ZOO_SERVERS 中定义所有处于 Zookeeper 集群中的程序，通过空格来间隔它们。而每个服务的的定义形式为 server.[id]=[host]:[port]:[port]，所以就有了上面例子中我们看到的样子。 在这个例子里，我们描述了三个 Zookeeper 程序的连接地址。 由于每个容器都有独立的端口表，所以即使这些程序都运行在一个主机里，我们依然不需要担心，它们会造成端口的冲突。所以这里我们直接使用默认的 2888 和 3888 来进行服务间的相互通信即可。 而在进行容器互联的过程中，我们可以通过 Docker 的解析机制，直接填入对应服务的名称替代它们的 IP 地址，也就是这个例子里的 zk2 和 zk3。 重启机制在项目定义中，我们还注意到了 restart: always 这个配置，这个配置主要是用来控制容器的重启策略的。 这里的 always 指的是不论任何情况，容器出现问题后都会自动重启，也包括 Docker 服务本身在启动后容器也会自动启动。 另外，restart 还支持几种配置： 配置值 说明 no 不设重启机制 always 总是重启 on-failure 在异常退出时重启 unless-stopped 除非由停止命令结束，其他情况都重启 在实际使用中，我们可以根据需要选择不同的重启策略。 而这个项目里，我们希望 Zookeeper 能够一直健壮的运行，所以使用了 always 这个重启策略。 启动项目一切就绪，我们就可以直接通过 Docker Compose 的命令来启动开发环境了。 1# ./bin/compose.sh up -d 留言互动在这节中，我们展示了在开发中使用 Docker 部署服务发现工具的过程，下面就是大家自己动手进行实践的时候了。 本小节中的示例，已经更新到了： https://github.com/youmingdot/docker-book-for-developer-samples 大家可以在实践过程中的用其作为参考。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果大家在实践过程中遇到困难，或者有自己的实践心得要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8C%EF%BC%9A%E6%90%AD%E5%BB%BA%20Docker%20%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[搭建 Docker 运行环境既然 Docker 是一款实用软件，我们就不得不先从它的安装说起，只有让 Docker 运行在我们的计算机上，才能更方便我们对 Docker 相关知识和使用方式的学习。得益于与商业性的优雅结合，Docker 背后拥有大量的优秀开发者为其提供技术支持，而这个优势所造就的结果之一，就是 Docker 拥有丰富且完善的安装体系，我们可以很轻松的通过多种方式安装和运行 Docker。 安装前的准备由于 Docker 容器实现本身就采用了 Linux 内核中很多的特性，所以它自然与 Linux 系统亲密性很高，所以我们可以很轻松的将 Docker Engine 安装在 Linux 系统中。 不过，在安装之前，我还得不厌其烦的啰嗦一些基本概念，让大家在安装 Docker 时能够更好的进行选择。掌握这些概念，能够帮助大家理解一些安装流程中操作的目的，不至于总是一味的进行“下一步”式安装。 Docker Engine 的版本在安装 Docker 之前，我们先来了解一下 Docker 的版本定义，这有利于我们在之后的开发中选择和使用合适的 Docker 版本。 对于 Docker Engine 来说，其主要分为两个系列： 社区版 ( CE, Community Edition ) 企业版 ( EE, Enterprise Edition ) 社区版 ( Docker Engine CE ) 主要提供了 Docker 中的容器管理等基础功能，主要针对开发者和小型团队进行开发和试验。而企业版 ( Docker Engine EE ) 则在社区版的基础上增加了诸如容器管理、镜像管理、插件、安全等额外服务与功能，为容器的稳定运行提供了支持，适合于中大型项目的线上运行。 社区版和企业版的另一区别就是免费与收费了。对于我们开发者来说，社区版已经提供了 Docker 所有核心的功能，足够满足我们在开发、测试中的需求，所以我们直接选择使用社区版进行开发即可。在这本小册中，所有的内容也是围绕着社区版的 Docker Engine 展开的。 从另外一个角度，Docker Engine 的迭代版本又会分为稳定版 ( Stable release ) 和预览版 ( Edge release )。不论是稳定版还是预览版，它们都会以发布时的年月来命名版本号，例如如 17 年 3 月的版本，版本号就是 17.03。 Docker Engine 的稳定版固定为每三个月更新一次，而预览版则每月都会更新。在预览版中可以及时掌握到最新的功能特性，不过这对于我们仅是使用 Docker 的开发者来说，意义并不是特别重大的，所以我还是更推荐安装更有保障的稳定版本。 在主要版本之外，Docker 官方也以解决 Bug 为主要目的，不定期发布次要版本。次要版本的版本号由主要版本和发布序号组成，如：17.03.2 就是对 17.03 版本的第二次修正。 Docker 的环境依赖由于 Docker 的容器隔离依赖于 Linux 内核中的相关支持，所以使用 Docker 首先需要确保安装机器的 Linux kernel 中包含 Docker 所需要使用的特性。以目前 Docker 官方主要维护的版本为例，我们需要使用基于 Linux kernel 3.10 以上版本的 Linux 系统来安装 Docker。 也许 Linux kernel 的版本还不够直观，下面的表格就直接展示了 Docker 对主流几款 Linux 系统版本的要求。 操作系统 支持的系统版本 CentOS CentOS 7 Debian Debian Wheezy 7.7 (LTS)Debian Jessie 8 (LTS)Debian Stretch 9Debian Buster 10 Fedora Fedora 26Fedora 27 Ubuntu Ubuntu Trusty 14.04 (LTS)Ubuntu Xenial 16.04 (LTS)Ubuntu Artful 17.10 当然，在较低版本的 Linux 系统中也能安装 Docker，不过只能是版本较低的 Docker，其功能存在一些缺失，或者与最新版本有所区别。在这本小册里，我们主要以较新版本的 Docker 功能和操作作为介绍，所以如果条件允许，建议将系统升级到支持最新版本 Docker 的系统版本。 在 Linux 系统中安装 Docker因为 Docker 本身就基于 Linux 的核心能力，同时目前主流的 Linux 系统中所拥有的软件包管理程序，已经可以很轻松的帮助我们处理各种依赖问题，所以在 Linux 中安装 Docker 并非什么难事。 更多的细节就不多说了，Docker 已经为我们准备了好了各系统的安装包，毕竟安装 Docker 并不是我们所要掌握的重点，所以这里我就直接给出安装的命令了。 CentOS1234567$ sudo yum install yum-utils device-mapper-persistent-data lvm2$$ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo$ sudo yum install docker-ce$$ sudo systemctl enable docker$ sudo systemctl start docker Debian123456789$ sudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common$$ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -$ sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable&quot;$ sudo apt-get update$ sudo apt-get install docker-ce$$ sudo systemctl enable docker$ sudo systemctl start docker Fedora1234567$ sudo dnf -y install dnf-plugins-core$$ sudo dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo$ sudo dnf install docker-ce$$ sudo systemctl enable docker$ sudo systemctl start docker Ubuntu123456789$ sudo apt-get install apt-transport-https ca-certificates curl software-properties-common$$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -$ sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;$ sudo apt-get update$ sudo apt-get install docker-ce$$ sudo systemctl enable docker$ sudo systemctl start docker 上手使用在安装 Docker 完成之后，我们需要先启动 docker daemon 使其能够为我们提供 Docker 服务，这样我们才能正常使用 Docker。 在我们通过软件包的形式安装 Docker Engine 时，安装包已经为我们在 Linux 系统中注册了一个 Docker 服务，所以我们不需要直接启动 docker daemon 对应的 dockerd 这个程序，而是直接启动 Docker 服务即可。启动的 Docker 服务的命令其实我已经包含在了前面谈到的安装命令中，也就是： 1$ sudo systemctl start docker 当然，为了实现 Docker 服务开机自启动，我们还可以运行这个命令： 1$ sudo systemctl enable docker docker version在 Docker 服务启动之后，我们先来尝试一个最简单的查看 Docker 版本的命令：docker version。 12345678910111213141516171819$ sudo docker versionClient: Version: 18.06.1-ce API version: 1.38 Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:23:03 2018 OS/Arch: linux/amd64 Experimental: falseServer: Engine: Version: 18.06.1-ce API version: 1.38 (minimum version 1.12) Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:25:29 2018 OS/Arch: linux/amd64 Experimental: false 这个命令能够显示 Docker C/S 结构中的服务端 ( docker daemon ) 和客户端 ( docker CLI ) 相关的版本信息。在默认情况下，docker CLI 连接的是本机运行的 docker daemon ，由于 docker daemon 和 docker CLI 通过 RESTful 接口进行了解耦，所以我们也能修改配置用于操作其他机器上运行的 docker daemon 。 docker info如果想要了解 Docker Engine 更多相关的信息，我们还可以通过 docker info 这个命令。 123456789101112131415$ sudo docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 18.06.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfs## ......Live Restore Enabled: false 在 docker info 这条命令的结果中，我们可以看到正在运行的 Docker Engine 实例中运行的容器数量，存储的引擎等等信息。由于命令结果比较多，这里我省略了大部分内容，大家可以自己操作来尝试获得完整的信息。在之后的章节里，较多结果的命令我也会省去一些与讲解内容无关的部分，节约大家阅读的时间并强化重点。 配置国内镜像源在很多编程语言中，为了更好的向大家提供依赖包的管理，通常都会有一些组织研发相应的包管理工具，例如 Java 的 Maven，PHP 的 Composer，Node.js 的 NPM 等等。而这些管理工具背后，也对应着一个默认的依赖包仓库。 由于众所周知的原因，我们直接连接这些位于国外服务器上的仓库去获取依赖包速度是非常慢的，这时候我们通常会采用国内一些组织或开发者贡献的国内镜像仓库 ( 注意，这里的“镜像”是指复制于国外源的意思，而不是 Docker 里的镜像 )。 在 Docker 中也有一个由官方提供的中央镜像仓库，不过，它与之前我们所说的国外依赖包仓库一样，除了慢的可怜以外，还经常莫名其妙的完全无法访问。 为了解决这个问题，我们最佳的方式依旧是在国内找一个镜像仓库的镜像源进行替换。很感谢 DaoCloud、阿里云等企业的支持，在国内我们可以找到许多镜像源。这里我们给出一个由 Docker 官方提供的国内镜像源： https://registry.docker-cn.com ( 注：部分读者反映配置了这个镜像源无效，大家需要注意此地址的协议是 https，不要搞错哟 ) 那么有了地址，我们要如何将其配置到 Docker 中呢？ 在 Linux 环境下，我们可以通过修改 /etc/docker/daemon.json ( 如果文件不存在，你可以直接创建它 ) 这个 Docker 服务的配置文件达到效果。 12345&#123; &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot; ]&#125; 在修改之后，别忘了重新启动 docker daemon 来让配置生效哟： 1$ sudo systemctl restart docker 要验证我们配置的镜像源是否生效，我们可以通过 docker info 来查阅当前注册的镜像源列表。 12345$ sudo docker info## ......Registry Mirrors: https://registry.docker-cn.com/## ...... 留言互动在这节中，在这一小节中我们掌握了如何在 Linux 中安装上了 Docker Engine，也学习使用了几个简单的 docker 命令的使用。这里给大家留一道实践题： 尝试自己在 Linux 系统中安装和运行 Docker Engine。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker Engine 的安装以及启动运行还有什么疑问，或者在操作的过程中出现了无法处理的问题，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8C%EF%BC%9A%E5%9C%A8%20Windows%20%E5%92%8C%20Mac%20%E4%B8%AD%E4%BD%BF%E7%94%A8%20Docker%2F</url>
    <content type="text"><![CDATA[在 Windows 和 Mac 中使用 Docker对于开发来说，Windows 和 macOS 是更为常见和常用的系统，所以也很有必要了解在 Windows 和 macOS 中使用 Docker 的方法。很幸运的是，Docker 的官方对这两个系统提供了强有力的支持，我们可以很轻松的在这两个系统中运行 Docker。在这一小节中，我们就来了解一下 Docker 在 Windows 和 macOS 中安装的方式以及运行的原理。 Docker Desktop在大多数情况下，我们的开发工作是在 Windows 或 macOS 这两个操作系统中进行的，既然 Docker 是我们用来解决开发、测试到运维整条产品线的工具，自然支持这两个系统是不可或缺的功能。 如同封装 Docker 为我们提供了轻松的虚拟化运行环境一样，Docker 在 Windows 和 macOS 中的安装也是极易完成的。Docker 官方为 Windows 和 macOS 系统单独开辟了一条产品线，名为 Docker Desktop，其定位是快速为开发者提供在 Windows 和 macOS 中运行 Docker 环境的工具。 Docker Desktop 实现容器化与 Docker Engine 是一致的，这就保证了我们在 Windows 和 macOS 中开发所使用的环境可以很轻松的转移到其他的 Docker 实例中，不论这个 Docker 实例是运行在 Windows、macOS 亦或是 Linux。 Docker Desktop 产品线包含两个软件，也就是针对 Windows 系统的 Docker for Windows 和针对 macOS 的 Docker for Mac。 安装 Docker Desktop在安装 Docker for Windows 和 Docker for Mac 之前，我们依然要了解一下两款软件对操作系统及软硬件的要求，只有达到了这些要求，我们才能顺利的安装上 Docker for Windows 和 Docker for Mac。 对于 Windows 系统来说，安装 Docker for Windows 需要符合以下条件： 必须使用 Windows 10 Pro ( 专业版 ) 必须使用 64 bit 版本的 Windows 对于 macOS 系统来说，安装 Docker for Mac 需要符合以下条件： Mac 硬件必须为 2010 年以后的型号 必须使用 macOS El Capitan 10.11 及以后的版本 另外，虚拟机软件 VirtualBox 与 Docker Desktop 兼容性不佳，建议在安装 Docker for Windows 和 Docker for Mac 之前先卸载 VirtualBox。 在确认系统能够支持 Docker Desktop 之后，我们就从 Docker 官方网站下载这两个软件的安装程序，这里直接附上 Docker Store 的下载链接，供大家直接下载： Docker for Windows ( https://store.docker.com/editions/community/docker-ce-desktop-windows ) Docker for Mac ( https://store.docker.com/editions/community/docker-ce-desktop-mac ) 安装 Docker for Windows 和 Docker for Mac 的方法十分简单，按 Windows 或 macOS 常见的软件安装方式安装即可。 启动 Docker像 Linux 中一样，我们要在 Windows 和 macOS 中使用 Docker 前，我们需要先将 Docker 服务启动起来。在这两个系统中，我们需要启动的就是刚才我们安装的 Docker for Windows 和 Docker for Mac 了。 启动两个软件的方式很简单，我们只需要通过操作系统的快捷访问功能查找到 Docker for Windows 或 Docker for Mac 并启动即可。 打开软件之后，我们会在 Windows 的任务栏或者 macOS 的状态栏中看到 Docker 的大鲸鱼图标。 Docker for Windows 或 Docker for Mac 在启动时，这只大鲸鱼上的集装箱会一直闪动，这说明 Docker 程序正在部署 docker daemon 所需要的一些环境并执行 docker daemon 的启动。当集装箱不再闪动，就说明 Docker 服务已经准备就绪，我们就可以在 Windows 和 macOS 中使用 Docker 了。 Docker Desktop 为我们在 Windows 和 macOS 中使用 Docker 提供了与 Linux 中几乎一致的方法，我们只需要打开 Windows 中的 PowerShell 获得 macOS 中的 Terminal，亦或者 Git Bash、Cmder、iTerm 等控制台类软件，输入 docker 命令即可。 使用 docker version 能够看到 Docker 客户端的信息，我们可以在这里发现程序运行的平台： 12345λ docker versionClient:## ...... OS/Arch: windows/amd64## ...... Docker Desktop 的实现原理通过之前小节的介绍，我们知道 Docker 的核心功能，也就是容器实现，是基于 Linux 内核中 Namespaces、CGroups 等功能的。那么大体上可以说，Docker 是依赖于 Linux 而存在的。那么问题来了，Docker Desktop 是如何实现让我们在 Windows 和 macOS 中如此顺畅的使用 Docker 的呢？ 其实 Docker Desktop 的实现逻辑很简单：既然 Windows 和 macOS 中没有 Docker 能够利用的 Linux 环境，那么我们生造一个 Linux 环境就行啦！Docker for Windows 和 Docker for Mac 正是这么实现的。 由于虚拟化在云计算时代的广泛使用，Windows 和 MacOS 也将虚拟化引入到了系统本身的实现中，这其中就包含了之前我们所提到的通过 Hypervisor 实现虚拟化的功能。在 Windows 中，我们可以通过 Hyper-V 实现虚拟化，而在 macOS 中，我们可以通过 HyperKit 实现虚拟化。 Docker for Windows 和 Docker for Mac 这里利用了这两个操作系统提供的功能来搭建一个虚拟 Linux 系统，并在其之上安装和运行 docker daemon。 除了搭建 Linux 系统并运行 docker daemon 之外，Docker Desktop 系列最突出的一项功能就是我们能够直接通过 PowerShell、Terminal 这类的控制台软件在 Windows 和 macOS 中直接操作虚拟 Linux 系统中运行的 docker daemon。 实现这个功能得益于 docker daemon 对外提供的操作过程并不是复杂且领域性强的 IPC 等方式，而是通用的 RESTful Api 的形式。也就是说，Docker Desktop 只要实现 Windows 和 macOS 中的客户端，就能够直接利用 Hypervisor 的网络支持与虚拟 Linux 系统中的 docker daemon 进行通讯，并对它进行控制。 这其实就是我们之前所提到 docker daemon 使用 RESTful Api 作为控制方式的优势体现了。 主机文件挂载控制能够直接在主机操作系统中进行，给我们使用 Docker Desktop 系列软件提供了极大的方便。除此之外，文件的挂载也是 Docker Desktop 所提供的大幅简化我们工作效率且简化使用的功能之一。 之前我们谈到了，Docker 容器中能够通过数据卷的方式挂载宿主操作系统中的文件或目录，宿主操作系统在 Windows 和 macOS 环境下的 Docker Desktop 中，指的是虚拟的 Linux 系统。 当然，如果只能从虚拟的 Linux 系统中进行挂载，显然不足以达到我们的期望，因为最方便的方式必然是直接从 Windows 和 macOS 里挂载文件了。 要实现我们所期望的效果，也就是 Docker 容器直接挂载主机系统的目录，我们可以先将目录挂载到虚拟 Linux 系统上，再利用 Docker 挂载到容器之中。这个过程被集成在了 Docker Desktop 系列软件中，我们不需要人工进行任何操作，整个过程已经实现了自动化。 Docker Desktop 对 Windows 和 macOS 到虚拟 Linux 系统，再到 Docker 容器中的挂载进行了实现，我们只需要直接选择能够被挂载的主机目录 ( 这个过程更多也是为了安全所考虑 )，剩下的过程全部由 Docker Desktop 代替我们完成。这相比于普通虚拟机软件进行挂载的过程来说，完全不能用百倍效率来比较了。 配置 Docker Desktop在我们使用 Docker Desktop 系列之前，我们还会简单修改其的一些配置，以便更好的合理搭配操作系统与 Docker Desktop 系列软件。 我们可以通过 Docker for Windows 或 Docker for Mac 的大鲸鱼图标打开配置页面：在大鲸鱼弹出的菜单中选择 Settings ( Windows ) 或 Preferences ( macOS )。 打开 Docker for Windows 和 Docker for Mac 的配置页面后，我们可以发现几个配置页面。这里我不逐一把每个页面进行截图了，大家可以自己动手查看页面每个页面的内容。 Docker for Windows 和 Docker for Mac 的配置项目较 Docker Engine 来说要多上许多，这主要是因为 Docker Desktop 是 Docker Engine 的超集，所以其不仅包含了 Docker Engine 的配置内容，还要包含诸如虚拟机实现等其他配置。 我这里抽出几个与 Docker 相关的关键配置，分别简单说明它们的作用： 文件系统挂载配置在 Docker for Windows 的 Shared Drivers 面板，以及在 Docker for Mac 中的 File Sharing 面板中，包含了我们之前提到的将本机目录挂载到 Hypervisor 里 Linux 系统中的配置。 资源控制配置在 Advanced 面板中，我们可以调整 Docker 最大占用的本机资源。当然，更准确的说我们是在调整虚拟 Linux 环境所能占用的资源，是通过这个方式影响 Docker 所能占用的最大资源。 网络配置在 Docker for Windows 的 Network 面板，以及在 Docker for Mac 中的 Advanced 面板中，我们可以配置 Docker 内部默认网络的子网等内容。这个网络的作用以及更详细的内容，我们会在之第 9 节中进行讲解。 docker daemon 配置在 Daemon 面板里，我们可以直接配置对 docker daemon 的运行配置进行调整。默认情况下，在 Daemon 面板里只有 Insecure registries 和 Registry mirrors 两个配置，分别用来定义未认证镜像仓库地址和镜像源地址。 我们可以点击切换按钮切换到 Advanced 模式，在这个模式下，我们可以直接编辑 docker daemon 的 daemon.json 配置文件，实现更具体、完整的配置 docker daemon 的目的。 低系统版本解决方案Docker Desktop 系列为我们在 Windows 和 macOS 中使用 Docker 提供了巨大的便利，几乎让我们可以在数分钟内搭建 Windows 和 macOS 中 Docker 的运行环境，并得到像 Linux 中使用 Docker 一样的体验。但 Docker Desktop 依然存在一定的局限性，其中最大的莫过于其对 Windows 和 macOS 的苛刻要求。虽然我们提倡保持操作系统的更新换代，以得到最新的功能以及更好的安全保障，但依然有很多情况下我们不得不使用低版本的 Windows 和 macOS。对于这种情况，Docker 官方也提供了相应的解决方案。 首先，让我们来聊聊为什么 Docker for Windows 和 Docker for Mac 会对操作系统有如此严苛的要求。其实原因很简单，刚才我们谈到了，Docker for Windows 和 Docker for Mac 的实现分别依靠了 Windows 中的 Hyper-V 和 macOS 中的 HyperKit，而这两个虚拟化工具只在高版本的 Windows 和 macOS 系统中才提供出来。 既然知道了原因，解决方案自然也就有了，既然我们不能利用 Hyper-V 或 HyperKit 来创建虚拟的 Linux 系统，那就找一个能够替代它们的工具，用其创建虚拟 Linux 系统即可。 Docker ToolboxDocker 官方为我们找到了用于搭建虚拟 Linux 系统的软件，即 Oracle 的 VirtualBox，并以此封装了另一个集成的 Docker 运行环境软件：Docker Toolbox。 安装 Docker Toolbox 的过程也十分简单，下载安装包并按常规软件一样安装即可。这里直接我直接提供给大家 Docker Toolbox 安装包的连接，方便大家下载。 Docker Toolbox for Windows ( https://download.docker.com/win/stable/DockerToolbox.exe ) Docker Toolbox for Mac ( https://download.docker.com/mac/stable/DockerToolbox.pkg ) 安装完 Docker Toolbox 后，我们有几项与 Docker for Windows 和 Docker for Mac 不同的使用方法需要注意。 由于不能很好的与系统以及 VirtualBox 互通结合，我们启动、关闭、重启 Docker 服务不能完全实现自动化，所以这里 Docker 为我们提供了 Docker QuickStart Terminal 这个工具来处理这些过程。换个方式说，我们必须通过它来启动和操作 Docker，而不能再直接使用 PowerShell、Terminal 这类软件了。 另外一个不便之处就是文件系统的挂载，由于 Docker Toolbox 无法直接操作 VirtualBox 实现挂载，所以这个过程需要我们人工来进行。整个挂载的方式与我们之前谈到的一样，区别只是需要我们手动操作。将本机目录挂载到虚拟 Linux 系统中的配置在 VirtualBox 的 Settings 中，我们将本机需要挂载的目录配置进去并保存即可。 留言互动在这节中，在这一小节中我们掌握了如何在 Windows 和 macOS 安装 Docker Desktop 并进行配置，了解了 Docker Desktop 的实现原理。这里给大家留一道思考题： 除了在 Windows 或 macOS 中搭建虚拟的 Linux 系统来实现基于 Linux Container 运行 Docker 这种方式外，你是否还知道直接使用 Windows 或 macOS 本身的容器技术运行 Docker 的方法？尝试了解这些实现方式，说说它们背后的原理。 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker Desktop 的安装、配置还有内部实现还有什么不解，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%EF%BC%9A%E8%BF%99%E6%98%AF%20Docker%20%E7%9A%84%E7%AE%80%E5%8E%86%2F</url>
    <content type="text"><![CDATA[这是 Docker 的简历在了解虚拟化和容器技术后，我们就更容易理解 Docker 的相关知识了。在这一小节中，我将介绍关于 Docker 的出现和发展，Docker 背后的技术。同时，我们将阐述 Docker 在虚拟化领域中的定位以及其带来的变革。 Docker 开源项目如果说 Docker 的诞生，就必须从 Docker 这个开源项目提起 ( 虽然它现在已经不叫 Docker 了 )。Docker 项目是一个由 Go 语言实现的容器引擎，它最初由 dotCloud 这家做云服务的公司在 2013 年开源。 由于 Docker 带来的巨大的便利，让很多开发、测试和运维等软件开发环节上的工作被简化甚至省去，所以在短短的几年间便成为虚拟化乃至整个技术领域的热词。同时，许多开发者乃至大型科技企业都参与到了 Docker 相关领域的贡献中来，为 Docker 及其生态圈贡献了许多优秀的软件项目，这大大提高了 Docker 生态的完整性，也让 Docker 日益健壮。 也许 dotCloud 自己也没有想到，云服务没卖出几个钱，反倒是 Docker 越来越火。拥有商业头脑的他们，干脆不再做云服务了，也把公司名字改成 Docker Inc. 专门从事 Docker 周边的生意。 当然，Docker 的商业化也带来了一定的变化。为了更好的进行商业运作，Docker Inc. 将 Docker 开源项目的名称修改为了 Moby，所以大家要是在 GitHub 上没有搜索到 Docker 不要觉得惊讶，因为它现在的名字是 Moby ( https://github.com/moby/moby )。 关于 Moby 和 Docker 更多的内容，这里给大家提供一下参考资料，有兴趣的朋友们可以前往阅读： Docker改名啦？什么是 Moby Project 对于 Docker 改名 Moby ，大家怎么看？ Introducing Moby Project Docker 所带来的改变简单说了一些 Docker 的故事，接来下我们就必须重点说一下 Docker 所带来的改变。正是这些对我们工作方式的改变，让我们越来越难以离开 Docker，又源于我们对 Docker 如此的喜爱，让 Docker 能够在短时间内就从雏鸟成长为大鹏，成为万众瞩目的新星。 云计算时代的挑战在计算机技术发展的早期，几乎所有的程序都是在开发后部署到一台或是少数几台服务器上的。那时的程序也几乎都是集所有模块和运行时环境为一身的“全栈应用”，虽然这些程序可以基于一套良好、完善的协议栈 ( 譬如一套完整的 MVC 架构 ) 进行开发，但再好的架构也无法让应用服务在这种体系下快速发展。 随着互联网的极速发展，应用程序的功能越来越丰富，而需要迭代的速度要求也越来越高，为了实现这些目标，应用的开发逐渐趋向服务化甚至微服务化。每个应用程序都有其对应依赖的操作系统或者其他程序，而在将应用程序细分为不同的微服务或者是其他形式的微小应用模块后，解决这种依赖问题会愈发显得棘手。有的应用运行环境特别复杂，搭建过程也极易出错，这都是让开发、测试、运维人员焦头烂额的地方。更多时候，开发者们肯定更愿意将他们宝贵的时间用在实际的开发中，而不是纠缠着应用运行环境的问题上。 同时，由于物理硬件的更新迭代速度已经难以追赶互联网的脚步，应用的部署逐渐转向集群化。应用模块的数量乘上每个应用所部署的机器的数量，会是一个非常庞大的数字。相信所有的开发或者运维都不会愿意把时间浪费在逐一搭建服务器环境这种重复的劳动上。 这些变化都对应用的开发、部署带来了不小的挑战。 我想很多读者已经想到了应对这些挑战的办法了，没错，那就是虚拟化技术。通过虚拟化技术可以让环境的搭建变得更加的容易，对我们快速部署分布式应用服务体系提供了极大的便利。 进而言之，如果我们把管理环境的复杂度，更轻量级的虚拟化实现等更加实际的问题考虑进去，容器技术自然成了虚拟化技术中最佳的选择项。 皆为效率如果说在分布式部署中应用容器技术是一个方向，那么 Docker 就是在这个方向上跑得最快也最完美的运动员了。Docker 不论从实现容器技术的完整性上来说，还是从上手易用性来说，都是可圈可点的。 好了，这里我要穿插一下推荐 Docker 的原因了。我们使用 Docker 的目的其实很简单，就是利用它的全面性和易用性带来的提升我们的工作效率。了解了这个目的，我想大家会更容易理解很多场合 Docker 能派上用场的原因。当然，通过这个道理，你也就明白了为什么我会说 Docker 是一门新时代开发者必须掌握的技术了。毕竟所有的老板都希望找到会得多、干活快的优秀开发者 ( 亦或者说，会的多、干活快是优秀开发者所必备的品质 )。 再怎么从理论上说快也是很难服众的，是骡子是马拉出来“跑个分”就知道了。Docker 官方对 Docker 在工作上带来的提升做了调查研究，分别从工作效率的提升和技术设计投入的减少等方面数据化了 Docker 所做出的突出贡献。 相信看到这些数据，你已经明白为何 Docker 备受关注的原因了。 Docker 的技术实现这里我们再简单了解一下 Docker 的技术实现，以便有探索欲望的读者查找相关资料进行深入阅读。 Docker 的实现，主要归结于三大技术：命名空间 ( Namespaces ) 、控制组 ( Control Groups ) 和联合文件系统 ( Union File System ) 。 Namespace命名空间是 Linux 核心在 2.4 版本后逐渐引入的一项用于运行隔离的模块。 相信很多开发者在不同的编程语言中都见过命名空间的概念，在这些编程语言中，命名空间的主要目的就是为了集合相同模块的类，区分不同模块间的同名类。 同样的道理，Linux 内核的命名空间，就是能够将计算机资源进行切割划分，形成各自独立的空间。 就实现而言，Linux Namespaces 可以分为很多具体的子系统，如 User Namespace、Net Namespace、PID Namespace、Mount Namespace 等等。 这里我们以进程为例，通过 PID Namespace，我们可以造就一个独立的进程运行空间，在其中进程的编号又会从 1 开始。在这个空间中运行的进程，完全感知不到外界系统中的其他进程或是其他进程命名空间中运行的进程。 利用 PID Namespace，Docker 就实现了容器中隔离程序运行中进程隔离这一目标。 Control Groups资源控制组 ( 常缩写为 CGroups ) 是 Linux 内核在 2.6 版本后逐渐引入的一项对计算机资源控制的模块。 顾名思义，资源控制组的作用就是控制计算机资源的。与以隔离进程、网络、文件系统等虚拟资源为目的 Namespace 不同，CGroups 主要做的是硬件资源的隔离。 之前我们提到了，虚拟化除了制造出虚拟的环境隔离同一物理平台运行的不同程序之外，另一大作用就是控制硬件资源的分配，CGroups 的使用正是为了这样的目的。 需要再强调一次的是，CGroups 除了资源的隔离，还有资源分配这个关键性的作用。通过 CGroups，我们可以指定任意一个隔离环境对任意资源的占用值或占用率，这对于很多分布式使用场景来说是非常有用的功能。 例如，我们在服务器上部署一个业务服务和一个健康监控服务。通常情况下，监控服务只会占用很少的计算机资源，但我们无法保证其不会因为一些逻辑问题产生 Bug 进而过分消耗计算机资源。而它申请的计算机资源越多，意味着业务服务所能使用的计算机资源也就越少，最后甚至可能造成物理服务器的崩溃。 上述的问题在没有隔离实现的普通运行环境下是比较难解决的，因为所有不从系统层面出发的限制程序资源使用的方式都并不完全有效。由于 CGroups 实现于操作系统，而操作系统垄断着系统资源的分配，所以其完全能够限制隔离环境下应用的资源占有量。 Union File System联合文件系统 ( Union File System ) 是一种能够同时挂载不同实际文件或文件夹到同一目录，形成一种联合文件结构的文件系统。联合文件系统本身与虚拟化并无太大的关系，但 Docker 却创新的将其引入到容器实现中，用它解决虚拟环境对文件系统占用过量，实现虚拟环境快速启停等问题。 在 Docker 中，提供了一种对 UnionFS 的改进实现，也就是 AUFS ( Advanced Union File System )。 AUFS 将文件的更新挂载到老的文件之上，而不去修改那些不更新的内容，这就意味着即使虚拟的文件系统被反复修改，也能保证对真实文件系统的空间占用保持一个较低水平。 也许这个表述还不够形象，那么我们来用 Git 进行比较，会让大家会更容易理解。大家知道，我们在 Git 中每进行一次提交，Git 并不是将我们所有的内容打包成一个版本，而只是将修改的部分进行记录，这样即使我们提交很多次后，代码库的空间占用也不会倍数增加。 同样的，通过 AUFS，Docker 大幅减少了虚拟文件系统对物理存储空间的占用。由此，Docker 也开创出了虚拟化领域很多新的轻量级解决方案，这在之后的小节里我们会提到。 Docker 的理念在对 Docker 及其背后的一些技术有了一个初步了解之后，我们还要着重说一下 Docker 本身的一些设计理念。如果说熟悉 Docker 背后的技术能够更好的帮助你正确使用 Docker，那么理解 Docker 的理念将更好的指导你如何搭配 Docker 容器间的关系。 让我们先来从一张 Docker 官方提供的架构图来看看 Docker 对容器结构的设计。 与其他虚拟化实现甚至其他容器引擎不同的是，Docker 推崇一种轻量级容器的结构，即一个应用一个容器。 举个具体的例子，在常见的虚拟机实现中，我们要搭建一套 LAMP 结构的服务，我们通常会建立一个虚拟机，在虚拟机中安装上 Linux 系统，之后分别安装 Apache、MySQL 和 PHP。而在 Docker 里，最佳的实践是分别基于 Apache、MySQL 和 PHP 的镜像建立三个容器，分别运行 Apache、MySQL 和 PHP ，而它们所在的虚拟操作系统也直接共享于宿主机的操作系统。 如果我们将 Docker 的轻量级容器实现和虚拟机的一些参数进行对比，更容易得到结果。 属性 Docker 虚拟机 启动速度 秒级 分钟级 硬盘使用 MB 级 GB 级 性能 接近原生 较低 普通机器支撑量 数百个 几个 虽然这里只列出了一些 Docker 的优势项，但这些优势都是对我们开发中环境搭建和使用极其有帮助的内容。就拿启动速度来说，我们在开发中显然不愿意调整环境或更新代码后要等待几分钟来让其生效，Docker 秒级的启动速度几乎让我们感知不到我们对环境做了什么改动。而像虚拟机占用大量操作系统资源，导致我们本地开发使用电脑过慢 ( 有时候不得不将环境搭建在另外的机器上，但这显然在代码编写到运行自测的过程中增加很多工作量 ) 等问题，也容易得到解决。 当然，在 Docker 中能实现这样的设计理念，还要归功于几项基础设施的支持。 首先，只有在容器技术的支撑下，应用即容器的方案才能有效的实施。因为容器技术既剔除了 Hypervisor 层，又干掉了虚拟操作系统的概念，让容器中应用运行的消耗与真实操作系统中运行的消耗几乎完全一致。只有这样，我们才能像在真实操作系统中开启应用一样开启新的容器，而不用过分担心虚拟化带来的性能消耗。 其次，基于联合文件系统的底层文件系统支持，让容器能够很容易在真实操作系统中共享存储资源，并由此带来了对存储空间的低消耗。与动辄就要独立开辟十几 GB 甚至几十 GB 的虚拟化实现相比，要存在巨大的优势。 当然，Docker 也支持你在容器中同时运行很多种程序，但其容器设计本身并不针对这种方案，所以如果你以这种方案在 Docker 中搭建环境，你会花费不少时间做出一些本来并不需要做的事情。虽然这看上去动手性很强，但我并不推荐在工作中这么去做，因为我们使用 Docker 本身就是为了效率，浪费时间在这些不必要的事情上，已经违背了我们使用 Docker 的初衷。 我们能用 Docker 做些什么从理论上我们已经知道 Docker 能够为我们的工作带来巨大的便利，那么将其放于实践中，我们应该如何正确的使用它呢？这里我摘录整理了一段来自 Docker 官方文档的指导意见，希望能够对大家的实践提供参考。 更快、更一致的交付你的应用程序使用 Docker 后，开发者能够在本地容器中得到一套标准的应用或服务的运行环境，由此可以简化开发的生命周期 ( 减少在不同环境间进行适配、调整所造成的额外消耗 )。对于整个应用迭代来说，加入 Docker 的工作流程将更加适合持续集成 ( Continuous Integration ) 和持续交付 ( Continuous Delivery )。 举个具体的例子： 开发者能够使用 Docker 在本地编写代码并通过容器与其他同事共享他们的工作。 他们能够使用 Docker 将编写好的程序推送至测试环境进行自动化测试或是人工测试。 当出现 Bugs 时，开发者可以在开发环境中修复它们，并很快的重新部署到测试环境中。 在测试完成后，部署装有应用程序的镜像就能完成生产环境的发布。 跨平台部署和动态伸缩基于容器技术的 Docker 拥有很高的跨平台性，Docker 的容器能够很轻松的运行在开发者本地的电脑，数据中心的物理机或虚拟机，云服务商提供的云服务器，甚至是混合环境中。 同时，Docker 的轻量性和高可移植性能够很好的帮助我们完成应用的动态伸缩，我们可以通过一些手段近实时的对基于 Docker 运行的应用进行弹性伸缩，这能够大幅提高应用的健壮性。 让同样的硬件提供更多的产出能力Docker 的高效和轻量等特征，为替代基于 Hypervisor 的虚拟机提供了一个经济、高效、可行的方案。在 Docker 下，你能节约出更多的资源投入到业务中去，让应用程序产生更高的效益。同时，如此低的资源消耗也说明了 Docker 非常适合在高密度的中小型部署场景中使用。 留言互动在这节中，我们溯源 Docker 的历史，从其诞生的背景和其解决的问题出发，阐述了 Docker 背后的技术和 Docker 本身的设计理念。这里给大家留一道思考题： Docker 所提倡的轻量级虚拟化与其他虚拟化实现中的完整操作系统虚拟化有什么样的优势，其优势又能应用到哪些实际的场景中去呢？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker 的发展历史，Docker 背后的技术或者 Docker 所推崇的理念还有不解之处，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%EF%BC%9A%E6%B5%85%E8%B0%88%E8%99%9A%E6%8B%9F%E5%8C%96%E5%92%8C%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[浅谈虚拟化和容器技术相信所有对 Docker 有所耳闻的朋友都知道，它是一款以容器虚拟化技术为基础的软件，因此在了解有关 Docker 的概念知识和使用方法之前，虚拟化和容器技术是我们不可或缺的基础知识。在本小册的第一个小节里，我们就先来尝一尝这道有关虚拟化和容器技术的开胃菜吧。 虚拟化技术如果要用简单的语句来阐述虚拟化技术的话，那么可以这么解释： 虚拟化技术是一种将计算机物理资源进行抽象、转换为虚拟的计算机资源提供给程序使用的技术。 这里所指的计算机资源，就包括了 CPU 提供的运算控制资源，硬盘提供的数据存储资源，网卡提供的网络传输资源等。 为程序跨平台兼容而生虚拟化这个概念并不是什么新事物了，早在 20 世纪 60 年代，IBM 就用它来描述一套能够抽象硬件资源的实验性系统。 在计算机技术发展的早期，各类计算平台、计算资源所提供的接口、调用方式十分杂乱，没有像今天这样相对统一的标准。由于要适配不同的平台，写各种兼容代码，这无形给开发者带来了很多的困扰。这种混乱甚至都出现在 IBM 这一家公司下不同机型的机器上，所以 IBM 的工程师们创造了虚拟化技术，用来帮助程序快速适配不同平台的物理机器。 熟悉计算机原理的朋友应该知道，程序对计算机资源的调用主要依赖于操作系统所给出的接口。我们的程序通过操作系统提供的接口，向物理硬件发送指令。 所以，要实现程序跨平台兼容的方法其实很简单，只要操作系统或者物理硬件所提供的接口调用方式一致，程序便不需要兼容不同硬件平台的接口，而只需要针对这一套统一的接口开发即可。虚拟化技术正是通过其本身适配不同平台的硬件，而加以抽象成统一的接口，来实现程序跨平台运行这一目的的。 时至今日，我们之所以关注和使用虚拟化技术，实现跨平台运行应用程序依然是很大一部分的原因。 将虚拟化应用于资源管理在虚拟化技术的发展过程中，人们逐渐发现了虚拟化的另一大用途，也就是将之应用于计算机资源的管理。 这其中的道理其实并不复杂，虚拟化技术本身就是抽象计算机的物理资源进而加工成虚拟的计算资源的，它自然很容易从中做“手脚”，来告诉应用程序一些虚假的资源数据。例如，我们只要告诉程序计算机只有 4GB 内存，那么不管真实的物理机是 8GB、16GB 还是 32GB，应用程序都会按照 4GB 这个虚假的值来处理它的逻辑。 通过虚拟化技术来管理计算机资源的方式，不但让我们对计算机资源的控制变得更加灵活，也大幅提高了计算机资源的使用率。 部分同学一直有一个误解：实现虚拟化的程序本身就要占用计算机的资源，而运转在其中的程序也不会降低它们对资源的消耗，怎么又会产生 1 + 1 &lt; 2 的效果呢。 这里要注意了，我们所说的是提高计算机资源使用率，而非减少程序资源的占用率，这两者看似很相近，其实并非是同一个概念。虚拟化技术能够提高计算机资源的使用率，是指利用虚拟化，我们可以将原来程序用不到的一些资源拿出来，分享给另外一些程序，让计算机资源不被浪费。 例如，这里我们有一台运行 Nginx 的机器，由于 Nginx 运行对系统资源的消耗并不高，这就让系统几乎 95% 以上的资源处于闲置状态。这时候我们通过虚拟化技术，把其他的一些程序放到这台机器上来运行，它们就能够充分利用闲置的资源。这带来的好处就是我们不需要再为这些程序单独部署机器，从而节约不少的成本。 部分读者读到这里就会产生疑惑了，我本身就可以在操作系统里安装这些程序并且同时运行，为什么还要把它们分别装到不同的虚拟环境中去呢？ 其实道理很简单，虽然我们能够在操作系统里同时运行多个程序，但前提得是这些程序本身不存在冲突。这里的冲突体现在很多的方面，例如不同的程序同时使用了同一个端口；不同程序依赖于同一个工具库的不同版本；程序本身限制了同时开启的进程数等。虚拟化技术通过资源隔离的方式，无形地也可以把这些程序隔离在不同的虚拟环境中，既然虚拟环境不同，自然运行在不同环境中的程序就不会互相干扰或争抢资源了。 虚拟化的分类说完虚拟化的起源和应用，我们得说说虚拟化的分类了。所谓虚拟化的分类，其实主要指的是我们在实现虚拟化的方式上的区别。 对于虚拟化技术的分类，有很多种不同的方式，有的之间也有互相重合的部分，但总体来说可以区分为两大类：硬件虚拟化、软件虚拟化。 所谓硬件虚拟化，指的是物理硬件本身就提供虚拟化的支持。举个例子来说，某个平台的 CPU，能够将另外一个平台的指令集转换为自身的指令集执行，并给程序完全运行在那个平台上的感觉。又或者说，CPU 能够自身模拟裂变，让程序或者操作系统认为存在多个 CPU，进而能够同时运行多个程序或者操作系统。这些都是硬件虚拟化的体现。 而软件虚拟化则指的是通过软件的方式来实现虚拟化中关键的指令转换部分。依然用 CPU 的例子来说话，在软件虚拟化实现中，通过一层夹杂在应用程序和硬件平台上的虚拟化实现软件来进行指令的转换。也就是说，虽然应用程序向操作系统或者物理硬件发出的指令不是当前硬件平台所支持的指令，这个实现虚拟化的软件也会将之转换为当前硬件平台所能识别的。 当然，在实际场景中，虚拟化还能进行更加细化的分类，例如： 平台虚拟化：在操作系统和硬件平台间搭建虚拟化设施，使得整个操作系统都运行在虚拟后的环境中。 应用程序虚拟化：在操作系统和应用程序间实现虚拟化，只让应用程序运行在虚拟化环境中。 内存虚拟化：将不相邻的内存区，甚至硬盘空间虚拟成统一连续的内存地址，即我们常说的虚拟内存。 桌面虚拟化：让本地桌面程序利用远程计算机资源运行，达到控制远程计算机的目的。 …… 由于虚拟化的分类实在太多，且不是这本小册关注的重点，这里就不全部罗列了。总之，从实现上来说，皆是硬件虚拟化和软件虚拟化两个方案的相互组合、组装而得。 虚拟机在这些虚拟化分类或者说是虚拟化实现中，我们要着重讲一下虚拟机 ( Virtual Machine )。所谓虚拟机，通常来说就是通过一个虚拟机监视器 ( Virtual Machine Monitor ) 的设施来隔离操作系统与硬件或者应用程序和操作系统，以此达到虚拟化的目的。这个夹在其中的虚拟机监视器，常常被称为 Hypervisor。 之所以我们在这里单独谈谈虚拟机，是因为它对于我们开发者来说是个再熟悉不过的概念了。从我们习惯用来搭建虚拟操作系统环境的 VMware Workstation、Xen 等软件，到 Java 虚拟机 JVM，PHP 虚拟机 HHVM 等等，都充活跃在我们程序开发到程序运行的过程中。 这时候有的读者可能会眼前一亮，发现原来 JVM、HHVM 等特定语言运行环境中的核心部分，也是虚拟化的一种实实在在的实现。没错，只要大家仔细分析和思考一下就会发现，它们正是基于虚拟化的思想来实现的。它们通过隔离程序和操作系统，将程序的指令转换为当前所在操作系统平台所能执行的指令，达到了不用对程序进行任何修改即可执行的目的。也正是这个原因，这些语言的程序都具有非常强的跨平台性。 虽然虚拟机技术得益于 Hypervisor 的加持，使得应用程序或者操作系统可以在无任何修改的情况下运行在另一平台上，但大家很容易发现，其有一个致命的缺陷，就是所有的指令都必须经过虚拟机监视器的处理。这也就意味着，虚拟机的性能是低下的，例如运行在 ZendVM 或者 HHVM 中的 PHP 程序，所有代码虽然编译成了 Opcode 码，但其依然是通过虚拟机才最终转换为机器所能识别的机器码去执行。 这种效率的低下有时候是无法容忍的，为了解决这个问题，真实的虚拟机程序常常不完全遵循 Hypervisor 的设计结构，而是引入一些其他技术来解决效率问题。 例如，在 VMware Workstation、Xen 中我们能够看到硬件辅助虚拟化的使用，通过让指令直达支持虚拟化的硬件，以此避开了效率低下的 Hypervisor。而如 JRE、HPHP 中，除了基于 Hypervisor 实现的解释执行机制外，还有即时编译 ( Just In Time ) 运行机制，让程序代码在运行前编译成符合当前硬件平台的机器码，这种方式就已经不属于虚拟化的范畴了。 容器技术容器技术是一种全新意义上的虚拟化技术，按分类或者实现方式来说，其应该属于操作系统虚拟化的范畴，也就是在由操作系统提供虚拟化的支持。 所谓容器技术，指的是操作系统自身支持一些接口，能够让应用程序间可以互不干扰的独立运行，并且能够对其在运行中所使用的资源进行干预。当然，目前来说容器技术还没有一个严格的定义，其实现方式也各有不同，所以这里只能算是我的一点小小总结归纳。 由于应用程序的运行被隔离在了一个独立的运行环境之中，这个独立的运行环境就好似一个容器，包裹住了应用程序，这就是容器技术名字的由来。 容器技术近年来已经是一个火遍大江南北的概念了，其之所以能名声大噪，很重要的一个原因是其在运行性能上要远超虚拟机等其他虚拟化实现。更甚一步说，运行在容器虚拟化中的应用程序，在运行效率上与真实运行在物理平台上的应用程序不相上下。 为什么容器技术能够造就近乎完美的运行效率呢？这就得从容器技术如何实现应用程序的指令转换开始说起。下面这张图展示了容器技术如何进行指令转换的。 … 实在无奈，没有找到容器技术进行指令转换的图片，因为容器技术压根没有做指令转换。是的，你没有听错，有时候解决问题的最佳方法就是不解决它。 由于没有指令转换，运行在容器中的应用程序自身必须支持在真实操作系统上运行，也就是必须遵循硬件平台的指令规则。 很多同学这时候就有疑问了，指令都不转换，也没有解决程序跨平台兼容的问题，这算哪门子虚拟化技术。 没错，正是这种原因，很多人并不认同容器技术属于虚拟化技术的范畴。不过另一派观点认为，容器技术提供了相对独立的应用程序运行的环境，也提供了资源控制的功能，所以我们依然可以归纳其为一种实现不完全的虚拟化技术。 虚拟机 VS 容器这里我们直接通过虚拟机和容器技术的剖析图来分析，就更容易看出容器虚拟化是如何在效率上完胜虚拟机的。 由于没有了虚拟操作系统和虚拟机监视器这两个层次，大幅减少了应用程序运行带来的额外消耗。 更准确的来说，所有在容器中的应用程序其实完全运行在了宿主操作系统中，与其他真实运行在其中的应用程序在指令运行层面是完全没有任何区别的。 留言互动在阅读完这一小节后，相信你对虚拟化和容器技术已经有了初步的认识，这里给大家留一道思考题： 通过容器技术与其他常见的虚拟化技术 ( 例如虚拟机 ) 实现各自的优势和劣势，说说它们各自有怎样的适用场景。 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对虚拟化技术、容器技术等还有不甚了解之处，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%EF%BC%9A%E4%BA%86%E8%A7%A3%20Docker%20%E7%9A%84%E6%A0%B8%E5%BF%83%E7%BB%84%E6%88%90%2F</url>
    <content type="text"><![CDATA[了解 Docker 的核心组成在掌握 Docker 的一些背景知识后，我们还不得不花费一节的篇幅来简单介绍有关 Docker 核心的一些知识。当然，大家不要觉得有“核心”这类的词，我们就要在这一节中深入 Docker 底层去讲解原理性的东西，更确切的说这一节更像一张词汇表，在掌握这些与 Docker 紧密相关的词汇后，大家可以更好的理解之后小节中的内容。 四大组成对象在之前的小节里，我们提到了 Docker 实现容器引擎的一些技术，但那些都是一些相对底层的原理实现，在 Docker 将它们封装后，我们并不会直接操作它们。在 Docker 中，另外提供出了一些软件层面的概念，这才是我们操作 Docker 所针对的对象。 在 Docker 体系里，有四个对象 ( Object ) 是我们不得不进行介绍的，因为几乎所有 Docker 以及周边生态的功能，都是围绕着它们所展开的。它们分别是：镜像 ( Image )、容器 ( Container )、网络 ( Network )、数据卷 ( Volume )。 镜像镜像 ( Image ) 这个概念相信大家不会陌生，因为它是其他虚拟化技术 ( 特别是虚拟机 ) 中常常被使用的一个概念。所谓镜像，可以理解为一个只读的文件包，其中包含了虚拟环境运行最原始文件系统的内容。 当然，Docker 的镜像与虚拟机中的镜像还是有一定区别的。首先，之前我们谈到了 Docker 中的一个创新是利用了 AUFS 作为底层文件系统实现，通过这种方式，Docker 实现了一种增量式的镜像结构。 每次对镜像内容的修改，Docker 都会将这些修改铸造成一个镜像层，而一个镜像其实就是由其下层所有的镜像层所组成的。当然，每一个镜像层单独拿出来，与它之下的镜像层都可以组成一个镜像。 另外，由于这种结构，Docker 的镜像实质上是无法被修改的，因为所有对镜像的修改只会产生新的镜像，而不是更新原有的镜像。 容器容器 ( Container ) 就更好理解了，在容器技术中，容器就是用来隔离虚拟环境的基础设施，而在 Docker 里，它也被引申为隔离出来的虚拟环境。 如果把镜像理解为编程中的类，那么容器就可以理解为类的实例。镜像内存放的是不可变化的东西，当以它们为基础的容器启动后，容器内也就成为了一个“活”的空间。 用更官方的定义，Docker 的容器应该有三项内容组成： 一个 Docker 镜像 一个程序运行环境 一个指令集合 关于镜像与容器的更多细节知识，我们在后面的小节中还会单独进行讲解。 网络对于大部分程序来说，它们的运行都不会是孤立的，而是要与外界或者更准确的说是与其他程序进行交互的，这里的交互绝大多数情况下指的就是数据信息的交换。网络通讯是目前最常用的一种程序间的数据交换方式了。 由于计算机网络领域拥有相对统一且独立的协议等约定，其跨平台性非常优秀，所有的应用都可以通过网络在不同的硬件平台或操作系统平台上进行数据交互。特别是在分布式云计算的时代，应用或服务间的通讯更是充分依赖于网络传输，所以自然拥有一套完善的网络体系支撑，是承载应用运行所必须的基础设施。 在 Docker 中，实现了强大的网络功能，我们不但能够十分轻松的对每个容器的网络进行配置，还能在容器间建立虚拟网络，将数个容器包裹其中，同时与其他网络环境隔离。 另外，利用一些技术，Docker 能够在容器中营造独立的域名解析环境，这使得我们可以在不修改代码和配置的前提下直接迁移容器，Docker 会为我们完成新环境的网络适配。对于这个功能，我们甚至能够在不同的物理服务器间实现，让处在两台物理机上的两个 Docker 所提供的容器，加入到同一个虚拟网络中，形成完全屏蔽硬件的效果。 正是因为拥有强大的网络功能，才能让我们制造健壮的 Docker 应用体系。 数据卷除了网络之外，文件也是重要的进行数据交互的资源。在以往的虚拟机中，我们通常直接采用虚拟机的文件系统作为应用数据等文件的存储位置。然而这种方式其实并非完全安全的，当虚拟机或者容器出现问题导致文件系统无法使用时，虽然我们可以很快的通过镜像重置文件系统使得应用快速恢复运行，但是之前存放的数据也就消失了。 为了保证数据的独立性，我们通常会单独挂载一个文件系统来存放数据。这种操作在虚拟机中是繁琐的，因为我们不但要搞定挂载在不同宿主机中实现的方法，还要考虑挂载文件系统兼容性，虚拟操作系统配置等问题。值得庆幸的是，这些在 Docker 里都已经为我们轻松的实现了，我们只需要简单的一两个命令或参数，就能完成文件系统目录的挂载。 能够这么简单的实现挂载，主要还是得益于 Docker 底层的 Union File System 技术。在 UnionFS 的加持下，除了能够从宿主操作系统中挂载目录外，还能够建立独立的目录持久存放数据，或者在容器间共享。 在 Docker 中，通过这几种方式进行数据共享或持久化的文件或目录，我们都称为数据卷 ( Volume )。 Docker Engine时至今日，Docker 生态已经远比它诞生之初要庞大许多，虽然我们仍然习惯使用 Docker 这个名字去指代实现容器技术支持的软件，但显然更加容易与其他的概念产生混淆。这里我们很有必要对这个 Docker 中最核心的软件进行介绍，不仅因为它在 Docker 生态中扮演着中心的地位，也因为它是我们在开发中实实在在接触最多的东西。 目前这款实现容器化的工具是由 Docker 官方进行维护的，Docker 官方将其命名为 Docker Engine，同时定义其为工业级的容器引擎 ( Industry-standard Container Engine )。在 Docker Engine 中，实现了 Docker 技术中最核心的部分，也就是容器引擎这一部分。 docker daemon 和 docker CLI虽然我们说 Docker Engine 是一款软件，但实实在在去深究的话，它其实算是由多个独立软件所组成的软件包。在这些程序中，最核心的就是 docker daemon 和 docker CLI 这俩了。 所有我们通常认为的 Docker 所能提供的容器管理、应用编排、镜像分发等功能，都集中在了 docker daemon 中，而我们之前所提到的镜像模块、容器模块、数据卷模块和网络模块也都实现在其中。在操作系统里，docker daemon 通常以服务的形式运行以便静默的提供这些功能，所以我们也通常称之为 Docker 服务。 在 docker daemon 管理容器等相关资源的同时，它也向外暴露了一套 RESTful API，我们能够通过这套接口对 docker daemon 进行操作。或者更确切的说，是通过这套 RESTful API 对 docker daemon 中运行的容器和其他资源进行管理。 通常来说，我们是采用在控制台或者命令行输入命令来控制 docker daemon 的，因为这样很酷也更容易适应那些有或者没有图形界面的操作系统。 那么问题来了，如果我们在控制台中编写一个 HTTP 请求以借助 docker daemon 提供的 RESTful API 来操控它，那显然是个费脑、费手又费时间的活儿。所以在 Docker Engine 里还直接附带了 docker CLI 这个控制台程序。 熟悉程序结构的朋友们比较容易看出来，docker daemon 和 docker CLI 所组成的，正是一个标准 C/S ( Client-Server ) 结构的应用程序。衔接这两者的，正是 docker daemon 所提供的这套 RESTful API。 留言互动在这节中，我们了解了 Docker 中核心的概念，这些基础知识能够帮助我们更好的理解之后我们对 Docker 的实践学习。这里给大家留一道思考题： Docker 的四大核心模块背后各由哪些技术提供支持，它们又在 Docker 实现虚拟运行环境的过程各扮演了什么样的角色？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker 的核心概念以及 Docker Engine 的基础知识有什么不理解之处，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E4%BD%BF%E7%94%A8%E5%AE%B9%E5%99%A8%EF%BC%9A%E9%95%9C%E5%83%8F%E4%B8%8E%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[镜像与容器镜像和容器作为 Docker 里最基础的概念，我们很有必要了解 Docker 对它们的很多定义以及其他与它们有关的知识。在这一小节里，我们就专门针对镜像与容器两个概念展开，细致的梳理与这两者有关的概念和定义。 Docker 镜像如果进行形象的表述，我们可以将 Docker 镜像理解为包含应用程序以及其相关依赖的一个基础文件系统，在 Docker 容器启动的过程中，它以只读的方式被用于创建容器的运行环境。 从另一个角度看，在之前的小节里我们讲到了，Docker 镜像其实是由基于 UnionFS 文件系统的一组镜像层依次挂载而得，而每个镜像层包含的其实是对上一镜像层的修改，这些修改其实是发生在容器运行的过程中的。所以，我们也可以反过来理解，镜像是对容器运行环境进行持久化存储的结果。 深入镜像实现与其他虚拟机的镜像管理不同，Docker 将镜像管理纳入到了自身设计之中，也就是说，所有的 Docker 镜像都是按照 Docker 所设定的逻辑打包的，也是受到 Docker Engine 所控制的。 这么说起来也许还不够具体，让我们来做一个比较。我们常见的虚拟机镜像，通常是由热心的提供者以他们自己熟悉的方式打包成镜像文件，被我们从网上下载或是其他方式获得后，恢复到虚拟机中的文件系统里的。而 Docker 的镜像我们必须通过 Docker 来打包，也必须通过 Docker 下载或导入后使用，不能单独直接恢复成容器中的文件系统。 虽然这么做失去了很多灵活性，但固定的格式意味着我们可以很轻松的在不同的服务器间传递 Docker 镜像，配合 Docker 自身对镜像的管理功能，让我们在不同的机器中传递和共享 Docker 变得非常方便。这也是 Docker 能够提升我们工作效率的一处体现。 对于每一个记录文件系统修改的镜像层来说，Docker 都会根据它们的信息生成了一个 Hash 码，这是一个 64 长度的字符串，足以保证全球唯一性。这种编码的形式在 Docker 很多地方都有体现，之后我们会经常见到。 由于镜像层都有唯一的编码，我们就能够区分不同的镜像层并能保证它们的内容与编码是一致的，这带来了另一项好处，就是允许我们在镜像之间共享镜像层。 举一个实际的例子，由 Docker 官方提供的两个镜像 elasticsearch 镜像和 jenkins 镜像都是在 openjdk 镜像之上修改而得，那么在我们实际使用的时候，这两个镜像是可以共用 openjdk 镜像内部的镜像层的。 这带来的一项好处就是让镜像可以共用一些存储空间，达到 1 + 1 &lt; 2 的效果，为我们在同一台机器里存放众多镜像提供了可能。 事实上，这个优势是更为明显的。一个虚拟机镜像的占用空间往往用 GB 来衡量，在同一台物理机上存放几个就已经是了不起的事情了。而 Docker 管理之下的镜像，占用空间是以 MB 为单位进行衡量的，加之镜像之间还能够共享部分的镜像层，也就是共享存储空间，所以我们在常见的硬盘里放下几十、数百个镜像也不是什么难事。 在之后的小节里，我们会讲到如何导出镜像，在导出镜像的时候，我们可以更清晰的看到镜像层的体现，这个留至后面我们来讲解。 查看镜像镜像是由 Docker 进行管理的，所以它们的存储位置和存储方式等我们并不需要过多的关心，我们只需要利用 Docker 所提供的一些接口或命令对它们进行控制即可。 如果要查看当前连接的 docker daemon 中存放和管理了哪些镜像，我们可以使用 docker images 这个命令 ( Linux、macOS 还是 Windows 上都是一致的 )。 123456$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEphp 7-fpm f214b5c48a25 9 days ago 368MBredis 3.2 2fef532eadb3 11 days ago 76MBredis 4.0 e1a73233e3be 11 days ago 83.4MBcogset/cron latest c01d5ac6fc8a 15 months ago 125MB 在 docker images 命令的结果中，我们可以看到镜像的 ID ( IMAGE ID)、构建时间 ( CREATED )、占用空间 ( SIZE ) 等数据。 这里需要注意一点，我们发现在结果中镜像 ID 的长度只有 12 个字符，这和我们之前说的 64 个字符貌似不一致。其实为了避免屏幕的空间都被这些看似“乱码”的镜像 ID 所挤占，所以 Docker 只显示了镜像 ID 的前 12 个字符，大部分情况下，它们已经能够让我们在单一主机中识别出不同的镜像了。 镜像命名镜像层的 ID 既可以识别每个镜像层，也可以用来直接识别镜像 ( 因为根据最上层镜像能够找出所有依赖的下层镜像，所以最上层进行的镜像层 ID 就能表示镜像的 ID )，但是使用这种无意义的超长哈希码显然是违背人性的，所以这里我们还要介绍镜像的命名，通过镜像名我们能够更容易的识别镜像。 在 docker images 命令打印出的内容中，我们还能看到两个与镜像命名有关的数据：REPOSITORY 和 TAG，这两者其实就组成了 docker 对镜像的命名规则。 来看这个例子： 准确的来说，镜像的命名我们可以分成三个部分：username、repository 和 tag。 username： 主要用于识别上传镜像的不同用户，与 GitHub 中的用户空间类似。 repository：主要用于识别进行的内容，形成对镜像的表意描述。 tag：主要用户表示镜像的版本，方便区分进行内容的不同细节 对于 username 来说，在上面我们展示的 docker images 结果中，有的镜像有 username 这个部分，而有的镜像是没有的。没有 username 这个部分的镜像，表示镜像是由 Docker 官方所维护和提供的，所以就不单独标记用户了。 如果大家再多接触一些镜像，会发现 Docker 中镜像的 repository 部分通常采用的是软件名。这时候大家一定要注意了，镜像还是镜像，镜像名还是镜像名，其与软件命名其实是独立的。 之所以镜像通常直接采用软件名，这还要回归到 Docker 对容器的轻量化设计中。Docker 对容器的设计和定义是微型容器而不是庞大臃肿的完整环境 ( 这当然归功于容器技术在实现虚拟化过程中性能几乎无损 )，这就使得我们通常会只在一个容器中运行一个应用程序，这样的好处自然是能够大幅降低程序之间相互的影响，也有利于利用容器技术控制每个程序所使用的资源。 回过头来，既然我们推崇这种一个容器运行一个程序的做法，那么自然容器的镜像也会仅包含程序以及与它运行有关的一些依赖包，所以我们使用程序的名字直接套用在镜像之上，既祛除了镜像取名的麻烦，又能直接表达镜像中的内容。 在镜像命名中，还有一个非常重要的部分，也就是镜像的标签 ( tag )。镜像的标签是对同一种镜像进行更细层次区分的方法，也是最终识别镜像的关键部分。 通常来说，镜像的标签主要是为了区分同类镜像不同构建过程所产生的不同结果的。由于时间、空间等因素的不同，Docker 每次构建镜像的内容也就有所不同，具体体现就是镜像层以及它们的 ID 都会产生变化。而标签就是在镜像命名这个层面上区分这些镜像的方法。 与镜像的 repository 类似，镜像 tag 的命名方法也通常参考镜像所关联的应用程序。更确切的来说，我们通常会采用镜像内应用程序的版本号以及一些环境、构建方式等信息来作为镜像的 tag。 例如，我们之前示例的结果中就分别有包含 Redis 3.2 版本和 4.0 版本的两个镜像：redis:3.2 和 redis:4.0。 除了单纯使用应用程序版本来作为镜像的标签外，有时候我们也会在其中包含一些构建方式的区别。例如 php:7.2-cli 和 php:7.2-fpm 两个镜像分别表示只包含控制台命令的 PHP 镜像以及包含 PHP-FPM 功能的 PHP 镜像，而他们对应 PHP 版本都是 7.2。 通过组合应用程序和它的版本号来命名镜像，大大方便了我们在 Docker 区别和使用镜像的门槛，与其说我们在使用 Docker 进行来启动容器，这个过程倒更像我们在运行指定版本的应用程序。 另外，Docker 中还有一个约定，当我们在操作中没有具体给出镜像的 tag 时，Docker 会采用 latest 作为缺省 tag。这也就带来了一个共识，也就是绝大多数镜像提供者在提供镜像时，会在 latest 对应的镜像中包含软件最新的版本。这带来了一项小便利，就是我们在不需要了解应用程序迭代周期的情况下，可以利用 latest 镜像保持软件最新版本的使用。 容器的生命周期要熟悉 Docker 容器，还有一个重要的概念，也就是容器的生命周期。 由于 Docker 揽下了大部分对容器管理的活，只提供给我们非常简单的操作接口，这就意味着 Docker 里对容器的一些运行细节会被更加严格的定义，这其中就包括了容器的生命周期。 这里有一张容器运行的状态流转图： 图中展示了几种常见对 Docker 容器的操作命令，以及执行它们之后容器运行状态的变化。这里我们撇开命令，着重看看容器的几个核心状态，也就是图中色块表示的：Created、Running、Paused、Stopped、Deleted。 在这几种状态中，Running 是最为关键的状态，在这种状态中的容器，就是真正正在运行的容器了。 主进程如果单纯去看容器的生命周期会有一些难理解的地方，而 Docker 中对容器生命周期的定义其实并不是独立存在的。 在 Docker 的设计中，容器的生命周期其实与容器中 PID 为 1 这个进程有着密切的关系。更确切的说，它们其实是共患难，同生死的兄弟。容器的启动，本质上可以理解为这个进程的启动，而容器的停止也就意味着这个进程的停止，反过来理解亦然。 当我们启动容器时，Docker 其实会按照镜像中的定义，启动对应的程序，并将这个程序的主进程作为容器的主进程 ( 也就是 PID 为 1 的进程 )。而当我们控制容器停止时，Docker 会向主进程发送结束信号，通知程序退出。 而当容器中的主进程主动关闭时 ( 正常结束或出错停止 )，也会让容器随之停止。 通过之前提到的几个方面来看，Docker 不仅是从设计上推崇轻量化的容器，也是许多机制上是以此为原则去实现的。所以，我们最佳的 Docker 实践方法是遵循着它的逻辑，逐渐习惯这种容器即应用，应用即容器的虚拟化方式。虽然在 Docker 中我们也能够实现在同一个容器中运行多个不同类型的程序，但这么做的话，Docker 就无法跟踪不同应用的生命周期，有可能造成应用的非正常关闭，进而影响系统、数据的稳定性。 写时复制机制写时复制 ( Copy on Write ) 这个词对于开发者来说应该并不陌生，在很多编程语言里，都隐藏了写时复制的实现。在编程里，写时复制常常用于对象或数组的拷贝中，当我们拷贝对象或数组时，复制的过程并不是马上发生在内存中，而只是先让两个变量同时指向同一个内存空间，并进行一些标记，当我们要对对象或数组进行修改时，才真正进行内存的拷贝。 Docker 的写时复制与编程中的相类似，也就是在通过镜像运行容器时，并不是马上就把镜像里的所有内容拷贝到容器所运行的沙盒文件系统中，而是利用 UnionFS 将镜像以只读的方式挂载到沙盒文件系统中。只有在容器中发生对文件的修改时，修改才会体现到沙盒环境上。 也就是说，容器在创建和启动的过程中，不需要进行任何的文件系统复制操作，也不需要为容器单独开辟大量的硬盘空间，与其他虚拟化方式对这个过程的操作进行对比，Docker 启动的速度可见一斑。 采用写时复制机制来设计的 Docker，既保证了镜像在生成为容器时，以及容器在运行过程中，不会对自身造成修改。又借助剔除常见虚拟化在初始化时需要从镜像中拷贝整个文件系统的过程，大幅提高了容器的创建和启动速度。可以说，Docker 容器能够实现秒级启动速度，写时复制机制在其中发挥了举足轻重的作用。 留言互动在这一小节中，我们对 Docker 的镜像与容器相关的概念进行了进一步的梳理，通过掌握这些词汇，能够更好的帮助大家理解之后小节中的内容。这里给大家留一道思考题： Docker 对镜像与容器的设计有什么独特之处，它们又给 Docker 带来了怎样的优势？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对镜像与容器相关的概念、知识还有不理解的地方，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E4%BD%BF%E7%94%A8%E5%AE%B9%E5%99%A8%EF%BC%9A%E8%BF%90%E8%A1%8C%E5%92%8C%E7%AE%A1%E7%90%86%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[运行和管理容器容器是基于容器技术所建立和运行的轻量级应用运行环境，它是 Docker 封装和管理应用程序或微服务的“集装箱”。在 Docker 中，容器算是最核心的部分了，掌握容器的操作也是 Docker 中最基础的技能了。在这一节中，我们会深入了解容器，展示关于容器的操作。 容器的创建和启动在了解容器的各项操作之前，我们再来回顾一下之前我们所提及的容器状态流转。 在这幅图中，我们可以看到，Docker 容器的生命周期里分为五种状态，其分别代表着： Created：容器已经被创建，容器所需的相关资源已经准备就绪，但容器中的程序还未处于运行状态。 Running：容器正在运行，也就是容器中的应用正在运行。 Paused：容器已暂停，表示容器中的所有程序都处于暂停 ( 不是停止 ) 状态。 Stopped：容器处于停止状态，占用的资源和沙盒环境都依然存在，只是容器中的应用程序均已停止。 Deleted：容器已删除，相关占用的资源及存储在 Docker 中的管理信息也都已释放和移除。 创建容器当我们选择好镜像以后，就可以通过 docker create 这个命令来创建容器了。 12$ sudo docker create nginx:1.1234f277e22be252b51d204acbb32ce21181df86520de0c337a835de6932ca06c3 执行 docker create 后，Docker 会根据我们所给出的镜像创建容器，在控制台中会打印出 Docker 为容器所分配的容器 ID，此时容器是处于 Created 状态的。 之后我们对容器的操作可以通过这个容器 ID 或者它的缩略形式进行，但用容器 ID 操作容器就和用镜像 ID 操作镜像一样烦闷，所以我们更习惯于使用容器名来操作容器。 要使用容器名操作容器，就先得给容器命名，在创建容器时，我们可以通过 --name 这个选项来配置容器名。 1$ sudo docker create --name nginx nginx:1.12 启动容器通过 docker create 创建的容器，是处于 Created 状态的，其内部的应用程序还没有启动，所以我们需要通过 docker start 命令来启动它。 1$ sudo docker start nginx 由于我们为容器指定了名称，这样的操作会更加自然，所以我们非常推荐为每个被创建的容器都进行命名。 当容器启动后，其中的应用就会运行起来，容器的几个生命周期也会绑定到了这个应用上，这个之前我们已经提及，这里就不在赘述。只要应用程序还在运行，那么容器的状态就会是 Running，除非进行一些修改容器的操作。 在 Docker 里，还允许我们通过 docker run 这个命令将 docker create 和 docker start 这两步操作合成为一步，进一步提高工作效率。 12$ sudo docker run --name nginx -d nginx:1.1289f2b769498a50f5c35a314ab82300ce9945cbb69da9cda4b022646125db8ca7 通过 docker run 创建的容器，在创建完成之后会直接启动起来，不需要我们再使用 docker start 去启动了。 这里需要注意的一点是，通常来说我们启动容器会期望它运行在“后台”，而 docker run 在启动容器时，会采用“前台”运行这种方式，这时候我们的控制台就会衔接到容器上，不能再进行其他操作了。我们可以通过 -d 或 --detach 这个选项告诉 Docker 在启动后将程序与控制台分离，使其进入“后台”运行。 管理容器容器创建和启动后，除了关注应用程序是否功能正常外，我们也会关注容器的状态等内容。 通过 docker ps 这个命令，我们可以罗列出 Docker 中的容器。 123$ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES89f2b769498a nginx:1.12 &quot;nginx -g &apos;daemon of…&quot; About an hour ago Up About an hour 80/tcp nginx 默认情况下，docker ps 列出的容器是处于运行中的容器，如果要列出所有状态的容器，需要增加 -a 或 --all 选项。 1234$ sudo docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES425a0d3cd18b redis:3.2 &quot;docker-entrypoint.s…&quot; 2 minutes ago Created redis89f2b769498a nginx:1.12 &quot;nginx -g &apos;daemon of…&quot; About an hour ago Up About an hour 80/tcp nginx 在 docker ps 的结果中，我们可以看到几项关于容器的信息。其中 CONTAINER ID、IMAGE、CREATED、NAMES 大家都比较容易理解，分别表示容器 ID，容器所基于的镜像，容器的创建时间和容器的名称。 结果中的 COMMAND 表示的是容器中主程序 ( 也就是与容器生命周期所绑定进程所关联的程序 ) 的启动命令，这条命令是在镜像内定义的，而容器的启动其实质就是启动这条命令。关于 COMMAND 的更多知识，我们在之后的 Docker 镜像制作中会更详细的解读。 结果中的 STATUS 表示容器所处的状态，其值和我们之前所谈到的状态有所区别，主要是因为这里还记录了其他的一些信息。在这里，常见的状态表示有三种： Created 此时容器已创建，但还没有被启动过。 Up [ Time ] 这时候容器处于正在运行状态，而这里的 Time 表示容器从开始运行到查看时的时间。 Exited ([ Code ]) [ Time ] 容器已经结束运行，这里的 Code 表示容器结束运行时，主程序返回的程序退出码，而 Time 则表示容器结束到查看时的时间。 有些读者有疑问，既然是列出容器，应该为命令取一些带有 ls 字眼的名字，为啥会用类似 Linux 中查看进程的 ps 呢？这其实有一部分历史原因，由于容器并非真的包裹住了进程，而只是隔离了进程，进程还是允许在宿主机操作系统之上的，所以列出镜像的过程到更新是查看正在运行的进程，故而有了这样的名字。 当然，在 Docker 逐渐成熟后，命令的命名也没有原来那么随意了，已经逐渐转换为使用大家广泛认可的形式。只是 docker ps 这条命令，还保留着复古的风格。 停止和删除容器要将正在运行的容器停止，我们可以使用 docker stop 命令。 1$ sudo docker stop nginx 容器停止后，其维持的文件系统沙盒环境还是存在的，内部被修改的内容也都会保留，我们可以通过 docker start 命令将这个容器再次启动。 当我们需要完全删除容器时，可以通过 docker rm 命令将容器进行删除。 1$ sudo docker rm nginx 正在运行中的容器默认情况下是不能被删除的，我们可以通过增加 -f 或 --force 选项来让 docker rm 强制停止并删除容器，不过这种做法并不妥当。 随手删除容器与其他虚拟机不同，Docker 的轻量级容器设计，讲究随用随开，随关随删。也就是说，当我们短时间内不需要使用容器时，最佳的做法是删除它而不是仅仅停止它。 有的读者会问，容器一旦删除，其内部的文件系统变动也就消失了，这样做岂不是非常麻烦。要解决这个疑惑，其根本是解决为什么我们会对容器中的文件系统做更改。我这里总结了两个对虚拟环境做更改的原因，以及在 Docker 中如何优雅的解决它们。 在使用虚拟机或其他虚拟化所搭建的虚拟环境时，我们倾向于使用一个干净的系统镜像并搭建程序的运行环境，由于将这类虚拟环境制作成镜像的成本较高，耗时也非常久，所以我们对于一些细小的改动倾向于修改后保持虚拟环境不被清除即可。而在 Docker 中，打包镜像的成本是非常低的，其速度也快得惊人，所以如果我们要为程序准备一些环境或者配置，完全可以直接将它们打包至新的镜像中，下次直接使用这个新的镜像创建容器即可。 容器中应用程序所产生的一些文件数据，是非常重要的，如果这些数据随着容器的删除而丢失，其损失是非常巨大的。对于这类由应用程序所产生的数据，并且需要保证它们不会随着容器的删除而消失的，我们可以使用 Docker 中的数据卷来单独存放。由于数据卷是独立于容器存在的，所以其能保证数据不会随着容器的删除而丢失。关于数据卷的具体使用，在之后的小节会专门讲解。 解决了这两个问题，大家心中的疑虑是不是就小了很多。而事实上，容器的随用随删既能保证在我们不需要它们的时候它们不会枉占很多资源，也保证了每次我们建立和启动容器时，它们都是“热乎”的崭新版本。大家都知道，系统卡就重装，而借助 Docker 秒级的容器启停特性，我们就是可以这么任性的“重装”。 进入容器很多时间，我们需要的操作并不仅仅是按镜像所给出的命令启动容器而已，我们还会希望进一步了解容器或操作容器，这时候最佳的方式就是让我们进入到容器了。 我们知道，容器是一个隔离运行环境的东西，它里面除了镜像所规定的主进程外，其他的进程也是能够运行的，Docker 为我们提供了一个命令 docker exec 来让容器运行我们所给出的命令。 这里我们试试用容器中的 more 命令查看容器的主机名定义。 12345$ sudo docker exec nginx more /etc/hostname::::::::::::::/etc/hostname::::::::::::::83821ea220ed docker exec 命令能帮助我们在正在运行的容器中运行指定命令，这对于服务控制，运维监控等有着不错的应用场景。但是在开发过程中，我们更常使用它来作为我们进入容器的桥梁。 熟悉 Linux 的朋友们知道，我们操作 Linux 这个过程，并不是 Linux 内部的某些机能，而是通过控制台软件来完成的。控制台软件分析我们的命令，将其转化为对 Linux 的系统调用，实现了我们对 Linux 的操作。若不是这样，生涩的系统调用方法对普通开发者来说简直就是黑洞一般的存在，更别提用它们控制系统了。 在 Linux 中，大家熟悉的控制台软件应该是 Shell 和 Bash 了，它们分别由 sh 和 bash 这两个程序启动。 说到这里，有读者一定想到了，既然有这两个控制台程序，我们只要在容器里执行它们，然后通过它们去控制容器内的环境，岂不就可以“自由的飞翔”了吗。没错，这里说的进入容器，就是通过 docker exec 命令来启动 sh 或 bash，并通过它们实现对容器内的虚拟环境的控制。 由于 bash 的功能要比 sh 丰富，所以在能够使用 bash 的容器里，我们优先选择它作为控制台程序。 12$ sudo docker exec -it nginx bashroot@83821ea220ed:/# 在借助 docker exec 进入容器的时候，我们需要特别注意命令中的两个选项不可或缺，即 -i 和 -t ( 它们俩可以利用简写机制合并成 -it )。 其中 -i ( --interactive ) 表示保持我们的输入流，只有使用它才能保证控制台程序能够正确识别我们的命令。而 -t ( --tty ) 表示启用一个伪终端，形成我们与 bash 的交互，如果没有它，我们无法看到 bash 内部的执行结果。 熟悉通过在容器中执行控制台程序进而进入容器这种方法，在开发过程中你能更轻松的观察容器中发生了什么，也更容易排查程序或者环境引起的问题。 衔接到容器Docker 为我们提供了一个 docker attach 命令，用于将当前的输入输出流连接到指定的容器上。 1$ sudo docker attach nginx 这个命令最直观的效果可以理解为我们将容器中的主程序转为了“前台”运行 ( 与 docker run 中的 -d 选项有相反的意思 )。 由于我们的输入输出流衔接到了容器的主程序上，我们的输入输出操作也就直接针对了这个程序，而我们发送的 Linux 信号也会转移到这个程序上。例如我们可以通过 Ctrl + C 来向程序发送停止信号，让程序停止 ( 从而容器也会随之停止 )。 在实际开发中，由于 docker attach 限制较多，功能也不够强大，所以并没有太多用武之地，这里我们就一笔带过，不做详细的解读了。 留言互动在本节中，我们对容器相关的操作进行了深入的了解，对容器的运行状态及相关知识做了介绍。这里给大家留一道实践题： 试着创建 Nginx 容器，之后进入到容器中，利用相关命令停止 Nginx 程序的运行，观察操作之后容器的状态变化。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对容器相关的操作与使用还有什么不理解的地方，或者对其有独特的见解，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E4%BD%BF%E7%94%A8%E5%AE%B9%E5%99%A8%EF%BC%9A%E7%AE%A1%E7%90%86%E5%92%8C%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[管理和存储数据数据是应用程序重要的产出，所以很好的管理和存储数据，是对应用程序劳动结果的尊重。特别是在大数据时代，所有的数据都是重要的资产，保护好数据是每个开发者必须掌握的技能。我们知道，在 Docker 里，容器运行的文件系统处于沙盒环境中，与外界其实是隔离的，那么我们又要如何在 Docker 中合理的通过文件与外界进行数据交换呢？在这一小节中，我们就来介绍 Docker 中与文件数据有关的内容。 数据管理实现方式Docker 容器中的文件系统于我们这些开发使用者来说，虽然有很多优势，但也有很多弊端，其中显著的两点就是： 沙盒文件系统是跟随容器生命周期所创建和移除的，数据无法直接被持久化存储。 由于容器隔离，我们很难从容器外部获得或操作容器内部文件中的数据。 当然，Docker 很好的解决了这些问题，这主要还是归功于 Docker 容器文件系统是基于 UnionFS。由于 UnionFS 支持挂载不同类型的文件系统到统一的目录结构中，所以我们只需要将宿主操作系统中，文件系统里的文件或目录挂载到容器中，便能够让容器内外共享这个文件。 由于通过这种方式可以互通容器内外的文件，那么文件数据持久化和操作容器内文件的问题就自然而然的解决了。 同时，UnionFS 带来的读写性能损失是可以忽略不计的，所以这种实现可以说是相当优秀的。 挂载方式基于底层存储实现，Docker 提供了三种适用于不同场景的文件系统挂载方式：Bind Mount、Volume 和 Tmpfs Mount。 Bind Mount 能够直接将宿主操作系统中的目录和文件挂载到容器内的文件系统中，通过指定容器外的路径和容器内的路径，就可以形成挂载映射关系，在容器内外对文件的读写，都是相互可见的。 Volume 也是从宿主操作系统中挂载目录到容器内，只不过这个挂载的目录由 Docker 进行管理，我们只需要指定容器内的目录，不需要关心具体挂载到了宿主操作系统中的哪里。 Tmpfs Mount 支持挂载系统内存中的一部分到容器的文件系统里，不过由于内存和容器的特征，它的存储并不是持久的，其中的内容会随着容器的停止而消失。 挂载文件到容器要将宿主操作系统中的目录挂载到容器之后，我们可以在容器创建的时候通过传递 -v 或 --volume 选项来指定内外挂载的对应目录或文件。 1$ sudo docker run -d --name nginx -v /webapp/html:/usr/share/nginx/html nginx:1.12 使用 -v 或 --volume 来挂载宿主操作系统目录的形式是 -v &lt;host-path&gt;:&lt;container-path&gt; 或 --volume &lt;host-path&gt;:&lt;container-path&gt;，其中 host-path 和 container-path 分别代表宿主操作系统中的目录和容器中的目录。这里需要注意的是，为了避免混淆，Docker 这里强制定义目录时必须使用绝对路径，不能使用相对路径。 我们能够指定目录进行挂载，也能够指定具体的文件来挂载，具体选择何种形式来挂载，大家可以根据具体的情况来选择。 当挂载了目录的容器启动后，我们可以看到我们在宿主操作系统中的文件已经出现在容器中了。 12$ sudo docker exec nginx ls /usr/share/nginx/htmlindex.html 在 docker inspect 的结果里，我们可以看到有关容器数据挂载相关的信息。 1234567891011121314151617$ sudo docker inspect nginx[ &#123;## ...... &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/webapp/html&quot;, &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ],## ...... &#125;] 在关于挂载的信息中我们可以看到一个 RW 字段，这表示挂载目录或文件的读写性 ( Read and Write )。实际操作中，Docker 还支持以只读的方式挂载，通过只读方式挂载的目录和文件，只能被容器中的程序读取，但不接受容器中程序修改它们的请求。在挂载选项 -v 后再接上 :ro 就可以只读挂载了。 1$ sudo docker run -d --name nginx -v /webapp/html:/usr/share/nginx/html:ro nginx:1.12 由于宿主操作系统文件挂载在权限允许的情况下能够挂载任何目录或文件，这给系统的安全性造成了一定的隐患，所以我们在使用 Bind Mount 的时候，一定要特别注意挂载的外部目录选择。当然，在保证安全性的前提下，有几种常见场景非常适合使用这种挂载方式。 当我们需要从宿主操作系统共享配置的时候。对于一些配置项，我们可以直接从容器外部挂载到容器中，这利于保证容器中的配置为我们所确认的值，也方便我们对配置进行监控。例如，遇到容器中时区不正确的时候，我们可以直接将操作系统的时区配置，也就是 /etc/timezone 这个文件挂载并覆盖容器中的时区配置。 当我们需要借助 Docker 进行开发的时候。虽然在 Docker 中，推崇直接将代码和配置打包进镜像，以便快速部署和快速重建。但这在开发过程中显然非常不方便，因为每次构建镜像需要耗费一定的时间，这些时间积少成多，就是对开发工作效率的严重浪费了。如果我们直接把代码挂载进入容器，那么我们每次对代码的修改都可以直接在容器外部进行。 挂载临时文件目录Tmpfs Mount 是一种特殊的挂载方式，它主要利用内存来存储数据。由于内存不是持久性存储设备，所以其带给 Tmpfs Mount 的特征就是临时性挂载。 与挂载宿主操作系统目录或文件不同，挂载临时文件目录要通过 --tmpfs 这个选项来完成。由于内存的具体位置不需要我们来指定，这个选项里我们只需要传递挂载到容器内的目录即可。 1$ sudo docker run -d --name webapp --tmpfs /webapp/cache webapp:latest 容器已挂载的临时文件目录我们也可以通过 docker inspect 命令查看。 12345678910$ sudo docker inspect webapp[ &#123;## ...... &quot;Tmpfs&quot;: &#123; &quot;/webapp/cache&quot;: &quot;&quot; &#125;,## ...... &#125;] 挂载临时文件首先要注意它不是持久存储这一特性，在此基础上，它有几种常见的适应场景。 应用中使用到，但不需要进行持久保存的敏感数据，可以借助内存的非持久性和程序隔离性进行一定的安全保障。 读写速度要求较高，数据变化量大，但不需要持久保存的数据，可以借助内存的高读写速度减少操作的时间。 使用数据卷除了与其他虚拟机工具近似的宿主操作系统目录挂载的功能外，Docker 还创造了数据卷 ( Volume ) 这个概念。数据卷的本质其实依然是宿主操作系统上的一个目录，只不过这个目录存放在 Docker 内部，接受 Docker 的管理。 在使用数据卷进行挂载时，我们不需要知道数据具体存储在了宿主操作系统的何处，只需要给定容器中的哪个目录会被挂载即可。 我们依然可以使用 -v 或 --volume 选项来定义数据卷的挂载。 1$ sudo docker run -d --name webapp -v /webapp/storage webapp:latest 数据卷挂载到容器后，我们可以通过 docker inspect 看到容器中数据卷挂载的信息。 12345678910111213141516171819$ sudo docker inspect webapp[ &#123;## ...... &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;2bbd2719b81fbe030e6f446243386d763ef25879ec82bb60c9be7ef7f3a25336&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/2bbd2719b81fbe030e6f446243386d763ef25879ec82bb60c9be7ef7f3a25336/_data&quot;, &quot;Destination&quot;: &quot;/webapp/storage&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ],## ...... &#125;] 这里我们所得到的信息与绑定挂载有所区别，除了 Type 中的类型不一样之外，在数据卷挂载中，我们还要关注一下 Name 和 Source 这两个信息。 其中 Source 是 Docker 为我们分配用于挂载的宿主机目录，其位于 Docker 的资源区域 ( 这里是默认的 /var/lib/docker ) 内。当然，我们并不需要关心这个目录，一切对它的管理都已经在 Docker 内实现了。 为了方便识别数据卷，我们可以像命名容器一样为数据卷命名，这里的 Name 就是数据卷的命名。在我们未给出数据卷命名的时候，Docker 会采用数据卷的 ID 命名数据卷。我们也可以通过 -v &lt;name&gt;:&lt;container-path&gt; 这种形式来命名数据卷。 1$ sudo docker run -d --name webapp -v appdata:/webapp/storage webapp:latest 由于 -v 选项既承载了 Bind Mount 的定义，又参与了 Volume 的定义，所以其传参方式需要特别留意。前面提到了，-v 在定义绑定挂载时必须使用绝对路径，其目的主要是为了避免与数据卷挂载中命名这种形式的冲突。 虽然与绑定挂载的原理差别不大，但数据卷在许多实际场景下你会发现它很有用。 当希望将数据在多个容器间共享时，利用数据卷可以在保证数据持久性和完整性的前提下，完成更多自动化操作。 当我们希望对容器中挂载的内容进行管理时，可以直接利用数据卷自身的管理方法实现。 当使用远程服务器或云服务作为存储介质的时候，数据卷能够隐藏更多的细节，让整个过程变得更加简单。 共用数据卷数据卷的另一大作用是实现容器间的目录共享，也就是通过挂载相同的数据卷，让容器之间能够同时看到并操作数据卷中的内容。这个功能虽然也可以通过绑定挂载来实现，但通过数据卷来操作会更加的舒适、简单。 由于数据卷的命名在 Docker 中是唯一的，所以我们很容易通过数据卷的名称确定数据卷，这就让我们很方便的让多个容器挂载同一个数据卷了。 12$ sudo docker run -d --name webapp -v html:/webapp/html webapp:latest$ sudo docker run -d --name nginx -v html:/usr/share/nginx/html:ro nginx:1.12 我们使用 -v 选项挂载数据卷时，如果数据卷不存在，Docker 会为我们自动创建和分配宿主操作系统的目录，而如果同名数据卷已经存在，则会直接引用。 如果有朋友觉得这样对数据卷的操作方式还不够直接和准确，我们还可以通过 docker volume 下的几个命令专门操作数据卷。 通过 docker volume create 我们可以不依赖于容器独立创建数据卷。 1$ sudo docker volume create appdata 通过 docker volume ls 可以列出当前已创建的数据卷。 1234$ sudo docker volume lsDRIVER VOLUME NAMElocal htmllocal appdata 删除数据卷虽然数据卷的目的是用来持久化存储数据的，但有时候我们也难免有删除它们以释放空间的需求。直接去 Docker 的目录下删除显然不是好的选择，我们应该通过 Docker 对数据卷的管理命令来删除它们。 我们可以直接通过 docker volume rm 来删除指定的数据卷。 1$ sudo docker volume rm appdata 在删除数据卷之前，我们必须保证数据卷没有被任何容器所使用 ( 也就是之前引用过这个数据卷的容器都已经删除 )，否则 Docker 不会允许我们删除这个数据卷。 对于我们没有直接命名的数据卷，因为要反复核对数据卷 ID，这样的方式并不算特别友好。这种没有命名的数据卷，通常我们可以看成它们与对应的容器产生了绑定，因为其他容器很难使用到它们。而这种绑定关系的产生，也让我们可以在容器删除时将它们一并删除。 在 docker rm 删除容器的命令中，我们可以通过增加 -v 选项来删除容器关联的数据卷。 1$ sudo docker rm -v webapp 如果我们没有随容器删除这些数据卷，Docker 在创建新的容器时也不会启用它们，即使它们与新创建容器所定义的数据卷有完全一致的特征。也就是说，此时它们已经变成了孤魂野鬼，纯粹的占用着硬盘空间而又不受管理。 此时我们可以通过 docker volume rm 来删除它们，但前提时你能在一堆乱码般的数据卷 ID 中找出哪个是没有被容器引用的数据卷。 为此，Docker 向我们提供了 docker volume prune 这个命令，它可以删除那些没有被容器引用的数据卷。 123456$ sudo docker volume prune -fDeleted Volumes:af6459286b5ce42bb5f205d0d323ac11ce8b8d9df4c65909ddc2feea7c3d1d530783665df434533f6b53afe3d9decfa791929570913c7aff10f302c17ed1a38965b822e27d0be93d149304afb1515f8111344da9ea18adc3b3a34bddd2b243c7## ...... 数据卷容器在数据卷的基础上，我们有一种相对新颖的用法，也就是数据卷容器。所谓数据卷容器，就是一个没有具体指定的应用，甚至不需要运行的容器，我们使用它的目的，是为了定义一个或多个数据卷并持有它们的引用。 创建数据卷容器的方式很简单，由于不需要容器本身运行，因而我们找个简单的系统镜像都可以完成创建。 1$ sudo docker create --name appdata -v /webapp/storage ubuntu 在使用数据卷容器时，我们不建议再定义数据卷的名称，因为我们可以通过对数据卷容器的引用来完成数据卷的引用。而不设置数据卷的名称，也避免了在同一 Docker 中数据卷重名的尴尬。 之前我们提到，Docker 的 Network 是容器间的网络桥梁，如果做类比，数据卷容器就可以算是容器间的文件系统桥梁。我们可以像加入网络一样引用数据卷容器，只需要在创建新容器时使用专门的 --volumes-from 选项即可。 1$ sudo docker run -d --name webapp --volumes-from appdata webapp:latest 引用数据卷容器时，不需要再定义数据卷挂载到容器中的位置，Docker 会以数据卷容器中的挂载定义将数据卷挂载到引用的容器中。 虽然看上去数据卷容器与数据卷的使用方法变化不大，但最关键的就在于其真正隐藏了数据卷的配置和定义，我们只需要通过数据卷容器的名称来使用它。这些细节的隐藏，意味着我们能够更轻松的实现容器的迁移。 备份和迁移数据卷由于数据卷本身就是宿主操作系统中的一个目录，我们只需要在 Docker 资源目录里找到它就可以很轻松的打包、迁移、恢复了。虽然这么做相对其他虚拟化方案来说已经很简单了，但在 Docker 里还不是最优雅的解决方式。 利用数据卷容器，我们还能够更方便的对数据卷中的数据进行迁移。 数据备份、迁移、恢复的过程可以理解为对数据进行打包，移动到其他位置，在需要的地方解压的过程。在数据打包之前，我们先建立一个用来存放打包文件的目录，这里我们使用 /backup 作为例子。 要备份数据，我们先建立一个临时的容器，将用于备份的目录和要备份的数据卷都挂载到这个容器上。 1$ sudo docker run --rm --volumes-from appdata -v /backup:/backup ubuntu tar cvf /backup/backup.tar /webapp/storage 在这条命令中，除了挂载的配置外，我们再注意几个选项。通过 --rm 选项，我们可以让容器在停止后自动删除，而不需要我们再使用容器删除命令来删除它，这对于我们使用一些临时容器很有帮助。在容器所基于的镜像之后，我们还看到了一串命令，也就是 tar cvf /backup/backup.tar /webapp/storage，其实如果我们在镜像定义之后接上命令，可以直接替换掉镜像所定义的主程序启动命令，而去执行这一条命令。在很多场合下，我们还能通过这个方法干很多不同的事情。 在备份后，我们就可以在 /backup 下找到数据卷的备份文件，也就是 backup.tar 了。 如果要恢复数据卷中的数据，我们也可以借助临时容器完成。 1$ docker run --rm --volumes-from appdata -v /backup:/backup ubuntu tar xvf /backup/backup.tar -C /webapp/storage --strip 恢复的过程与备份的过程类似，只不过把打包的命令转换为解包的命令而已。 另一个挂载选项上面我们讲到了使用 -v 选项来挂载存在容易混淆的问题，其主要原因是挂载的方式和配置随着 Docker 的不断发展日渐丰富，而 -v 选项的传参方式限制了它能使用的场景。 其实在 Docker 里为我们提供了一个相对支持丰富的挂载方式，也就是通过 --mount 这个选项配置挂载。 1$ sudo docker run -d --name webapp webapp:latest --mount &apos;type=volume,src=appdata,dst=/webapp/storage,volume-driver=local,volume-opt=type=nfs,volume-opt=device=&lt;nfs-server&gt;:&lt;nfs-path&gt;&apos; webapp:latest 在 --mount 中，我们可以通过逗号分隔这种 CSV 格式来定义多个参数。其中，通过 type 我们可以定义挂载类型，其值可以是：bind，volume 或 tmpfs。另外，--mount 选项能够帮助我们实现集群挂载的定义，例如在这个例子中，我们挂载的来源是一个 NFS 目录。 由于在实际开发中，-v 基本上足够满足我们的需求，所以我们不常使用相对复杂的 --mount 选项来定义挂载，这里我们只是将它简单介绍，供大家参考。 留言互动在本节中，我们介绍了关于如何在 Docker 中管理和存储数据的方法。这里给大家留一道实践题： 结合我们所提到三种挂载方式各自的适用场景，分别尝试使用它们进行数据挂载。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker 中的数据挂载还有不理解的地方，或者对其有独特的见解，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E4%BD%BF%E7%94%A8%E5%AE%B9%E5%99%A8%EF%BC%9A%E4%B8%BA%E5%AE%B9%E5%99%A8%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[为容器配置网络在互联网时代，网络已经成为绝大多数应用进行数据交换的主要通道，Docker 作为集群部署的利器，在网络支持上也下了许多功夫。功能丰富和强大，并不代表使用复杂，在 Docker 的封装下，我们依然可以通过命令和参数轻松的为容器制定不同的网络方案。在这一节中，我们就来了解 Docker 的网络部分。 容器网络在之前介绍 Docker 核心组成的时候，我们已经简单谈到了容器网络的相关知识。容器网络实质上也是由 Docker 为应用程序所创造的虚拟环境的一部分，它能让应用从宿主机操作系统的网络环境中独立出来，形成容器自有的网络设备、IP 协议栈、端口套接字、IP 路由表、防火墙等等与网络相关的模块。 还是回归上面这幅之前展示过的关于 Docker 网络的图片。在 Docker 网络中，有三个比较核心的概念，也就是：沙盒 ( Sandbox )、网络 ( Network )、端点 ( Endpoint )。 沙盒提供了容器的虚拟网络栈，也就是之前所提到的端口套接字、IP 路由表、防火墙等的内容。其实现隔离了容器网络与宿主机网络，形成了完全独立的容器网络环境。 网络可以理解为 Docker 内部的虚拟子网，网络内的参与者相互可见并能够进行通讯。Docker 的这种虚拟网络也是于宿主机网络存在隔离关系的，其目的主要是形成容器间的安全通讯环境。 端点是位于容器或网络隔离墙之上的洞，其主要目的是形成一个可以控制的突破封闭的网络环境的出入口。当容器的端点与网络的端点形成配对后，就如同在这两者之间搭建了桥梁，便能够进行数据传输了。 这三者形成了 Docker 网络的核心模型，也就是容器网络模型 ( Container Network Model )。 浅析 Docker 的网络实现容器网络模型为容器引擎提供了一套标准的网络对接范式，而在 Docker 中，实现这套范式的是 Docker 所封装的 libnetwork 模块。 而对于网络的具体实现，在 Docker 的发展过程中也逐渐抽象，形成了统一的抽象定义。进而通过这些抽象定义，便可以对 Docker 网络的实现方式进行不同的变化。 目前 Docker 官方为我们提供了五种 Docker 网络驱动，分别是：Bridge Driver、Host Driver、Overlay Driver、MacLan Driver、None Driver。 其中，Bridge 网络是 Docker 容器的默认网络驱动，简而言之其就是通过网桥来实现网络通讯 ( 网桥网络的实现可以基于硬件，也可以基于软件 )。而 Overlay 网络是借助 Docker 集群模块 Docker Swarm 来搭建的跨 Docker Daemon 网络，我们可以通过它搭建跨物理主机的虚拟网络，进而让不同物理机中运行的容器感知不到多个物理机的存在。 Bridge Driver 和 Overlay Driver 在开发中使用频率较高，之后的小节讲解里，关于容器网络的部分我们都主要围绕着它们展开。 当然，关于 Docker 的网络实现还有非常多的细节。对于开发者来说，我们只是 Docker 的使用者而非技术专家，所以这里我们不做更多详尽的论述。 容器互联由于 Docker 提倡容器与应用共生的轻量级容器理念，所以容器中通常只包含一种应用程序，但我们知道，如今纷繁的系统服务，没有几个是可以通过单一的应用程序支撑的。拿最简单的 Web 应用为例，也至少需要业务应用、数据库应用、缓存应用等组成。也就是说，在 Docker 里我们需要通过多个容器来组成这样的系统。 而这些互联网时代的应用，其间的通讯方式主要以网络为主，所以打通容器间的网络，是使它们能够互相通讯的关键所在。 要让一个容器连接到另外一个容器，我们可以在容器通过 docker create 或 docker run 创建时通过 --link 选项进行配置。 例如，这里我们创建一个 MySQL 容器，将运行我们 Web 应用的容器连接到这个 MySQL 容器上，打通两个容器间的网络，实现它们之间的网络互通。 12$ sudo docker run -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=yes mysql$ sudo docker run -d --name webapp --link mysql webapp:latest 容器间的网络已经打通，那么我们要如何在 Web 应用中连接到 MySQL 数据库呢？Docker 为容器间连接提供了一种非常友好的方式，我们只需要将容器的网络命名填入到连接地址中，就可以访问需要连接的容器了。 假设我们在 Web 应用中使用的是 JDBC 进行数据库连接的，我们可以这么填写连接。 1String url = &quot;jdbc:mysql://mysql:3306/webapp&quot;; 在这里，连接地址中的 mysql 就好似我们常见的域名解析，Docker 会将其指向 MySQL 容器的 IP 地址。 看到这里，读者们有没有发现 Docker 在容器互通中为我们带来的一项便利，也就是我们不再需要真实的知道另外一个容器的 IP 地址就能进行连接。再具体来对比，在以往的开发中，我们每切换一个环境 ( 例如将程序从开发环境提交到测试环境 )，都需要重新配置程序中的各项连接地址等参数，而在 Docker 里，我们并不需要关心这个，只需要程序中配置被连接容器的别名，映射 IP 的工作就交给 Docker 完成了。 暴露端口需要注意的是，虽然容器间的网络打通了，但并不意味着我们可以任意访问被连接容器中的任何服务。Docker 为容器网络增加了一套安全机制，只有容器自身允许的端口，才能被其他容器所访问。 这个容器自我标记端口可被访问的过程，我们通常称为暴露端口。我们在 docker ps 的结果中可以看到容器暴露给其他容器访问的端口。 123$ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES95507bc88082 mysql:5.7 &quot;docker-entrypoint.s…&quot; 17 seconds ago Up 16 seconds 3306/tcp, 33060/tcp mysql 这里我们看到，MySQL 这个容器暴露的端口是 3306 和 33060。所以我们连接到 MySQL 容器后，只能对这两个端口进行访问。 端口的暴露可以通过 Docker 镜像进行定义，也可以在容器创建时进行定义。在容器创建时进行定义的方法是借助 --expose 这个选项。 1$ sudo docker run -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=yes --expose 13306 --expose 23306 mysql:5.7 这里我们为 MySQL 暴露了 13306 和 23306 这两个端口，暴露后我们可以在 docker ps 中看到这两个端口已经成功的打开。 123$ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3c4e645f21d7 mysql:5.7 &quot;docker-entrypoint.s…&quot; 4 seconds ago Up 3 seconds 3306/tcp, 13306/tcp, 23306/tcp, 33060/tcp mysql 容器暴露了端口只是类似我们打开了容器的防火墙，具体能不能通过这个端口访问容器中的服务，还需要容器中的应用监听并处理来自这个端口的请求。 通过别名连接纯粹的通过容器名来打开容器间的网络通道缺乏一定的灵活性，在 Docker 里还支持连接时使用别名来使我们摆脱容器名的限制。 1$ sudo docker run -d --name webapp --link mysql:database webapp:latest 在这里，我们使用 --link &lt;name&gt;:&lt;alias&gt; 的形式，连接到 MySQL 容器，并设置它的别名为 database。当我们要在 Web 应用中使用 MySQL 连接时，我们就可以使用 database 来代替连接地址了。 1String url = &quot;jdbc:mysql://database:3306/webapp&quot;; 管理网络容器能够互相连接的前提是两者同处于一个网络中 ( 这里的网络是指容器网络模型中的网络 )。这个限制很好理解，刚才我们说了，网络这个概念我们可以理解为 Docker 所虚拟的子网，而容器网络沙盒可以看做是虚拟的主机，只有当多个主机在同一子网里时，才能互相看到并进行网络数据交换。 当我们启动 Docker 服务时，它会为我们创建一个默认的 bridge 网络，而我们创建的容器在不专门指定网络的情况下都会连接到这个网络上。所以我们刚才之所以能够把 webapp 容器连接到 mysql 容器上，其原因是两者都处于 bridge 这个网络上。 我们通过 docker inspect 命令查看容器，可以在 Network 部分看到容器网络相关的信息。 12345678910111213141516171819202122232425262728$ sudo docker inspect mysql[ &#123;## ...... &quot;NetworkSettings&quot;: &#123;## ...... &quot;Networks&quot;: &#123; &quot;bridge&quot;: &#123; &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;NetworkID&quot;: &quot;bc14eb1da66b67c7d155d6c78cb5389d4ffa6c719c8be3280628b7b54617441b&quot;, &quot;EndpointID&quot;: &quot;1e201db6858341d326be4510971b2f81f0f85ebd09b9b168e1df61bab18a6f22&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;DriverOpts&quot;: null &#125; &#125;## ...... &#125;## ...... &#125;] 这里我们能够看到 mysql 容器在 bridge 网络中所分配的 IP 地址，其自身的端点、Mac 地址，bridge 网络的网关地址等信息。 Docker 默认创建的这个 bridge 网络是非常重要的，理由自然是在没有明确指定容器网络时，容器都会连接到这个网络中。在之前讲解 Docker for Win 和 Docker for Mac 安装的时候，我们提到过这两个软件的配置中都有一块配置 Docker 中默认网络的内容，这块所指的默认网络就是这个 bridge 网络。 创建网络在 Docker 里，我们也能够创建网络，形成自己定义虚拟子网的目的。 docker CLI 里与网络相关的命令都以 docker network 开头，其中创建网络的命令是 docker network create。 1$ sudo docker network create -d bridge individual 通过 -d 选项我们可以为新的网络指定驱动的类型，其值可以是刚才我们所提及的 bridge、host、overlay、maclan、none，也可以是其他网络驱动插件所定义的类型。这里我们使用的是 Bridge Driver ( 当我们不指定网络驱动时，Docker 也会默认采用 Bridge Driver 作为网络驱动 )。 通过 docker network ls 或是 docker network list 可以查看 Docker 中已经存在的网络。 1234$ sudo docker network lsNETWORK ID NAME DRIVER SCOPEbc14eb1da66b bridge bridge local35c3ef1cc27d individual bridge local 之后在我们创建容器时，可以通过 --network 来指定容器所加入的网络，一旦这个参数被指定，容器便不会默认加入到 bridge 这个网络中了 ( 但是仍然可以通过 --network bridge 让其加入 )。 1$ sudo docker run -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=yes --network individual mysql:5.7 我们通过 docker inspect 观察一下此时的容器网络。 123456789101112131415161718192021222324252627282930$ sudo docker inspect mysql[ &#123;## ...... &quot;NetworkSettings&quot;: &#123;## ...... &quot;Networks&quot;: &#123; &quot;individual&quot;: &#123; &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: [ &quot;2ad678e6d110&quot; ], &quot;NetworkID&quot;: &quot;35c3ef1cc27d24e15a2b22bdd606dc28e58f0593ead6a57da34a8ed989b1b15d&quot;, &quot;EndpointID&quot;: &quot;41a2345b913a45c3c5aae258776fcd1be03b812403e249f96b161e50d66595ab&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot;, &quot;IPAddress&quot;: &quot;172.18.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;DriverOpts&quot;: null &#125; &#125;## ...... &#125;## ...... &#125;] 可以看到，容器所加入网络已经变成了 individual 这个网络了。 这时候我们通过 --link 让处于另外一个网络的容器连接到这个容器上，看看会发生什么样的效果。 123$ sudo docker run -d --name webapp --link mysql --network bridge webapp:latestdocker: Error response from daemon: Cannot link to /mysql, as it does not belong to the default network.ERRO[0000] error waiting for container: context canceled 可以看到容器并不能正常的启动，而 Docker 提醒我们两个容器处于不同的网络，之间是不能相互连接引用的。 我们来改变一下，让运行 Web 应用的容器加入到 individual 这个网络，就可以成功建立容器间的网络连接了。 1$ sudo docker run -d --name webapp --link mysql --network individual webapp:latest 端口映射刚才我们提及的都是容器直接通过 Docker 网络进行的互相访问，在实际使用中，还有一个非常常见的需求，就是我们需要在容器外通过网络访问容器中的应用。最简单的一个例子，我们提供了 Web 服务，那么我们就需要提供一种方式访问运行在容器中的 Web 应用。 在 Docker 中，提供了一个端口映射的功能实现这样的需求。 通过 Docker 端口映射功能，我们可以把容器的端口映射到宿主操作系统的端口上，当我们从外部访问宿主操作系统的端口时，数据请求就会自动发送给与之关联的容器端口。 要映射端口，我们可以在创建容器时使用 -p 或者是 --publish 选项。 1$ sudo docker run -d --name nginx -p 80:80 -p 443:443 nginx:1.12 使用端口映射选项的格式是 -p &lt;ip&gt;:&lt;host-port&gt;:&lt;container-port&gt;，其中 ip 是宿主操作系统的监听 ip，可以用来控制监听的网卡，默认为 0.0.0.0，也就是监听所有网卡。host-port 和 container-port 分别表示映射到宿主操作系统的端口和容器的端口，这两者是可以不一样的，我们可以将容器的 80 端口映射到宿主操作系统的 8080 端口，传入 -p 8080:80 即可。 我们可以在容器列表里看到端口映射的配置。 123$ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbc79fc5d42a6 nginx:1.12 &quot;nginx -g &apos;daemon of…&quot; 4 seconds ago Up 2 seconds 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp nginx 打印的结果里用 -&gt; 标记了端口的映射关系。 在 Windows 和 macOS 中使用映射Docker 的端口映射功能是将容器端口映射到宿主操作系统的端口上，实际来说就是映射到了 Linux 系统的端口上。而我们知道，在 Windows 和 macOS 中运行的 Docker，其 Linux 环境是被虚拟出来的，如果我们仅仅是将端口映射到 Linux 上，由于虚拟环境还有一层隔离，我们依然不能通过 Windows 或 macOS 的端口来访问容器。 解决这种问题的方法很简单，只需要再加一次映射，将虚拟 Linux 系统中的端口映射到 Windows 或 macOS 的端口即可。 如果我们使用 Docker for Windows 或 Docker for Mac，这个端口映射的操作程序会自动帮助我们完成，所以我们不需要做任何额外的事情，就能够直接使用 Windows 或 macOS 的端口访问容器端口了。 而当我们使用 Docker Toolbox 时，由于其自动化能力比较差，所以需要我们在 VirtualBox 里单独配置这个操作系统端口到 Linux 端口的映射关系。 在 VirtualBox 配置中的端口转发一栏里，进行相关的配置即可。 留言互动在本节中，我们了解了 Docker 网络相关的知识和操作。这里给大家留一道思考题： 通过 Docker 网络进行的容器互联，与通过宿主机进行端口映射的容器互联有怎样的区别，又各有怎样的优劣？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对容器网络的概念或者使用方法还有什么不解之处，或者对其有独特的见解，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F07%2F%E4%BD%BF%E7%94%A8%E5%AE%B9%E5%99%A8%EF%BC%9A%E4%BB%8E%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E8%8E%B7%E5%BE%97%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[从镜像仓库获得镜像之前我们说到了，Docker 与其他虚拟化软件的一处不同就是将镜像管理纳入到了功能之中。实现虚拟化只是程序能够无缝移植的一部分，而有了镜像管理，就真正取代了我们在移植过程中的繁琐操作。利用 Docker 的镜像管理功能，我们可以很方便的通过网络传输和分享镜像，并保障镜像内容的一致性。所以，了解 Docker 的镜像管理方法可以算是掌握 Docker 的第一步。 镜像仓库在之前的小节里，我们已经提到过 Docker 里集中存放镜像的一个概念，也就是镜像仓库。 如果说我们把镜像的结构用 Git 项目的结构做类比，那么镜像仓库就可以看似 GitLab、GitHub 等的托管平台，只不过 Docker 的镜像仓库托管的不是代码项目，而是镜像。 当然，存储镜像并不是镜像仓库最值得炫耀的功能，其最大的作用是实现了 Docker 镜像的分发。借助镜像仓库，我们得到了一个镜像的中转站，我们可以将开发环境上所使用的镜像推送至镜像仓库，并在测试或生产环境上拉取到它们，而这个过程仅需要几个命令，甚至自动化完成。 获取镜像虽然有很多种方式将镜像引入到 Docker 之中，但我们最为常用的获取现有镜像的方式还是直接从镜像仓库中拉取，因为这种方式简单、快速、有保障。 要拉取镜像，我们可以使用 docker pull 命令，命令的参数就是我们之前所提到的镜像仓库名。 12345678$ sudo docker pull ubuntuUsing default tag: latestlatest: Pulling from library/ubuntu124c757242f8: Downloading [===============================================&gt; ] 30.19MB/31.76MB9d866f8bde2a: Download complete fa3f2f277e67: Download complete 398d32b153e8: Download complete afde35469481: Download complete 当我们运行这个命令后，Docker 就会开始从镜像仓库中拉取我们所指定的镜像了，在控制台中，我们可以看到镜像拉取的进度。下载进度会分为几行，其实每一行代表的就是一个镜像层。Docker 首先会拉取镜像所基于的所有镜像层，之后再单独拉取每一个镜像层并组合成这个镜像。当然，如果在本地已经存在相同的镜像层 ( 共享于其他的镜像 )，那么 Docker 就直接略过这个镜像层的拉取而直接采用本地的内容。 上面是一个拉取官方镜像并且没有给出镜像标签的例子，大家注意到，当我们没有提供镜像标签时，Docker 会默认使用 latest 这个标签，这个我们在之前的小节中提到过，就不在赘述了。 当然，我们也能够使用完整的镜像命名来拉取镜像。 12345678$ sudo docker pull openresty/openresty:1.13.6.2-alpine1.13.6.2-alpine: Pulling from openresty/openrestyff3a5c916c92: Pull complete ede0a2a1012b: Pull complete 0e0a11843023: Pull complete 246b2c6f4992: Pull complete Digest: sha256:23ff32a1e7d5a10824ab44b24a0daf86c2df1426defe8b162d8376079a548bf2Status: Downloaded newer image for openresty/openresty:1.13.6.2-alpine 镜像在被拉取之后，就存放到了本地，接受当前这个 Docker 实例管理了，我们可以通过 docker images 命令看到它们。 1234$ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEubuntu latest cd6d8154f1e1 12 days ago 84.1MBopenresty/openresty 1.13.6.2-alpine 08d5c926e4b6 3 months ago 49.3MB Docker Hub既然说到镜像仓库，就不得不提 Docker Hub 了。Docker Hub 是 Docker 官方建立的中央镜像仓库，除了普通镜像仓库的功能外，它内部还有更加细致的权限管理，支持构建钩子和自动构建，并且有一套精致的 Web 操作页面。 Docker Hub 的地址是：https://hub.docker.com/ 由于定位是 Docker 的中央镜像仓库系统，同时也是 Docker Engine 的默认镜像仓库，所以 Docker Hub 是开发者共享镜像的首选，那么也就意味着其中的镜像足够丰富。 常用服务软件的镜像，我们都能在 Docker Hub 中找到，甚至能找到针对它们不同用法的不同镜像。 同时，Docker Hub 也允许我们将我们制作好的镜像上传到其中，与广大 Docker 用户共享你的成果。 搜索镜像由于 Docker Hub 提供了一套完整的 Web 操作界面，所以我们搜索其中的镜像会非常方便。 在上方的搜索条中输入镜像的关键词，回车搜索我们就可以看到镜像搜索的结果了。 在 Docker Hub 的搜索结果中，有几项关键的信息有助于我们选择合适的镜像： OFFICIAL 代表镜像为 Docker 官方提供和维护，相对来说稳定性和安全性较高 STARS 代表镜像的关注人数，这类似 GitHub 的 Stars，可以理解为热度 PULLS 代表镜像被拉取的次数，基本上能够表示镜像被使用的频度 当然，关于镜像更多的信息我们可以在 DETAILS 中看到，这其中通常还包括了每个镜像不同的使用方法。具体如何阅读这些使用说明，我们会在之后的小节里专门介绍。 除了直接通过 Docker Hub 网站搜索镜像这种方式外，我们还可以用 docker CLI 中的 docker search 这个命令搜索 Docker Hub 中的镜像。 12345678910$ sudo docker search ubuntuNAME DESCRIPTION STARS OFFICIAL AUTOMATEDubuntu Ubuntu is a Debian-based Linux operating sys… 8397 [OK] dorowu/ubuntu-desktop-lxde-vnc Ubuntu with openssh-server and NoVNC 220 [OK]rastasheep/ubuntu-sshd Dockerized SSH service, built on top of offi… 171 [OK]consol/ubuntu-xfce-vnc Ubuntu container with &quot;headless&quot; VNC session… 129 [OK]ansible/ubuntu14.04-ansible Ubuntu 14.04 LTS with ansible 95 [OK]ubuntu-upstart Upstart is an event-based replacement for th… 89 [OK] neurodebian NeuroDebian provides neuroscience research s… 54 [OK] ## ...... 使用 docker search 命令，我们可以得到一个类似于 Docker Hub 网页版搜索的镜像列表结果，其中的信息与网页版也是类似的。通过这种方式我们可以在不方便访问 Web 的环境下搜索镜像，对于控制台爱好者来说也是一种不错的选择。 管理镜像对镜像的管理要比搜索和获取镜像更常用，所以了解镜像管理相关的操作以及知识是非常有必要的。 除了之前我们所提到的 docker images 可以列出本地 Docker 中的所有镜像外，如果我们要获得镜像更详细的信息，我们可以通过 docker inspect 这个命令。 12345678910111213$ sudo docker inspect redis:3.2[ &#123; &quot;Id&quot;: &quot;sha256:2fef532eadb328740479f93b4a1b7595d412b9105ca8face42d3245485c39ddc&quot;, &quot;RepoTags&quot;: [ &quot;redis:3.2&quot; ], &quot;RepoDigests&quot;: [ &quot;redis@sha256:745bdd82bad441a666ee4c23adb7a4c8fac4b564a1c7ac4454aa81e91057d977&quot; ],## ...... &#125;] 在 docker inspect 的结果中我们可以看到关于镜像相当完备的信息，由于条目分类比较多，这里我就不一一罗列展开了。 除了能够查看镜像的信息外，docker inspect 还能查看容器等之前我们所提到的 Docker 对象的信息，而传参的方式除了传递镜像或容器的名称外，还可以传入镜像 ID 或容器 ID。 12$ sudo docker inspect redis:4.0$ sudo docker inspect 2fef532e 参数识别细心的读者在这里一定发现了一个细节，之前我们所谈到镜像 ID 是 64 个字符，而 docker images 命令里的缩写也有 12 个字符，为什么我这里展示的操作命令里只填写了 8 个字符呢？ 这就有必要专门说说 Docker 所支持的这种传参方式了。 不论我们是通过镜像名还是镜像 ID 传递到 docker inspect 或者其他类似的命令 ( 需要指定 Docker 对象的命令 ) 里，Docker 都会根据我们传入的内容去寻找与之匹配的内容，只要我们所给出的内容能够找出唯一的镜像，那么 Docker 就会对这个镜像执行给定的操作。反之，如果找不到唯一的镜像，那么操作不会进行，Docker 也会显示错误。 也就是说，只要我们提供了能够唯一识别镜像或容器的信息，即使它短到只有 1 个字符，Docker 都是可以处理的。 例如我们有五个镜像： 1234567REPOSITORY TAG IMAGE ID CREATED SIZEphp 7-fpm f214b5c48a25 11 days ago 368MBubuntu latest cd6d8154f1e1 13 days ago 84.1MBredis 3.2 2fef532eadb3 13 days ago 76MBredis 4.0 e1a73233e3be 13 days ago 83.4MBopenresty/openresty 1.13.6.2-alpine 08d5c926e4b6 3 months ago 49.3MBcogset/cron latest c01d5ac6fc8a 16 months ago 125MB 我们注意到镜像 ID 前缀为 2 的只有 redis:3.2 这个镜像，那么我们就可以使用 2 来指代这个镜像。 1$ sudo docker inspect 2 而前缀为 c 的镜像有两个，这时候如果我们直接使用 c 来指代镜像的话，Docker 会提示未能匹配到镜像。 123$ sudo docker inspect c[]Error: No such object: c 删除镜像虽然 Docker 镜像占用的空间比较小，但日渐冗杂的镜像和凌乱的镜像版本会让管理越来越困难，所以有时候我们需要清理一些无用的镜像，将它们从本地的 Docker Engine 中移除。 删除镜像的命令是 docker rmi，参数是镜像的名称或 ID。 123456789$ sudo docker rmi ubuntu:latestUntagged: ubuntu:latestUntagged: ubuntu@sha256:de774a3145f7ca4f0bd144c7d4ffb2931e06634f11529653b23eba85aef8e378Deleted: sha256:cd6d8154f1e16e38493c3c2798977c5e142be5e5d41403ca89883840c6d51762Deleted: sha256:2416e906f135eea2d08b4a8a8ae539328482eacb6cf39100f7c8f99e98a78d84Deleted: sha256:7f8291c73f3ecc4dc9317076ad01a567dd44510e789242368cd061c709e0e36dDeleted: sha256:4b3d88bd6e729deea28b2390d1ddfdbfa3db603160a1129f06f85f26e7bcf4a2Deleted: sha256:f51700a4e396a235cee37249ffc260cdbeb33268225eb8f7345970f5ae309312Deleted: sha256:a30b835850bfd4c7e9495edf7085cedfad918219227c7157ff71e8afe2661f63 删除镜像的过程其实是删除镜像内的镜像层，在删除镜像命令打印的结果里，我们可以看到被删除的镜像层以及它们的 ID。当然，如果存在两个镜像共用一个镜像层的情况，你也不需要担心 Docker 会删除被共享的那部分镜像层，只有当镜像层只被当前被删除的镜像所引用时，Docker 才会将它们从硬盘空间中移除。 docker rmi 命令也支持同时删除多个镜像，只需要通过空格传递多个镜像 ID 或镜像名即可。 123456789$ sudo docker rmi redis:3.2 redis:4.0Untagged: redis:3.2Untagged: redis@sha256:745bdd82bad441a666ee4c23adb7a4c8fac4b564a1c7ac4454aa81e91057d977Deleted: sha256:2fef532eadb328740479f93b4a1b7595d412b9105ca8face42d3245485c39ddc## ......Untagged: redis:4.0Untagged: redis@sha256:b77926b30ca2f126431e4c2055efcf2891ebd4b4c4a86a53cf85ec3d4c98a4c9Deleted: sha256:e1a73233e3beffea70442fc2cfae2c2bab0f657c3eebb3bdec1e84b6cc778b75## ...... 留言互动在本节中，我们对镜像的获取和其他一些关于镜像的基本操作进行了使用展示，介绍了 Docker 的官方镜像仓库 Docker Hub，简单概述了镜像与镜像仓库的关系。这里给大家留一道思考题： Docker 中镜像仓库这项功能设计，在实际工作中能够为我们带来哪些具体的便利？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对镜像的操作与使用还有什么不理解的地方，或者对其有独特的见解，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。]]></content>
  </entry>
  <entry>
    <title><![CDATA[验证码输入框]]></title>
    <url>%2F2018%2F12%2F03%2F%E9%AA%8C%E8%AF%81%E7%A0%81%E8%BE%93%E5%85%A5%E6%A1%86%2F</url>
    <content type="text"><![CDATA[前言 最近项目中有一个类似于付款的时候需要输入密码一样的控件，不过我们是输入验证码。在google上搜索了很多类似的博客，发现大部分都是通过放置多个TextView，然后放一个隐藏的EditText获取焦点的形式实现的，想着这样还不如自己撸一个控件，于是就有了这篇文章。 如何使用 通过gradle引入控件就可以使用了。1implementation 'com.fxyan.widget:validationCodeView:1.0.2' 项目地址 思考 在写之前，我们先思考一下主要需要解决的问题有哪些？ 如何让View点击时获取到焦点并弹起数字软键盘； 如何监听软键盘上的输入以及删除； 如何处理 对于第一个问题，首先，我们得让View可以通过点击获取到焦点。12setFocusable(true);setFocusableInTouchMode(true); 然后，我们在onTouchEvent的ACTION_DOWN事件处理中，获取焦点，并弹起输入法软键盘。123456789@Overridepublic boolean onTouchEvent(MotionEvent event) &#123; if (event.getAction() == MotionEvent.ACTION_DOWN) &#123; requestFocus(); imm.showSoftInput(this, InputMethodManager.SHOW_FORCED); return true; &#125; return super.onTouchEvent(event);&#125; 最后，我们希望弹起的软键盘的输入类型是数字的。12345@Overridepublic InputConnection onCreateInputConnection(EditorInfo outAttrs) &#123; outAttrs.inputType = InputType.TYPE_CLASS_NUMBER; return super.onCreateInputConnection(outAttrs);&#125; 对于第二个问题，我们需要在View中设置KeyListener，然后处理数字输入和Del。12345678910111213141516171819202122232425262728293031private class InputKeyListener implements View.OnKeyListener &#123; @Override public boolean onKey(View v, int keyCode, KeyEvent event) &#123; if (event.getAction() == KeyEvent.ACTION_DOWN) &#123; if (keyCode &gt;= KeyEvent.KEYCODE_0 &amp;&amp; keyCode &lt;= KeyEvent.KEYCODE_9) &#123; if (content.size() &lt; itemCount) &#123; content.put(content.size(), String.valueOf(keyCode - 7)); invalidate(); if (content.size() == itemCount) &#123; if (onInputCompletedListener != null) &#123; StringBuilder builder = new StringBuilder(); for (int i = 0; i &lt; content.size(); i++) &#123; builder.append(content.get(i)); &#125; onInputCompletedListener.onInputCompleted(builder.toString()); &#125; imm.hideSoftInputFromWindow(getWindowToken(), 0); &#125; return true; &#125; &#125; else if (keyCode == KeyEvent.KEYCODE_DEL) &#123; if (content.size() &gt; 0) &#123; content.remove(content.size() - 1); invalidate(); &#125; return true; &#125; &#125; return false; &#125;&#125; 属性说明 需要注意的大致上就这两个问题，其他的东西都是结合Canvas API去绘制相应的图形和文本了。 vcvItemCount验证码位数 vcvItemWidth单个验证码框宽度 vcvItemHeight单个验证码框高度 vcvItemDistance两个验证码框之间的距离 vcvBorderWidth验证码框的宽度 vcvBorderStyle验证码框的样式(矩形，线) vcvBorderRadius框为矩形时候的圆角 vcvContentStatus验证码的显示状态(明文，密码) vcvContentSize验证码为明文时的文本大小 vcvContentRadiusWhenIsHidden验证码为密文时候的圆半径 vcvCompletedBorderColor已填写内容的边框颜色 vcvCompletedContentColor已填写的文本颜色 vcvUnCompleteBorderColor未填写内容的边框颜色 vcvIsAheadDraw是否提前渲染一个框 效果图 效果图如下]]></content>
  </entry>
  <entry>
    <title><![CDATA[MultiDex]]></title>
    <url>%2F2018%2F11%2F21%2FMultiDex%2F</url>
    <content type="text"><![CDATA[先说下为什么有这篇文章，app刚完成第一版开发(笔者内心是非常崩溃的，接手的项目其实前景还不错，但是第一版被玩坏了，做第一版的产品，UI，测试，开发都走了，然后来接手这个项目，全是一脸懵逼，前期规划的太烂)，然后运营也开始进行培训，刚好白天运营同事拿过来一款手机，Android4.4的版本，然后运行app就闪退，于是开始寻找这个原因就有了这篇文章。 5.0以前 先说下，在Android5.0以前，Android使用的是dalvik虚拟机，而dalvik虚拟机为每一个apk只生成一个classes.dex文件(dex全称Dalvik Executable Format，是java文件编译后的class文件的集合)。那么重点来了，这个dex文件它所保存的classes的方法个数是0~65535，随着业务的不断增加，迟早有一天会超过这个限制，那么该怎么解决方法数64k的限制呢？这个时候就出现了multidex这个东西。 5.0以后 前面说了Android5.0版本之前使用的是Dalvik虚拟机，对每个apk只会生成一个classes.dex文件。而Android5.0开始，使用的是ART(Android Runtime)，它本身支持从APK加载多个DEX文件，它会在apk安装的时候执行一次预编译，如果发现有多个dex文件，它会将其整合成一个.oat的文件供Android设备执行。因此如果minSdkVersion高于Android5.0，就不需要multidex库的支持。 配置multidexminSdkVersion21或更高 如果minSdkVersion为21或者更高，我们只需要在app的build.gradle文件下配置multiDexEnable为true即可。123456789android &#123; defaultConfig &#123; ... minSdkVersion 21 targetSdkVersion 28 multiDexEnabled true &#125; ...&#125; minSdkVersion低于21 如果minSdkVersion低于21，那么我们需要使用multidex support library。首先，修改build.gradle文件。12345678910111213android &#123; defaultConfig &#123; ... minSdkVersion 15 targetSdkVersion 28 multiDexEnabled true &#125; ...&#125;dependencies &#123; compile 'com.android.support:multidex:1.0.3'&#125; 然后修改Application。 如果没有重写Application，我们需要在AndroidManifest.xml文件中指定application标签的name属性为MultiDexApplication； 12345678&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;manifest xmlns:android="http://schemas.android.com/apk/res/android" package="com.example.myapp"&gt; &lt;application android:name="android.support.multidex.MultiDexApplication" &gt; ... &lt;/application&gt;&lt;/manifest&gt; 如果重写了Application，可以让其继承MultiDexApplication； 1public class MyApplication extends MultiDexApplication &#123; ... &#125; 如果既重写了Application，又继承了其他的Application，那么可以使用multiDex.install(context)的方式。 1234567public class MyApplication extends SomeOtherApplication &#123; @Override protected void attachBaseContext(Context base) &#123; super.attachBaseContext(base); MultiDex.install(this); &#125;&#125; 注意一点，不要在MultiDex.install()方法之前通过反射或者JNI执行任何代码，这会导致出现ClassNotFoundException。 然后我们再构建项目，它会生成一个primary dex(classes.dex)，和若干个support dex(classes2.dex…)，最后构建系统会将这些dex文件打包到apk中。在运行的时候，multidex APIs会使用特定的类加载器检索所有可用的DEX文件，而不仅仅只是在主classes.dex文件中进行检索。 官方文档https://developer.android.google.cn/studio/build/multidex#abouthttps://developer.android.com/studio/build/multidex#about]]></content>
  </entry>
  <entry>
    <title><![CDATA[INSTALL_FAILED_CONFLICTING_PROVIDER]]></title>
    <url>%2F2018%2F11%2F20%2FINSTALL-FAILED-CONFLICTING-PROVIDER%2F</url>
    <content type="text"><![CDATA[前言 首先，我们项目分为三个环境，开发环境，测试环境，生产环境。测试人员是在测试环境进行测试，而运营那边使用的试生产环境的app，然后测试同学说，运营那边在使用的时候如果遇到什么问题，他需要下载一个生产环境的包去上面进行验证，但是这样就会导致本地的测试环境的包被覆盖掉了，希望能够在手机上装两个相同的app。于是乎，为了满足测试小姐姐的这个需求，在修改的过程中就有了下面的问题。 产生原因 平常我们在做app开发过程中，可能自己编写ContentProvider的情况比较少，所以可能碰到这种情况的比较少，但是android7.0的严格模式，外部app无法访问本app的私有目录，我们得通过FileProvider进行目录共享，而FileProvider就是继承ContentProvider的。我们需要在AndroidManifest.xml文件中配置provider节点。1234567&lt;provider android:authorities="com.fxyan.demo.fileProvider" android:name="android.support.v4.content.FileProvider" android:exported="false" android:grantUriPermissions="true"&gt; &lt;meta-data android:name="FILE_PROVIDER_PATHS" android:resource="@xml/file_provider_paths"/&gt;&lt;/provider&gt; 而每个provider是需要指定一个authorities的，这个值在Android系统中必须是唯一的。为了满足测试小姐姐的需求，我在build.gradle文件中配置了多个buildType，对每个buildType增加了一个applicationIdSuffix，如下所示。1234567debug &#123; applicationIdSuffix ".debug" //...&#125;release &#123; //...&#125; 比如，我们项目的applicationId为”com.fxyan.deom”，那么你在打debug包的时候，apk的applicationId就是”com.fxyan.demo.debug”，这样就保证debug包和release在手机上能够同时存在。 但是结果并不如意，我在装两个包的时候，AS弹出了如下的对话框。 这就是我前面说到的，因为我们配置的provider的authorities是一个硬编码的字符串，我们应该让其跟着applicationId来变动。1234567&lt;provider android:authorities=$&#123;applicationId&#125;.fileProvider" android:name="android.support.v4.content.FileProvider" android:exported="false" android:grantUriPermissions="true"&gt; &lt;meta-data android:name="FILE_PROVIDER_PATHS" android:resource="@xml/file_provider_paths"/&gt;&lt;/provider&gt; 像上面这样修改之后，再次安装就可以了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[jenkins构建Android自动化打包]]></title>
    <url>%2F2018%2F11%2F20%2Fjenkins%E6%9E%84%E5%BB%BAAndroid%E8%87%AA%E5%8A%A8%E5%8C%96%E6%89%93%E5%8C%85%2F</url>
    <content type="text"><![CDATA[前言 为什么要弄jenkins自动化打包，其一，使用jenkins自动打包是在服务器上进行的，不占用自己电脑的资源；其二，简化流程，比如没用jenkins之前，我们要将包放到蒲公英上，需要先打包，然后再到蒲公英上上传应用，巴拉巴拉一大推流程，但是使用jenkins配置构建job，我们就可以不用关心上面的这一系列流程，它会帮助我们自动完成构建，上传等操作。 配置流程安装jenkins 笔者是mac os的系统，安装jenkins可以使用如下的命令进行。1$ brew install jenkins 或者你也可以到jenkins的官网上下载，然后进行安装，是一样的。 配置job 这里我就不细说jenkins的安装过程了， 比较简单，在下载插件的时候，如果不明确的知道自己需要哪些插件，可以选择推荐的插件安装就可以了，一般我们需要用到的都会有。 新建job 在dashboard界面，我们选择New Item选项，如下图所示。 然后输入job名称，选择Freestyle project，然后点击ok就可以了。 配置源码 在新建完成job之后，我们会进入到job的配置界面，然后第一步，我们需要配置构建的源码来源，这里笔者是使用git版本管理工具的，首先切换到Source Code Management。 然后选择Git，输入Git仓库地址，如下所示。 因为jenkins需要从git仓库中pull代码，然后进行构建，所以我们需要将git的ssh的私钥配置在jenkins上，以便job可以成功的从远程仓库拉取代码。如下图所示，这里需要选择SSH Username with primary key，然后将私钥配置在primary key里面。 配置gradle 配置完源码来源后，我们将tab切换到build下面，来配置gradle的一些信息。 默认情况下，jenkins是没有下载gradle的，我们可以配置命令自动进行下载，也可以在全局设置中先下载，然后在上面的配置界面中选择已有的gradle版本进行构建。 这里记得勾选自动下载。 上传蒲公英 笔者这边以蒲公英做示例，首先我们需要到插件管理下面下载”Upload To Pgyer”插件。 因为笔者这里已经是安装了这个插件的，实际上安装的时候是在available下面进行搜索安装的。 下载完成插件，我们再回到job的配置界面，选择Post-build Actions，表示在构建完成后做什么事情。然后添加action，选择upload to pgyer，笔者这里选择的是with api2，需要配置pgyer api_key，这个可以在蒲公英的用户账号设置里面找到。 运行job 上面的配置基本上完成了一大半，剩下的就是在构建的过程中进行填坑了。通过Build Now，我们新建一个构建任务。 通过console我们可以看到，没有找到sdk，我们可以通过local.property或者是指定一个ANDROID_HOME的环境变量。这里笔者选择了后者。 添加完环境变量之后我们再次运行。依旧是构建失败，这次log中提示找不到配置的ANDROID_HOME对应的目录。 但是实际上这个目录是存在的，于是笔者怀疑应该是目录访问权限限制了。于是乎去对应的路径下修改了权限。chmod命令我就不多说了。修改完访问权限，我们再次构建job就成功了。 扩展构建参数 上面只是完成了一个job的简单配置，我们构建命令也只是简单的使用了assembleRelease。显然这是不够的，比如我们现在项目中配置了很多的渠道，或者buildTypes，这个时候我们想要打某个渠道的包，或者某个buildType的apk包那该如何是好？ 在job的的配置界面第一个tab下，勾选this project is parameterized，如下所示，这里笔者选择choice parameters。 然后我们增加两个参数选择，一个debug，一个release，如下所示。 别忘了还需要修改gradle的构建命令，和配置的参数相关联。 然后我们再来看看Build Now，这里变成了一个可选择的。 触发器 构建触发器是指什么时候进行构建，比如我们可以指定当源码更新的时候就出发构建；或者是在每天的凌晨两点开始构建等等，这就是构建触发器。在job的配置界面，我们可以看到第三个tab，Build Triggers。 比如我们这里配置每天凌晨两点钟构建一次，可以配置成如下的样子。 具体的参数配置可以参考jenkins定时任务的官方文档说明。]]></content>
  </entry>
  <entry>
    <title><![CDATA[全屏模式和adjustResize的冲突]]></title>
    <url>%2F2018%2F11%2F16%2F%E5%85%A8%E5%B1%8F%E6%A8%A1%E5%BC%8F%E5%92%8CadjustResize%E7%9A%84%E5%86%B2%E7%AA%81%2F</url>
    <content type="text"><![CDATA[问题 之前在写Window那一节的SoftInputMode的时候有提到过关于全屏模式和adjustResize的问题。平常我们开发过程中，经常会做状态栏的沉浸式，笔者一般使用沉浸式的方式是让布局全屏展示，然后单独写一个title的布局，在代码中让其设置一个状态栏高度的padding值，这样就简单的达到了状态栏沉浸式的效果。想法很美好，显示很骨感，这样做导致了一个问题，如果页面上有需要输入的东西，即使你设置softInputMode为adjustResize，也不会生效。应该是Android系统的一个bug，这里附上链接。 方案 这里先附上一个没有进行校准的效果。 我们在Activity中设置了如下代码，但是看效果图发现并没有什么卵用。1getWindow().setSoftInputMode(WindowManager.LayoutParams.SOFT_INPUT_STATE_ALWAYS_VISIBLE | WindowManager.LayoutParams.SOFT_INPUT_ADJUST_RESIZE); 既然如此，笔者想能否通过监听软键盘的弹起和落下来动态的改变LayoutParam的height值，朝着这个方向，就有了接下来的方法。 首先，我们给根布局设置一个监听事件12345678ViewGroup vp = findViewById(android.R.id.content);vp.getViewTreeObserver().addOnGlobalLayoutListener(new ViewTreeObserver.OnGlobalLayoutListener()&#123; @Override public void onGlobalLayout() &#123; &#125;&#125;); 然后，我们要想办法监听到软键盘的弹起和落下，这里笔者通过布局可视高度的变化来进行判断。1234567891011121314151617181920Rect rect = new Rect();int visibleHeight = 0;@Overridepublic void onGlobalLayout() &#123; vp.getWindowVisibleDisplayFrame(rect); if (visibleHeight == 0) &#123; visibleHeight = rect.bottom; &#125; else if (visibleHeight - rect.bottom &gt; 200) &#123; // 这里键盘弹起来 visibleHeight = rect.bottom; lp.height = visibleHeight; vp.requestLayout(); &#125; else if (rect.bottom - visibleHeight &gt; 200) &#123; // 这里键盘落下去 visibleHeight = rect.bottom; lp.height = visibleHeight; vp.requestLayout(); &#125;&#125; 最后运行下来看看效果图。]]></content>
  </entry>
  <entry>
    <title><![CDATA[关于sw限定符适配]]></title>
    <url>%2F2018%2F11%2F08%2F%E5%85%B3%E4%BA%8Esw%E9%99%90%E5%AE%9A%E7%AC%A6%E9%80%82%E9%85%8D%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[Could not find lint-gradle-api]]></title>
    <url>%2F2018%2F10%2F31%2FCould-not-find-lint-gradle-api%2F</url>
    <content type="text"><![CDATA[问题所在 这几天刚把Flutter的开发环境搭建好，准备学习Flutter。搭建开发环境，可以参考Flutter文档上面的内容，写的还是非常详细的。 于是我新建了一个flutter的项目，然后运行该项目，结果给了我如下的错误。 从日志上来看，是flutter在构建项目的时候找不到lint-gradle-api.jar，那么就得想办法让flutter在构建的时候能够访问到这个jar包才行。通过google我这里提供两种方案。 方案一 首先找到你的flutter的安装目录，如果不知道在哪里的，可以通过terminal的命令找到安装目录。1$ which flutter 找到安装目录之后，我们进入到flutter的目录下，然后进入到flutter/packages/flutter_tools/gradle/这个目录下，你会发现这个目录下面有一个flutter.gralde文件。然后我们找到下面代码所在的位置。1234567891011buildscript &#123; repositories &#123; jcenter() maven &#123; url 'https://dl.google.com/dl/android/maven2' &#125; &#125; dependencies &#123; classpath 'com.android.tools.build:gradle:3.1.2' &#125;&#125; 第一种方案非常简单只需要在jcenter()之前加上google()就可以了，然后去运行你的flutter项目。123456789101112buildscript &#123; repositories &#123; google() jcenter() maven &#123; url 'https://dl.google.com/dl/android/maven2' &#125; &#125; dependencies &#123; classpath 'com.android.tools.build:gradle:3.1.2' &#125;&#125; 方案二 如果还是无法找到lint-gradle-api.jar，那么这里再给你一个国内阿里的仓库地址。12345678910111213buildscript &#123; repositories &#123; maven&#123; url 'https://maven.aliyun.com/repository/jcenter' &#125; maven&#123; url 'http://maven.aliyun.com/nexus/content/groups/public' &#125; &#125; dependencies &#123; classpath 'com.android.tools.build:gradle:3.1.2' &#125;&#125; 配置成上面的maven仓库地址也是可以解决这个问题的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用gradle统一项目配置]]></title>
    <url>%2F2018%2F10%2F28%2F%E4%BD%BF%E7%94%A8gradle%E7%BB%9F%E4%B8%80%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[问题所在&ensp;&ensp;在项目开发过程中，经常会有很多的module，而每个module下面都会依赖一些library，当项目越来越大的时候，这种分散在每个module下面单独的gradle配置依赖库的方式就很难以进行管理。 解决方式&ensp;&ensp;我们可以通过gradle的ext变量来建立一个公用的配置，这样其他的module中的gralde配置从这个公用配置中获取需要的信息来完成自身module的配置。这样既能够保证每个module下的依赖库版本是一致的，而且管理起来也十分的方便。 build.gradle&ensp;&ensp;首先我们来看看一个module下面的build.gradle文件的依赖库配置(这里只是举个栗子，比较简单，请以实际开发为准)。12345678//supportimplementation "com.android.support:appcompat-v7:27.1.1"implementation "com.android.support:design:27.1.1"implementation "com.android.support:cardview-v7:27.1.1"//retrofitimplementation "com.squareup.retrofit2:retrofit:2.3.0"implementation "com.squareup.retrofit2:converter-gson:2.3.0"implementation "com.squareup.retrofit2:adapter-rxjava2:2.3.0" config.gradle&ensp;&ensp;然后我们在主工程的外层新建一个config.gradle(名字自取)文件，使用ext变量，它里面用map存放一些键值对的信息。下面是我写的一些配置。123456789101112131415161718192021222324252627282930ext &#123; versions = [ "android_support_version": "27.1.1", "retrofit_version" : "2.3.0" ] groups = [ "android_support": "com.android.support", "retrofit2" : "com.squareup.retrofit2" ] names = [ // support "appcompat_v7" : "appcompat-v7", "design" : "design", "cardview_v7" : "cardview-v7", // retrofit "retrofit" : "retrofit", "converter_gson" : "converter-gson", "adapter_rxjava2": "adapter-rxjava2" ] android_support = [ "appcompat_v7": "$&#123;groups.android_support&#125;:$&#123;names.appcompat_v7&#125;:$&#123;versions.android_support_version&#125;", "design" : "$&#123;groups.android_support&#125;:$&#123;names.design&#125;:$&#123;versions.android_support_version&#125;", "cardview_v7" : "$&#123;groups.android_support&#125;:$&#123;names.cardview_v7&#125;:$&#123;versions.android_support_version&#125;" ] retrofit2 = [ "retrofit" : "$&#123;groups.retrofit2&#125;:$&#123;names.retrofit&#125;:$&#123;versions.retrofit_version&#125;", "converter_gson" : "$&#123;groups.retrofit2&#125;:$&#123;names.converter_gson&#125;:$&#123;versions.retrofit_version&#125;", "adapter_rxjava2": "$&#123;groups.retrofit2&#125;:$&#123;names.adapter_rxjava2&#125;:$&#123;versions.retrofit_version&#125;", ]&#125; 引入config.gradle&ensp;&ensp;配置文件写完了，那么如何将其引入到工程中呢，这个时候我们需要在主工程的build.gradle文件开头添加如下一句话。1apply from : "config.gradle" 这样重新构建一下，就能够将config.gradle文件引入到主工程中了。 修改module的build.gradle&ensp;&ensp;接下来我们来修改刚才module中的build.gradle文件，如下所示。123456789101112def support = rootProject.ext.android_supportdef retrofit = rootProject.ext.retrofit2dependencies &#123; implementation support.appcompat_v7 implementation support.design implementation support.cardview_v7 implementation retrofit.retrofit implementation retrofit.converter_gson implementation retrofit.adapter_rxjava2&#125; &ensp;&ensp;修改完成后重新构建项目，ok，你会发现完全没有问题，这样我们就可以将其他module下的依赖库也通过相同的方式来引入，而当要修改依赖库版本相关信息的时候，只需要修改配置文件中的版本信息就可以了，这样是不是很方便呢？]]></content>
  </entry>
  <entry>
    <title><![CDATA[从源码角度看okhttp]]></title>
    <url>%2F2018%2F09%2F12%2F%E4%BB%8E%E6%BA%90%E7%A0%81%E8%A7%92%E5%BA%A6%E7%9C%8Bokhttp%2F</url>
    <content type="text"><![CDATA[举个栗子 okhttp是square公司开源的http请求框架，支持同步请求和异步请求，一般用法如下。123456789101112131415161718192021222324252627282930val client = OkHttpClient.Builder() .connectTimeout(60, TimeUnit.SECONDS) .readTimeout(60, TimeUnit.SECONDS) .writeTimeout(60, TimeUnit.SECONDS) .addInterceptor &#123; chain -&gt; val oldRequest: Request = chain.request() val newRequest: Request = oldRequest.newBuilder() .addHeader("accessToken", "xxx") .build() chain.proceed(newRequest) &#125; .build()val request = Request.Builder() .url("xxx") .get() .build()val call = client.newCall(request)//同步请求//call.execute()//异步请求call.enqueue(object : Callback &#123; override fun onFailure(call: Call?, e: IOException?) &#123; //失败 &#125; override fun onResponse(call: Call?, response: Response?) &#123; //成功 &#125;&#125;) 可以看到，使用okhttp的一般步骤如下： 构建OkHttpClient对象，并配置相关的参数； 构建Request请求； 构建Call对象； 执行execute()同步请求或者执行enqueue()异步请求 OkHttpClient 典型的Builder模式，我们可以通过构建OkHttpClient.Builder来配置一些参数信息。12345678910111213141516171819202122public Builder() &#123; dispatcher = new Dispatcher();//网络请求的分发器 protocols = DEFAULT_PROTOCOLS;//支持http1.1，http2.0 connectionSpecs = DEFAULT_CONNECTION_SPECS; eventListenerFactory = EventListener.factory(EventListener.NONE); proxySelector = ProxySelector.getDefault(); cookieJar = CookieJar.NO_COOKIES; socketFactory = SocketFactory.getDefault(); hostnameVerifier = OkHostnameVerifier.INSTANCE; certificatePinner = CertificatePinner.DEFAULT; proxyAuthenticator = Authenticator.NONE; authenticator = Authenticator.NONE; connectionPool = new ConnectionPool(); dns = Dns.SYSTEM; followSslRedirects = true; followRedirects = true; retryOnConnectionFailure = true;//失败重连 connectTimeout = 10_000;//默认连接超时10s readTimeout = 10_000;//默认读取超时10s writeTimeout = 10_000;//默认写入超时10s pingInterval = 0;&#125; Request Request表示一个请求，请求一般包括url，method，header等，我们可以看看Request的成员定义。1234final HttpUrl url;//请求的urlfinal String method;//请求方式 get/post/put/delete 等final Headers headers;//请求头final @Nullable RequestBody body;//请求体 Call它是一个接口。12345678910111213141516171819202122232425public interface Call extends Cloneable &#123; Request request(); //同步请求 Response execute() throws IOException; //异步请求 void enqueue(Callback responseCallback); //取消请求 void cancel(); //如果Call已经调用了execute()或者enqueue()，则返回true boolean isExecuted(); //是否已经取消了 boolean isCanceled(); //使用当前Call创建一个新的Call Call clone(); interface Factory &#123; Call newCall(Request request); &#125;&#125; 我们可以看看OkHttpClient的newCall(Request)方法。123@Override public Call newCall(Request request) &#123; return RealCall.newRealCall(this, request, false /* for web socket */);&#125; 可以看到这里实际上是调用了RealCall的newRealCall()。 RealCall RealCall是Call的实现类，一般我们操作的实际上也是RealCall。这里我只粘贴比较有用的代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687final class RealCall implements Call &#123; final OkHttpClient client; final RetryAndFollowUpInterceptor retryAndFollowUpInterceptor; //事件监听器 private EventListener eventListener; //用来构建Call的Request final Request originalRequest; //当前Call是否已经执行，每个Call只能够被执行一次 private boolean executed; private RealCall(OkHttpClient client, Request originalRequest, boolean forWebSocket) &#123; this.client = client; this.originalRequest = originalRequest; this.forWebSocket = forWebSocket; this.retryAndFollowUpInterceptor = new RetryAndFollowUpInterceptor(client, forWebSocket); &#125; static RealCall newRealCall(OkHttpClient client, Request originalRequest, boolean forWebSocket) &#123; //调用构造方法 RealCall call = new RealCall(client, originalRequest, forWebSocket); call.eventListener = client.eventListenerFactory().create(call); return call; &#125; //同步执行 @Override public Response execute() throws IOException &#123; //这里使用同步代码块保证每个Call只能够执行一次 synchronized (this) &#123; if (executed) throw new IllegalStateException("Already Executed"); executed = true; &#125; captureCallStackTrace(); eventListener.callStart(this); try &#123; //还记得OkHttpClient中构造的时候的Dispatcher吗，这里实际上是把RealCall给了Dispatcher去调用它的executed()方法，当然只是将其加入到正在执行同步请求的队列中 client.dispatcher().executed(this); //实际上进行同步请求的是这个方法 Response result = getResponseWithInterceptorChain(); if (result == null) throw new IOException("Canceled"); return result; &#125; catch (IOException e) &#123; eventListener.callFailed(this, e); throw e; &#125; finally &#123; client.dispatcher().finished(this); &#125; &#125; //异步执行 @Override public void enqueue(Callback responseCallback) &#123; synchronized (this) &#123; if (executed) throw new IllegalStateException("Already Executed"); executed = true; &#125; captureCallStackTrace(); eventListener.callStart(this); //这里构造成Runnable然后移交给Dispatcher的异步请求方法 client.dispatcher().enqueue(new AsyncCall(responseCallback)); &#125; //这里是做同步请求的核心代码 Response getResponseWithInterceptorChain() throws IOException &#123; //这里是我们添加的拦截器 List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); interceptors.addAll(client.interceptors()); //网络请求重试拦截器 interceptors.add(retryAndFollowUpInterceptor); interceptors.add(new BridgeInterceptor(client.cookieJar())); interceptors.add(new CacheInterceptor(client.internalCache())); interceptors.add(new ConnectInterceptor(client)); if (!forWebSocket) &#123;//是否是websocket interceptors.addAll(client.networkInterceptors()); &#125; interceptors.add(new CallServerInterceptor(forWebSocket)); //构造InterceptorChain Interceptor.Chain chain = new RealInterceptorChain(interceptors, null, null, null, 0, originalRequest, this, eventListener, client.connectTimeoutMillis(), client.readTimeoutMillis(), client.writeTimeoutMillis()); //调用proceed开始进行请求 return chain.proceed(originalRequest); &#125;&#125; 可以看到不管是executed()做同步请求还是使用enqueue()做异步请求，最终都会调用到OkHttpClient的Dispatcher的executed()方法和enqueue()方法，请求的核心代码是在RealCall的getResponseWithInterceptorChain()中，对于同步请求，Dispatcher只是将RealCall添加到正在执行同步请求的队列中做一个记录。 AsyncCall 我们可以看到RealCall里面有一个内部类AsyncCall，它是一个Runnable，我们在RealCall的enqueue()方法中有这么一行代码。1client.dispatcher().enqueue(new AsyncCall(responseCallback)); 可以看到在交给Dispatcher进行异步请求的时候会先构造一个AsyncCall的对象，那么AsyncCall是什么呢？实际上就是一个Runnable。123456789101112131415161718192021222324252627282930313233final class AsyncCall extends NamedRunnable &#123; private final Callback responseCallback; AsyncCall(Callback responseCallback) &#123; super("OkHttp %s", redactedUrl()); this.responseCallback = responseCallback; &#125; @Override protected void execute() &#123; boolean signalledCallback = false; try &#123; //咦咦咦，看到没有，这个方法由线程池执行Runnable后调用run()进一步调用这个方法，做请求的东西实际上和同步请求一样，还是调用了getResponseWithInterceptorChain() Response response = getResponseWithInterceptorChain(); if (retryAndFollowUpInterceptor.isCanceled()) &#123; signalledCallback = true; responseCallback.onFailure(RealCall.this, new IOException("Canceled")); &#125; else &#123; signalledCallback = true; responseCallback.onResponse(RealCall.this, response); &#125; &#125; catch (IOException e) &#123; if (signalledCallback) &#123; // Do not signal the callback twice! Platform.get().log(INFO, "Callback failure for " + toLoggableString(), e); &#125; else &#123; eventListener.callFailed(RealCall.this, e); responseCallback.onFailure(RealCall.this, e); &#125; &#125; finally &#123; client.dispatcher().finished(this); &#125; &#125;&#125; 我们可以看到异步请求的核心代码和同步请求的核心代码都是getResponseWithInterceptorChain()；然后我们看看NamedRunnable，就只是在构造器中增加了对应的名称，然后当任务交给线程执行的时候，将线程的名称修改为指定的名称。123456789101112131415161718192021public abstract class NamedRunnable implements Runnable &#123; protected final String name; public NamedRunnable(String format, Object... args) &#123; this.name = Util.format(format, args); &#125; @Override public final void run() &#123; //修改Thread的名称为指定名称 String oldName = Thread.currentThread().getName(); Thread.currentThread().setName(name); try &#123; //这里执行请求 execute(); &#125; finally &#123; Thread.currentThread().setName(oldName); &#125; &#125; protected abstract void execute();&#125; Dispatcher 这是个网络请求的分发器，我们上面有分析RealCall的源码，它里面的同步和异步请求都会分发给Dispatcher的同步和异步请求，这里同样只粘贴核心代码。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public final class Dispatcher &#123; //最大请求数 private int maxRequests = 64; //每个host的最大请求数 private int maxRequestsPerHost = 5; private @Nullable Runnable idleCallback; //执行请求的线程池 private @Nullable ExecutorService executorService; //准备进行异步请求的Call队列 private final Deque&lt;AsyncCall&gt; readyAsyncCalls = new ArrayDeque&lt;&gt;(); //正在进行异步请求的Call队列 private final Deque&lt;AsyncCall&gt; runningAsyncCalls = new ArrayDeque&lt;&gt;(); //正在进行同步请求的Call队列 private final Deque&lt;RealCall&gt; runningSyncCalls = new ArrayDeque&lt;&gt;(); //构造线程池 public synchronized ExecutorService executorService() &#123; if (executorService == null) &#123; executorService = new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), Util.threadFactory("OkHttp Dispatcher", false)); &#125; return executorService; &#125; synchronized void enqueue(AsyncCall call) &#123; //1.正在执行异步请求的Call队列小于最大请求数量；2.call对应的host的请求数量小于每个host的最大请求数量 if (runningAsyncCalls.size() &lt; maxRequests &amp;&amp; runningCallsForHost(call) &lt; maxRequestsPerHost) &#123; //添加到正在执行异步请求的Call队列中 runningAsyncCalls.add(call); //将Runnable交给线程池 executorService().execute(call); &#125; else &#123; //添加到等待队列 readyAsyncCalls.add(call); &#125; &#125; synchronized void executed(RealCall call) &#123; //添加到正在执行的同步请求队列 runningSyncCalls.add(call); &#125;&#125;//这个方法主要是调整用的，如果正在请求的Call队列没有到最大请求，且等待队列有Call则将等待队列中的Call移到正在请求队列，并将Runnable交给线程池处理 private void promoteCalls() &#123; if (runningAsyncCalls.size() &gt;= maxRequests) return; // Already running max capacity. if (readyAsyncCalls.isEmpty()) return; // No ready calls to promote. for (Iterator&lt;AsyncCall&gt; i = readyAsyncCalls.iterator(); i.hasNext(); ) &#123; AsyncCall call = i.next(); if (runningCallsForHost(call) &lt; maxRequestsPerHost) &#123; i.remove(); runningAsyncCalls.add(call); executorService().execute(call); &#125; if (runningAsyncCalls.size() &gt;= maxRequests) return; // Reached max capacity. &#125; &#125; RealInterceptorChain 在RealCall的getResponseWithInterceptorChain()方法中，我们可以看到最终代码会调用到RealInterceptorChain.proceed()方法。123456789101112131415public Response proceed(Request request, StreamAllocation streamAllocation, HttpCodec httpCodec, RealConnection connection) throws IOException &#123; calls++; //创建下一个RealInterceptorChain RealInterceptorChain next = new RealInterceptorChain(interceptors, streamAllocation, httpCodec, connection, index + 1, request, call, eventListener, connectTimeout, readTimeout, writeTimeout); Interceptor interceptor = interceptors.get(index); //在interceptor的interceptor中实际上调用了chanin的proceed()，相当于交给了下一个RealInterceptorChain Response response = interceptor.intercept(next); return response;&#125; 可以看到这是一个链式调用，大致上如下图所示。 关于如何回传我们可以看看最后一个Interceptor的intercep()，也就是CallServerInterceptor的intercept()方法。12345678910@Override public Response intercept(Chain chain) throws IOException &#123; Response response = responseBuilder .request(request) .handshake(streamAllocation.connection().handshake()) .sentRequestAtMillis(sentRequestMillis) .receivedResponseAtMillis(System.currentTimeMillis()) .build(); return response;&#125; 可以看到CallServerInterceptor的intercept()方法会返回Response。]]></content>
  </entry>
  <entry>
    <title><![CDATA[taskAffinity属性]]></title>
    <url>%2F2018%2F09%2F12%2FtaskAffinity%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[我们在AndroidManifest.xml文件中可以指定taskAffinity属性，如下所示。1234&lt;activity android:name=".CActivity" android:launchMode="singleTask" android:taskAffinity="com.yanfangxiong.taskAffinity" /&gt; 它表示任务相关性，实际上的作用是指定所在的任务栈的名称，指定taskAffinity也需要注意以下几点 taskAffinity的值不要和包名一样，因为默认情况下，Activity都是运行在包名的任务栈中； taskAffinity的值中必须要有”.”，不然无法运行。 像上面的代码，当启动CActivity的时候，会看是否有com.yanfangxiong.taskAffinity的任务栈存在，如果没有则会新建名为com.yanfangxiong.taskAffinity的任务栈，然后再将CActivity放入到任务栈，如果有该任务栈存在，则会看是否有CActivity的实例，如果有则调用onNewIntent()方法。但但但是，一般我们使用taskAffinity没有作用，为什么呢？因为taskAffinity属性要和singleTask启动模式(Intent的FLAG_ACTIVITY_NEW_TASK)一起使用，或者和allowTaskReparenting属性一起使用。 和singleTask一起使用 我们可以像上面一样在manifest文件中指定launchMode为singleTask，然后给Activity指定taskAffinity属性。123456789101112&lt;activity android:name=".AActivity"&gt; &lt;intent-filter&gt; &lt;action android:name="android.intent.action.MAIN" /&gt; &lt;category android:name="android.intent.category.LAUNCHER" /&gt; &lt;/intent-filter&gt;&lt;/activity&gt;&lt;activity android:name=".BActivity" android:launchMode="singleTask" android:screenOrientation="portrait" android:taskAffinity="com.yanfangxiong.taskAffinity" /&gt; 或者我们不置顶BActivity的launchMode，通过Intent的flag，如下。123456val intent = Intent(this@AActivity, BActivity::class.java)intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK)val queryIntent = this@AActivity.packageManager.queryIntentActivities(intent, PackageManager.MATCH_DEFAULT_ONLY)if (queryIntent != null &amp;&amp; queryIntent.isNotEmpty()) &#123; this@AActivity.startActivity(intent)&#125; 上面的代码表示AActivity将会运行在名字为包名的任务栈，而BActivity将会运行在名字为com.yanfangxiong.taskAffinity的任务栈中。我们通过如下代码打印出taskId，看看两者是否是相同的。1234override fun onResume() &#123; super.onResume() Log.d("fxYan", "$taskId")&#125; 然后我们运行程序，之后从AActivity跳转到BActivity，看看两者是否在同一个任务栈中。可以看到两者在两个不同的任务栈中。 和allowTaskReparenting一起使用 栗子已备好，大人请品尝。我创建了两个app，一个是com.yanfangxiong.test，记为A应用，另外一个是com.yanfangxiong.test2，记为B应用。A应用中有一个AActivity，B应用中有一个AActivity和一个BActivity；然后从A应用的AActivity点击后会打开B应用的BActivity。然后我们分别修改BActivity的allowTaskReparenting属性，执行相同的流程。 打开A应用； 通过A应用的AActivity启动B应用的BActivity； 回到桌面； 通过B应用的launcher启动B应用。 这里涉及到一个命令，可以查看activity的信息。1$ adb shell dumpsys activity activities allowTaskReparenting为false 我们先来看看当B应用的BActivity的allowTaskReparenting为false的情况。为了简化，我这里只输出第四步的activity信息，如下所示。 先来看看B应用的任务栈信息，可以看到，只有我们启动的AActivity在任务栈中。 然后再看看A应用的任务栈信息，可以看到，有B应用的BActivity和A应用的AActivity在任务栈中。 allowTaskReparenting为true 然后我们看看allowTaskReparenting为true的情况，如下所示。 先来看看B应用的任务栈信息，可以看到神奇的一幕，有我们启动的AActivity以及之前通过A应用启动的BActivity在任务栈中，而且这个时候返回的时候是返回AActivity。 然后再看看A应用的任务栈信息，可以看到，只有A应用的AActivity在任务栈中。 allowTaskReparenting属性为true的时候，BActivity发现B应用启动后，有自己想要的任务栈，所以会从A应用的任务栈迁移到B应用的任务栈，就出现了上面神奇的一幕。]]></content>
  </entry>
  <entry>
    <title><![CDATA[关于http和https]]></title>
    <url>%2F2018%2F08%2F30%2F%E5%85%B3%E4%BA%8Ehttp%E5%92%8Chttps%2F</url>
    <content type="text"><![CDATA[http http(HyperText transfer protocol)是超文本传输协议的简称。它是浏览器和服务器之间传输信息的一种应用层协议，以明文的方式传输内容。 因为是明文传输，如果其他人通过拦截请求的方式就可以获取到传输数据，所以http协议是不安全的。 https 为了解决http协议传输数据的不安全性，就出现了https。https是安全超文本传输协议，它在http协议的基础上加入了SSL协议，SSL协议通过CA证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。 单向认证双向认证http2.0新特性]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何使用Telegram客户端]]></title>
    <url>%2F2018%2F08%2F08%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Telegram%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[嗯～，Telegram是一款工作沟通交流的工具。这里总结下各端上的Telegram客户端如何正常使用。 通用方法 适用于各个端的Telegram客户端，配置下MTPROTO代理 这里提供两个免费的MTPROTO代理。 配置一 server 74.120.175.43 port 400 secret bbd3d8c677df2c657bed1a1094a7e75a 配置二 Server 45.77.97.94 port 400 secret 5788c35845a9d6c9e8a0db182c60765e Android Android上面下载一个ShadowSocks的app，还可以进行翻墙，很方便吧。]]></content>
  </entry>
  <entry>
    <title><![CDATA[浅谈camera2API]]></title>
    <url>%2F2018%2F08%2F01%2F%E6%B5%85%E8%B0%88camera2API%2F</url>
    <content type="text"><![CDATA[camera2是API21出的一套方便与camera devices进行交互的包。要使用camera2 API，我们首先得对其中的一些基本的类有一定的了解。 基础类CameraManager 它是一个系统服务，通过它我们可以访问CameraDevice以及获取关于CameraDevice的一些特性。 一般我们通过Context的getSystemService()方法就能获取到CameraManager的实例。1val camaraManager = context.getSystemService(Context.CAMERA_SERVICE) 它是在SystemServiceRegistry的static代码块中注册的。123456registerService(Context.CAMERA_SERVICE, CameraManager.class, new CachedServiceFetcher&lt;CameraManager&gt;() &#123; @Override public CameraManager createService(ContextImpl ctx) &#123; return new CameraManager(ctx); &#125;&#125;); 内部类AvailabilityCallback 就是监听Camera是否有用的一个回调。12345678public static abstract class AvailabilityCallback &#123; public void onCameraAvailable(@NonNull String cameraId) &#123; &#125; public void onCameraUnavailable(@NonNull String cameraId) &#123; &#125;&#125; TorchCallback 监听闪光灯模式的一个回调。123456789public static abstract class TorchCallback &#123; public void onTorchModeUnavailable(@NonNull String cameraId) &#123; &#125; public void onTorchModeChanged(@NonNull String cameraId, boolean enabled) &#123; &#125;&#125; 常用方法getCameraIdList() getCameraIdList()可以获取到硬件设备所有的可用camera id。1234@NonNullpublic String[] getCameraIdList() throws CameraAccessException &#123; return CameraManagerGlobal.get().getCameraIdList();&#125; 我们可以看到它里面实际上是调用的CameraManagerGlobal的getCameraIdList()方法。12345678910111213141516171819202122232425public String[] getCameraIdList() &#123; String[] cameraIds = null; synchronized(mLock) &#123; // Try to make sure we have an up-to-date list of camera devices. connectCameraServiceLocked(); int idCount = 0; for (int i = 0; i &lt; mDeviceStatus.size(); i++) &#123; int status = mDeviceStatus.valueAt(i); if (status == ICameraServiceListener.STATUS_NOT_PRESENT || status == ICameraServiceListener.STATUS_ENUMERATING) continue; idCount++; &#125; cameraIds = new String[idCount]; idCount = 0; for (int i = 0; i &lt; mDeviceStatus.size(); i++) &#123; int status = mDeviceStatus.valueAt(i); if (status == ICameraServiceListener.STATUS_NOT_PRESENT || status == ICameraServiceListener.STATUS_ENUMERATING) continue; cameraIds[idCount] = mDeviceStatus.keyAt(i); idCount++; &#125; &#125; return cameraIds;&#125; mDeviceStatus是一个map集合，key是camera id，value是camera id对应的camera status，mDeviceStatus的元素是在connectCameraServiceLocked()方法调用的时候存放的。1234567891011121314151617181920212223242526272829303132333435363738private void connectCameraServiceLocked() &#123; // 重连 if (mCameraService != null) return; //获取IBinder对象，进而获取到ICameraService的对象 IBinder cameraServiceBinder = ServiceManager.getService(CAMERA_SERVICE_BINDER_NAME); if (cameraServiceBinder == null) &#123; // Camera service下线 return; &#125; try &#123; cameraServiceBinder.linkToDeath(this, /*flags*/ 0); &#125; catch (RemoteException e) &#123; // Camera service下线 return; &#125; ICameraService cameraService = ICameraService.Stub.asInterface(cameraServiceBinder); try &#123; CameraMetadataNative.setupGlobalVendorTagDescriptor(); &#125; catch (ServiceSpecificException e) &#123; handleRecoverableSetupErrors(e); &#125; try &#123; CameraStatus[] cameraStatuses = cameraService.addListener(this); for (CameraStatus c : cameraStatuses) &#123; onStatusChangedLocked(c.status, c.cameraId); &#125; mCameraService = cameraService; &#125; catch(ServiceSpecificException e) &#123; // Unexpected failure throw new IllegalStateException("Failed to register a camera service listener", e); &#125; catch (RemoteException e) &#123; // Camera service is now down, leave mCameraService as null &#125;&#125; 我们再来看看onStatusChangeLocked()方法。123456789101112131415161718192021222324private void onStatusChangedLocked(int status, String id) &#123; // 判断当前camera id对应的状态是否是有效状态 if (!validStatus(status)) &#123; return; &#125; // 存放到mDeviceStatus中 Integer oldStatus = mDeviceStatus.put(id, status); if (oldStatus != null &amp;&amp; oldStatus == status) &#123; return; &#125; if (oldStatus != null &amp;&amp; isAvailable(status) == isAvailable(oldStatus)) &#123; return; &#125; // 如果camera id对应的状态发生改变，则回调给通过CameraManager的register方法注册的AvailabilityCallback final int callbackCount = mCallbackMap.size(); for (int i = 0; i &lt; callbackCount; i++) &#123; Handler handler = mCallbackMap.valueAt(i); final AvailabilityCallback callback = mCallbackMap.keyAt(i); postSingleUpdate(callback, handler, id, status); &#125;&#125; getCameraCharacteristics 通过这个方法，我们可以获取到对应camera id的CameraCharacteristics对象。12345678910111213141516171819202122232425262728293031323334public CameraCharacteristics getCameraCharacteristics(@NonNull String cameraId) throws CameraAccessException &#123; CameraCharacteristics characteristics = null; synchronized (mLock) &#123; ICameraService cameraService = CameraManagerGlobal.get().getCameraService(); if (cameraService == null) &#123; throw new CameraAccessException(CameraAccessException.CAMERA_DISCONNECTED, "Camera service is currently unavailable"); &#125; try &#123; if (!supportsCamera2ApiLocked(cameraId)) &#123; // 遗留问题不兼容camera2 api locked int id = Integer.parseInt(cameraId); String parameters = cameraService.getLegacyParameters(id); CameraInfo info = cameraService.getCameraInfo(id); characteristics = LegacyMetadataMapper.createCharacteristics(parameters, info); &#125; else &#123; CameraMetadataNative info = cameraService.getCameraCharacteristics(cameraId); characteristics = new CameraCharacteristics(info); &#125; &#125; catch (ServiceSpecificException e) &#123; throwAsPublicException(e); &#125; catch (RemoteException e) &#123; throw new CameraAccessException(CameraAccessException.CAMERA_DISCONNECTED, "Camera service is currently unavailable", e); &#125; &#125; return characteristics;&#125; openCamera() 通过这个方法我们就可以获取到CameraDevice对象了，我们可以看到这个方法接受一个CameraDevice.StateCallback对象，当CameraDevice连接成功和失败的时候就会回调到这个Callback的对应方法中。 (un)registerAvailabilityCallback 注册和取消注册AvailabilityCallback，最终会将其放到CameraManagerGlobal的mCallbackMap中。 (un)registerTorchCallback 注册和取消注册TorchCallback，最终会将其放到CameraManagerGlobal的mTorchCallbackMap中。 CameraService的重连 在查看CameraManager的源码过程中，发现CameraService下线重连机制，通过IBinder的死亡代理进行重连，我们在connectCameraServiceLocked()中看到，在调用linkToDeath()的时候，如果发现CameraService下线了，会回调到binderDied()方法中，我们看看binderDied()方法做的事情是什么。1234567891011121314151617181920public void binderDied() &#123; synchronized(mLock) &#123; if (mCameraService == null) return; mCameraService = null; // 更新cameraId对应的status for (int i = 0; i &lt; mDeviceStatus.size(); i++) &#123; String cameraId = mDeviceStatus.keyAt(i); onStatusChangedLocked(ICameraServiceListener.STATUS_NOT_PRESENT, cameraId); &#125; // for (int i = 0; i &lt; mTorchStatus.size(); i++) &#123; String cameraId = mTorchStatus.keyAt(i); onTorchStatusChangedLocked(ICameraServiceListener.TORCH_STATUS_NOT_AVAILABLE, cameraId); &#125; // 这个方法里面进行cameraService的重连 scheduleCameraServiceReconnectionLocked(); &#125;&#125; 我们可以看scheduleCameraServiceReocnnectionLock()方法。12345678910111213141516171819202122232425262728private void scheduleCameraServiceReconnectionLocked() &#123; final Handler handler; if (mCallbackMap.size() &gt; 0) &#123; handler = mCallbackMap.valueAt(0); &#125; else if (mTorchCallbackMap.size() &gt; 0) &#123; handler = mTorchCallbackMap.valueAt(0); &#125; else &#123; // 如果没有注册callback，则不进行重连操作 return; &#125; handler.postDelayed( new Runnable() &#123; @Override public void run() &#123; // 重连 ICameraService cameraService = getCameraService(); if (cameraService == null) &#123; synchronized(mLock) &#123; // 重连失败，继续重连 scheduleCameraServiceReconnectionLocked(); &#125; &#125; &#125; &#125;, CAMERA_SERVICE_RECONNECT_DELAY_MS);&#125; CameraDevice 它表示的就是Android设备上的一个摄像头，允许你在高帧率的情况下对图像进行捕获以及后期处理有一个精细的控制。 TEMPLATE CameraDevice里面定义了一些TEMPLATE，使我们在创建CaptureRequest.Builder的时候需要的。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* * 创建一个适合于相机预览窗口的Request，这意味着高帧率优先于高质量处理，这个Request正常 * 情况下被用于CameraCaptureSession的setRepeatingRequest()，这个TEMPLATE在所有的 * camera devices上都支持 */ public static final int TEMPLATE_PREVIEW = 1; /* * 创建一个静态图像捕获的Request，这意味着优先考虑图片质量，而不是帧率。通常情况下被用于 * CameraCaptureSession的capture()，这个TEMPLATE在所有的camera devices上都支持 */ public static final int TEMPLATE_STILL_CAPTURE = 2; /* * 创建一个适合于视频录制的Request，这意味着需要一个稳定的帧率和质量。通常情况下被用于 * CameraCaptureSession的setRepeatingRequest()，这个TEMPLATE在所有的camera devices * 上都支持 */ public static final int TEMPLATE_RECORD = 3; /* * 创建一个在视频录制过程中静态图像捕获的Request，这意味着在不中断的录制过程中最大化图像质量。 * 通常情况下，你通过CameraDevice的createCaptureRequest(TEMPLATE_RECORD)创建一个 * Request，然后通过CameraCaptureSession的setRepeatingRequest()开启视频录制请求， * 然后你调用CameraCaptureSession的capture()可以使用这个TEMPLATE，这个TEMPLATE * 基本所有的camera devices都支持，除非旧设备的CameraCharacteristics的 * INFO_SUPPORTED_HARDWARE_LEVEL字段为INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY */ public static final int TEMPLATE_VIDEO_SNAPSHOT = 4; /* * 创建一个零延时的静态图像捕获Request，这意味着在不影响预览帧率的情况下，最大化图像质量。 * 这个TEMPLATE被所有支持 * CameraMetadata#REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING * CameraMetadata#PRIVATE_REPROCESSING * CameraMetadata#REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING * CameraMetadata#YUV_REPROCESSING * 的camera devices所支持 */ public static final int TEMPLATE_ZERO_SHUTTER_LAG = 5; /* * 用于直接应用程序控制捕获参数的basic TEMPLATE，所有的自动控制都会失效，比如自动曝光， * 自动白平衡，自动聚焦等。手动设置的参数诸如曝光等都被设置为合理的默认值，但是你可以根据 * 程序的需要修改这些值。 * 这个TEMPLATE被所有的支持 * CameraMetadata#REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR * CameraMetadata#MANUAL_SENSOR * 的camera devices所支持 */ public static final int TEMPLATE_MANUAL = 6; 内部类StateCallback Camera Device的各种状态回调。1234567891011121314151617181920212223242526272829303132333435public static abstract class StateCallback &#123; // 打开camera失败，camera device被一个优先级更高的client在使用 public static final int ERROR_CAMERA_IN_USE = 1; // 打开camera失败，所有的camera device正在被使用 public static final int ERROR_MAX_CAMERAS_IN_USE = 2; // setCameraDisabled();因为设备原因无法打开camera public static final int ERROR_CAMERA_DISABLED = 3; // camera device遇到一个致命的错误，需要重新打开以便使用 public static final int ERROR_CAMERA_DEVICE = 4; // Android设备遇到一个致命的错误，需要重新启动来加载camera相关功能 public static final int ERROR_CAMERA_SERVICE = 5; // camera device被打开的时候回调，表示camera可以被使用了 public abstract void onOpened(@NonNull CameraDevice camera); // Must implement // 当调用CameraDevice的close()方法的时候会回调， public void onClosed(@NonNull CameraDevice camera) &#123; &#125; /* * camera device不在可用的时候会回调，可能是安全策略或权限的改变，也可能是可拆卸摄像头连接 * 断开，亦或者是一个更高优先级的client需要使用camera device。此方法调用之后仍然会触发capture * 回调，或者将新的image buffer递送给活跃的输出。 */ public abstract void onDisconnected(@NonNull CameraDevice camera); // Must implement // camera device发生错误的时候会回调这个方法 public abstract void onError(@NonNull CameraDevice camera, @ErrorCode int error); // Must implement&#125; 常用方法close 尽可能快的关闭camera device的连接，一旦这个方法被调用，后续访问camera device将会抛出IllegalStateException。当和camera device的连接完全关闭的时候，会回调到StateCallback的onClosed()方法，此时camera device是可以被重新打开的。 这个方法调用之后，在StateCallback的onClosed()方法调用之前，camera device和活跃的session的callback都不会发生，那些已经提交的capture请求也会被丢弃，就好像CameraCaptureSession的abortCaptures()被调用了一样，但是失败的callback会被调用。 createCaptureSession 通过提供给camera device一个目标输出的Surface集合来创建一个新的camera capture session。活跃的camera session为camera device的每个capture request确定一组潜在的输出Surface集合，每个capture request可能使用其中的某个或者所有的输出Surface。一旦CameraCaptureSession被创建了，你就可以通过CameraCaptureSession的capture(),captureBurst(),setRepeatingCapture(),setRepeatingBurst()来发起capture请求。123public abstract void createCaptureSession(@NonNull List&lt;Surface&gt; outputs, @NonNull CameraCaptureSession.StateCallback callback, @Nullable Handler handler) throws CameraAccessException; createCaptureRequest 接受一个TEMPLATE来创建CaptureRequest.Builder，Request是用于CameraCaptureSession和硬件设备进行交互的。123@NonNullpublic abstract CaptureRequest.Builder createCaptureRequest(@RequestTemplate int templateType) throws CameraAccessException; CameraCaptureSession CaptureRequest使用常见问题拍摄图片方向反转 这个问题应该算是遇到的比较多的，图片拍摄保存后是倒着的。要弄清楚这个问题产生的原因我们得知道两个东西，一个是屏幕rotation，一个是camera sensor的角度，这两个因素决定了你拍摄的图片后的方向。一般我们竖屏的界面，屏幕rotation是Surface.ROTATION_0，然后一般的手机camera sensor的角度是90度，这个时候我们拍摄的图片保存是正常，但是有些手机的camera sensor是270度，这样拍摄就会导致图片保存的时候是倒着的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[APT揭露编译时注解的面纱]]></title>
    <url>%2F2018%2F08%2F01%2FAPT%E6%8F%AD%E9%9C%B2%E7%BC%96%E8%AF%91%E6%97%B6%E6%B3%A8%E8%A7%A3%E7%9A%84%E9%9D%A2%E7%BA%B1%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[有效的防止系统字体修改影响app]]></title>
    <url>%2F2018%2F07%2F15%2F%E6%9C%89%E6%95%88%E7%9A%84%E9%98%B2%E6%AD%A2%E7%B3%BB%E7%BB%9F%E5%AD%97%E4%BD%93%E4%BF%AE%E6%94%B9%E5%BD%B1%E5%93%8Dapp%2F</url>
    <content type="text"><![CDATA[前言 不知道你们有没有这种烦恼，比如我们在使用TextView控件的时候，设置字体大小是16sp，然后我们在手机设置中将字体的大小从标准修改为小，大或者特大，然后再回到app，发现这个时候TextView上显示的文本完全就不是我们想要的，因为sp会受到系统字体大小设置的影响。 解决方法 这里提供两种解决方法，更推荐使用第二种方式。 方法一 这种方法比较暴躁，也比较简单，就是你布局文件中textSize的单位使用dp，这样就不会受到设置的影响了。但是，这样修改后会有警告，因为google是建议textSize的单位使用sp。 方法二 于是在google上搜索了N多篇博客，基本都是如下的方式，重写getResource()方法。1234567override fun getResources(): Resources &#123; val resources = super.getResources() val config = Configuration() config.setToDefaults() resources.updateConfiguration(config, resources.displayMetrics) return resources&#125; 我想问，你们这样写就没有一点点的疑问吗，这样会将Configuration的配置全部重置为默认的，也就是说你设置的一些配置都没有了。 于是我将代码修改为了下面的，从当前的resources获取configuration然后对其的fontScale进行修改。1234567891011override fun getResources(): Resources &#123; val resources = super.getResources() if (resources != null) &#123; val config = resources.configuration if (config != null &amp;&amp; config.fontScale != 1F) &#123; config.fontScale = 1F resources.updateConfiguration(config, resources.displayMetrics) &#125; &#125; return resources&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何优雅的给RecyclerView添加头尾]]></title>
    <url>%2F2018%2F07%2F15%2F%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E7%BB%99RecyclerView%E6%B7%BB%E5%8A%A0%E5%A4%B4%E5%B0%BE%2F</url>
    <content type="text"><![CDATA[前言 RecyclerView的可定制化程度相较于ListView确实是方便了很多，但是RecyclerView是不支持添加头尾以及空布局的，经过一些实践，最终觉得对适配器进行扩展的方式是比较方便的。 内容 这里就不在赘述，直接上代码了。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192@SuppressWarnings("ALL")public abstract class BaseRecyclerAdapter&lt;T, VH extends RecyclerView.ViewHolder&gt; extends RecyclerView.Adapter &#123; private final int ITEM_TYPE = 0; private final int EMPTY_TYPE = 99; private final int BASE_HEADER_TYPE = 100; private final int BASE_FOOTER_TYPE = 200; protected Context context; protected LayoutInflater inflater; protected int resId; protected List&lt;T&gt; dataSource; protected SparseArray&lt;View&gt; headers; protected SparseArray&lt;View&gt; footers; protected View emptyView; protected OnItemClickListener&lt;T&gt; onItemClickListener; protected View.OnClickListener onClickListener; protected boolean showHeaderFooterWhenEmpty; public BaseRecyclerAdapter(@NonNull Context context, @LayoutRes int resId) &#123; this.context = context; this.inflater = LayoutInflater.from(context); this.resId = resId; this.dataSource = new ArrayList&lt;&gt;(); this.headers = new SparseArray&lt;&gt;(); this.footers = new SparseArray&lt;&gt;(); &#125; public void clearDataSource() &#123; dataSource.clear(); &#125; public void addAll(List&lt;T&gt; list) &#123; dataSource.addAll(list); &#125; public void addHeaderView(View header) &#123; if (headers.indexOfValue(header) &lt; 0) &#123; headers.put(BASE_HEADER_TYPE + headers.size(), header); &#125; &#125; public void addFooterView(View footer) &#123; if (footers.indexOfValue(footer) &lt; 0) &#123; footers.put(BASE_FOOTER_TYPE + footers.size(), footer); &#125; &#125; public int getHeaderCount() &#123; return headers.size(); &#125; public int getFooterCount() &#123; return footers.size(); &#125; public void setEmptyView(View view) &#123; this.emptyView = view; &#125; public void setShowHeaderFooterWhenEmpty(boolean showHeaderFooterWhenEmpty) &#123; this.showHeaderFooterWhenEmpty = showHeaderFooterWhenEmpty; &#125; public void setOnItemClickListener(OnItemClickListener&lt;T&gt; listener) &#123; this.onItemClickListener = listener; &#125; public void setOnClickListener(View.OnClickListener listener) &#123; this.onClickListener = onClickListener; &#125; @Override public int getItemViewType(int position) &#123; if (emptyView != null &amp;&amp; dataSource.isEmpty() &amp;&amp; !showHeaderFooterWhenEmpty) &#123; return EMPTY_TYPE; &#125; if (position &lt; headers.size()) &#123; return headers.keyAt(position); &#125; int index = position - headers.size(); int viewType; if (dataSource.isEmpty()) &#123; if (emptyView == null) &#123; viewType = footers.keyAt(index); &#125; else if (index == 0) &#123; viewType = EMPTY_TYPE; &#125; else &#123; index = index - 1; viewType = footers.keyAt(index); &#125; &#125; else &#123; if (index &lt; dataSource.size()) &#123; viewType = ITEM_TYPE; &#125; else &#123; index = index - dataSource.size(); viewType = footers.keyAt(index); &#125; &#125; return viewType; &#125; @NonNull @Override public RecyclerView.ViewHolder onCreateViewHolder(@NonNull ViewGroup parent, int viewType) &#123; // empty if (viewType == EMPTY_TYPE) &#123; return new RecyclerView.ViewHolder(emptyView) &#123; &#125;; &#125; // header View view = headers.get(viewType); if (view != null) &#123; return new RecyclerView.ViewHolder(view) &#123; &#125;; &#125; // footer view = footers.get(viewType); if (view != null) &#123; return new RecyclerView.ViewHolder(view) &#123; &#125;; &#125; // item return createItemViewHolder(inflater.inflate(resId, parent, false)); &#125; protected abstract VH createItemViewHolder(View view); @Override public void onBindViewHolder(@NonNull RecyclerView.ViewHolder holder, int position) &#123; if (getItemViewType(position) == ITEM_TYPE) &#123; final int index = position - headers.size(); final T obj = dataSource.get(index); if (onItemClickListener != null) &#123; holder.itemView.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View v) &#123; onItemClickListener.onItemClicked(obj, index); &#125; &#125;); &#125; bindData((VH) holder, dataSource.get(index), index); &#125; &#125; protected abstract void bindData(@NonNull VH h, T obj, int position); @Override public int getItemCount() &#123; if (emptyView != null &amp;&amp; dataSource.isEmpty()) &#123; if (showHeaderFooterWhenEmpty) &#123; return headers.size() + 1 + footers.size(); &#125; else &#123; return 1; &#125; &#125; return headers.size() + dataSource.size() + footers.size(); &#125; @Override public void onAttachedToRecyclerView(@NonNull RecyclerView recyclerView) &#123; RecyclerView.LayoutManager lm = recyclerView.getLayoutManager(); if (lm instanceof GridLayoutManager) &#123; final GridLayoutManager glm = (GridLayoutManager) lm; glm.setSpanSizeLookup(new GridLayoutManager.SpanSizeLookup() &#123; @Override public int getSpanSize(int position) &#123; int type = getItemViewType(position); // fix span count for header and footer and empty view if (type == ITEM_TYPE) &#123; return 1; &#125; return glm.getSpanCount(); &#125; &#125;); &#125; &#125; public interface OnItemClickListener&lt;T&gt; &#123; void onItemClicked(T obj, int position); &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[关于软键盘的一些思考]]></title>
    <url>%2F2018%2F06%2F11%2F%E5%85%B3%E4%BA%8E%E8%BD%AF%E9%94%AE%E7%9B%98%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[前言 公司的app大部分的界面都涉及到表单相关内容，所以要考虑软键盘和输入界面之间的协调性，于是在经过一系列的方法实践之后，总结了两种还算是比较和谐的方式。阅读本文前，请你先弄清楚windowSoftInputMode这个属性的作用，这个属性在Window与WindowManager一文中有讲解。 从布局入手 这种方式需要设置activity的windowSoftInputMode为adjustResize。然后通过对activity根布局的变化来知晓软键盘的显示和隐藏。1234567891011121314151617181920212223242526272829303132333435363738394041class KeyBoardInfo( private var rootView: View, var listener: OnKeyBoardHiddenChangeListener?) : ViewTreeObserver.OnGlobalLayoutListener &#123; constructor(rootView: View, keyboardHiddenChanged: (Boolean) -&gt; Unit) : this(rootView, object : OnKeyBoardHiddenChangeListener &#123; override fun onKeyBoardHiddenChanged(hidden: Boolean) &#123; keyboardHiddenChanged(hidden) &#125; &#125;) private val rootViewRect: Rect = Rect() private var rootViewVisibleHeight: Int = 0 init &#123; rootView.viewTreeObserver.addOnGlobalLayoutListener(this) &#125; override fun onGlobalLayout() &#123; rootView.getWindowVisibleDisplayFrame(rootViewRect) val visibleHeight = rootViewRect.height() when &#123; rootViewVisibleHeight == 0 -&gt; rootViewVisibleHeight = visibleHeight rootViewVisibleHeight - visibleHeight &gt; 200 -&gt; &#123; rootViewVisibleHeight = visibleHeight listener?.onKeyBoardHiddenChanged(false) &#125; visibleHeight - rootViewVisibleHeight &gt; 200 -&gt; &#123; rootViewVisibleHeight = visibleHeight listener?.onKeyBoardHiddenChanged(true) &#125; &#125; &#125; fun release() &#123; listener = null &#125; interface OnKeyBoardHiddenChangeListener &#123; fun onKeyBoardHiddenChanged(hidden: Boolean) &#125;&#125; 思路很简单，通过保存最近一次根布局的可视高度，然后和变化后的可是高度进行比较，达到某个差值就认为软键盘的状态发生了变化。 从事件分发入手 这种方式在BaseActivity中重写dispatchTouchEvent()，在ACTION_DOWN的时候查看当前聚焦控件是否需要隐藏软键盘，若需要，则直接隐藏掉。12345678910111213141516171819202122232425262728293031323334override fun dispatchTouchEvent(ev: MotionEvent?): Boolean &#123; when (ev?.action) &#123; MotionEvent.ACTION_DOWN -&gt; &#123; if (shouldHideKeyboard(currentFocus, ev)) &#123; hideKeyboard(this) whenKeyboardHidden() &#125; &#125; &#125; return super.dispatchTouchEvent(ev)&#125;open fun whenKeyboardHidden() &#123; //todo 软键盘隐藏的时候需要做的时候&#125;fun hideKeyboard(context: Activity) &#123; context.currentFocus?.windowToken?.apply &#123; val service: InputMethodManager? = context.getSystemService(Context.INPUT_METHOD_SERVICE) as? InputMethodManager? service?.hideSoftInputFromWindow(this, InputMethodManager.HIDE_NOT_ALWAYS) &#125;&#125;fun shouldHideKeyboard(currentFocus: View?, event: MotionEvent): Boolean &#123; if (currentFocus == null || currentFocus !is EditText) return false val l = intArrayOf(0, 0) currentFocus.getLocationInWindow(l) val left = l[0] val top = l[1] val bottom = top + currentFocus.height val right = left + currentFocus.width return !(event.x &gt; left &amp;&amp; event.x &lt; right &amp;&amp; event.y &gt; top &amp;&amp; event.y &lt; bottom)&#125; 使用这种方式，请设置windowSoftInputMode为adjustPan。 推荐方式 我们来对比下两者的优缺点。 1. 对于第一种方式，windowSoftInputMode设置为adjustResize的时候，如果布局底部有按钮，那么得根据软键盘的显示和隐藏动态的设置按钮的可视性，这种方式会让用户在视觉上有不协调地方；你可能会说，一样可以设置windowSoftInputMode为adjustPan，但是这样会导致一些表单界面最下面必须将软键盘收起后才能看到，而且需要给最外层控件设置点击事件，在点击之后隐藏软键盘，这样就太麻烦了；其次，现在app一般都会沉浸式状态栏，一般情况下我们会让布局占据状态栏的部分，然后动态设置顶部控件的边距达到这种效果，但是在这种方式下，adjustResize是无效的，也就是说，全屏模式和adjustResize两者是冲突的。但是这种方式也有优点，就是我们可以很方便的知道软键盘何时显示何时隐藏。 2. 对于第二种方式，优点就是在手势触碰的时候，就会隐藏掉软键盘，然后再进行其他的响应。当然它也有缺点，一般软键盘的右上角都有一个收起软件盘的按钮，如果我们通过这个方式去隐藏软键盘，whenKeyboardHidden()方法是不会回调的，这显然就不是我们想要的那种效果。 分析完这两者的利弊之后，我决定将两者结合使用，于是乎就得到了下面的代码。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.guoshujinfu.mobile.gscloud.uiimport android.content.res.Resourcesimport android.graphics.Rectimport android.os.Buildimport android.os.Bundleimport android.support.annotation.CallSuperimport android.support.v7.app.AppCompatActivityimport android.view.MotionEventimport android.view.WindowManagerimport com.guoshujinfu.mobile.gscloud.extension.hideKeyboardimport com.guoshujinfu.mobile.gscloud.extension.shouldHideKeyboardimport com.guoshujinfu.mobile.gscloud.ui.login.LoginActivityimport com.guoshujinfu.mobile.gscloud.utils.ActivityControllerimport com.guoshujinfu.mobile.gscloud.views.dialog.IphoneDialogimport com.guoshujinfu.mobile.gscloud.views.dialog.LoadingDialogimport com.gyf.barlibrary.ImmersionBar/** * @author fxYan */abstract class BaseActivity : AppCompatActivity() &#123; private var latestHeight: Int = 0 private var displayRect: Rect = Rect() override fun onCreate(savedInstanceState: Bundle?) &#123; super.onCreate(savedInstanceState) setContentView(getLayoutRes()) initComponents(savedInstanceState) &#125; abstract fun getLayoutRes(): Int @CallSuper open fun initComponents(savedInstanceState: Bundle?) &#123; window.decorView.viewTreeObserver.addOnGlobalLayoutListener &#123; window.decorView.getWindowVisibleDisplayFrame(displayRect) val visibleHeight = displayRect.height() when &#123; latestHeight == 0 -&gt; latestHeight = visibleHeight latestHeight - visibleHeight &gt; 200 -&gt; &#123; latestHeight = visibleHeight whenKeyboardShow() &#125; visibleHeight - latestHeight &gt; 200 -&gt; &#123; latestHeight = visibleHeight whenKeyboardHidden() &#125; &#125; &#125; &#125; override fun dispatchTouchEvent(ev: MotionEvent?): Boolean &#123; when (ev?.action) &#123; MotionEvent.ACTION_DOWN -&gt; &#123; if (shouldHideKeyboard(currentFocus, ev)) &#123; hideKeyboard(this) &#125; &#125; &#125; return super.dispatchTouchEvent(ev) &#125; open fun whenKeyboardShow() &#123;&#125; open fun whenKeyboardHidden() &#123;&#125;&#125; 软键盘的显示和隐藏还是通过监听布局高度的变化来完成，然后再事件分发的时候如果需要隐藏软键盘就先将软键盘给隐藏掉，在进行其他的操作。]]></content>
  </entry>
  <entry>
    <title><![CDATA[android arch 学习之LiveData]]></title>
    <url>%2F2018%2F05%2F22%2Fandroid-arch-%E5%AD%A6%E4%B9%A0%E4%B9%8BLiveData%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[你真的了解git config吗]]></title>
    <url>%2F2018%2F05%2F18%2F%E4%BD%A0%E7%9C%9F%E7%9A%84%E4%BA%86%E8%A7%A3git-config%E5%90%97%2F</url>
    <content type="text"><![CDATA[前言 记得当时刚使用git的时候，安装完git后就按照别人说的稀里糊涂配置了这些玩意。12$ git config --global user.name "xxx"$ git config --global user.email "xxx" 压根没有想过git config这玩意有没有其他的作用。而最近看完progit这本书后，发现git config的用法还是很多的。这里就记录一些比较常用的。 config文件 git config实际上有三个层级的配置文件，它们分别是： git config –system，在mac上，这个配置文件在/usr/local/git/etc/gitconfig； git config –global，在mac上，这个配置文件在~/.gitconfig； git config –local，这个配置文件是在本地仓库的.git/config。 而当你使用到这些配置属性的时候，git会根据层级来获得这个属性的值，本地仓库下的配置优先级最高，其次是global配置，最后才是system配置。 我们可以看下global文件下配置的属性。 可以看到我们通过git config –global属性配置的user.name和user.email。 不同仓库不同身份 这个很简答，我们只需要通过git config –lobal配置好本地仓库的name和email，然后再生成对应email的ssh key并配置在服务器端就可以了。12$ git config --local user.name "xxx"$ git config --local user.email "xxx" 多个远程仓库 我记得很早之前我有个朋友问我一个问题，说他们的git工作模式是fork，每个人都有一个远程仓库和一个本地仓库，同时也有一个中央仓库，而他想要把代码同时提交到多个远程仓库该怎么弄。 默认情况下，我们clone远程仓库的代码后，local 配置文件下会有一个名为origin的远程仓库别名。 我们只需要通过git remote add xxx repoUrl添加其他的远程仓库就可以了。123$ git remote add another xxxxxx# 移除$ git remote rm another 本地配置文件是这个样子的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[android arch 学习之lifecycle-aware components]]></title>
    <url>%2F2018%2F05%2F17%2Fandroid-arch-%E5%AD%A6%E4%B9%A0%E4%B9%8Blifecycle-aware-components%2F</url>
    <content type="text"><![CDATA[前言 早在去年的时候就看到了Google新发布的arch库，但是当时还是在alpha版本，就没有过多的去关注，现在arch库已经处于稳定的阶段，于是决定好好的学习一下arch库。 原文地址翻墙地址：https://developer.android.com/topic/libraries/architecture/lifecycle国内地址：https://developer.android.google.cn/topic/libraries/architecture/lifecycle 举个栗子 BroadcastReceiver相信大家用的非常多了，当然你说现在EventBus等总线框架这么强大， 基本没自己手写过广播那我就没办法了，但是用法总归是记得的。这里我们编写一个简单的监听电池信息的广播，同时使用动态注册的方式。123456789101112131415161718192021222324252627282930class BatteryReceiver : BroadcastReceiver() &#123; override fun onReceive(context: Context?, intent: Intent?) &#123; if (Intent.ACTION_BATTERY_CHANGED == intent?.action) &#123; //... &#125; &#125;&#125;class BatteryActivity : AppCompatActivity() &#123; private val receiver: BatteryReceiver by lazy &#123; BatteryReceiver() &#125; private val filter: IntentFilter by lazy &#123; IntentFilter(Intent.ACTION_BATTERY_CHANGED) &#125; override fun onResume() &#123; super.onResume() registerReceiver(receiver, filter) &#125; override fun onPause() &#123; super.onPause() unregisterReceiver(receiver) &#125;&#125; 这也是一般情况下我们通用的形式，一旦某个东西需要和生命周期联动，就重写组件的生命周期方法在里面做一些操作，一旦这些操作过多之后就会导致难以管理。于是乎lifecycle-aware Components就这么产生了。先看结果，后续再来详细的分析。123456789101112131415161718192021222324252627282930class BatteryLifecycleObserver( private val context: Context) : LifecycleObserver &#123; private val receiver: BatteryReceiver by lazy &#123; BatteryReceiver() &#125; private val filter: IntentFilter by lazy &#123; IntentFilter(Intent.ACTION_BATTERY_CHANGED) &#125; @OnLifecycleEvent(Lifecycle.Event.ON_RESUME) fun register() &#123; context.registerReceiver(receiver, filter) &#125; @OnLifecycleEvent(Lifecycle.Event.ON_PAUSE) fun unregister() &#123; context.unregisterReceiver(receiver) &#125;&#125;class BatteryActivity : AppCompatActivity() &#123; override fun onCreate(savedInstanceState: Bundle?, persistentState: PersistableBundle?) &#123; super.onCreate(savedInstanceState, persistentState) lifecycle.addObserver(BatteryLifecycleObserver(this)) &#125;&#125; 可以看到我们完全将广播的操作从Activity中抽离出来，而我们需要做的仅仅是在Activity中通过lifecycle成员的addObserver()与BatteryLifecycleObserver进行关联，这样的Activity更加的易于阅读和管理。 Lifecycle 那么Lifecycle是什么呢？ Lifecycle它持有当前所关联的生命周期组件的生命周期状态； 它允许LifecycleObserver对这些生命周期进行监听。 Event 这些枚举值对应生命周期组件的生命周期回调。1234567ON_CREATEON_STARTON_RESUMEON_PAUSEON_STOPON_DESTROYON_ANY ON_CREATE,ON_START,ON_RESUME这些事件关联的方法会在生命周期组件的对应方法之后调用；而ON_PAUSE,ON_STOP,ON_DESTROY这些事件关联的方法会在生命周期组件的对应方法之前调用。(具体你们编写一个测试的项目就知道了，这里我就不粘贴测试相关的代码了) ON_ANY事件所关联的生命周期方法允许定义两个参数，一个是LifecycleOwner，另一个是Lifecycle.EVENT。其他的时间所关联的方法运行定义一个参数Lifecycle，这一点让同一个LifecycleObserver的实例观察不同的LifecycleOwner成为了可能。 State 表示生命周期组件的生命周期状态。123456789INITIALIZEDDESTROYEDCREATEDSTARTEDRESUMEDpublic boolean isAtLeast(@NonNull State state) &#123; return compareTo(state) &gt;= 0;&#125; 而State和Event之间的关系我们盗用下官方的图。。 其他方法 除了添加和移除LifecycleObserver外，还允许获取当前生命周期组件的状态。123public abstract void addObserver(@NonNull LifecycleObserver observer);public abstract void removeObserver(@NonNull LifecycleObserver observer);public abstract State getCurrentState(); LifecycleOwner 这是一个只含有一个方法的接口，它的作用实际上就是将Lifecycle从生命周期组件中抽象出来。123456789public interface LifecycleOwner &#123; /** * Returns the Lifecycle of the provider. * * @return The lifecycle of the provider. */ @NonNull Lifecycle getLifecycle();&#125; 通常情况下你可以使用LifecycleRegistry来管理生命周期，但是如果你想管理整个application的生命周期，你可以考虑使用ProcessLifecycleOwner。 自定义LifecycleOwner 如果你的support library不低于26.1.0版本，那么SupportActivity默认就是实现了LifecycleOwner接口的，如果你是低于这个版本，那么就需要自己实现LifecycleOwner，前面说了，通常情况下你只要使用LifecycleRegistry就可以了。1234567891011121314151617181920212223public class MyActivity extends Activity implements LifecycleOwner &#123; private LifecycleRegistry mLifecycleRegistry; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); mLifecycleRegistry = new LifecycleRegistry(this); mLifecycleRegistry.markState(Lifecycle.State.CREATED); &#125; @Override public void onStart() &#123; super.onStart(); mLifecycleRegistry.markState(Lifecycle.State.STARTED); &#125; @NonNull @Override public Lifecycle getLifecycle() &#123; return mLifecycleRegistry; &#125;&#125; LifecycleObserver 这个接口没有任何的方法定义。123public interface LifecycleObserver &#123;&#125; 如果你的项目里面使用的是Java8，那么你完全可以实现DefaultLifecycleObserver即可，因为Java 8支持默认接口实现，如果仍旧使用的是Java7，你可以实现LifecycleObserver接口，并通过OnLifecycleEvent注解来进行编写。1234567891011121314151617181920212223/*Java 8*//** * 如果你出现这个问题 * method in super class are prohibited in JVM target 1.6. Recompile with -jvm-target 1.8 * * 请在build.gradle文件中添加 * kaptOption&#123; jvmTarget = '1.8' * &#125; */class TestObserver implements DefaultLifecycleObserver &#123; @Override public void onCreate(LifecycleOwner owner) &#123; // your code &#125;&#125;/*Java 7*/class TestObserver implements LifecycleObserver &#123; @OnLifecycleEvent(ON_STOP) void onStopped() &#123; // your code &#125;&#125; 源码分析 简单的介绍说完了，如果你只是想停留在如何使用的阶段下面的内容完全可以忽略了。 LifecycleRegistry 这个类继承自Lifecycle，我们可以看到在SupportActivity中就是通过这个类来管理lifecycle的。123public class SupportActivity extends Activity implements LifecycleOwner &#123; private LifecycleRegistry mLifecycleRegistry = new LifecycleRegistry(this);&#125; 首先我们来看看addObserver()。123456789101112131415161718192021222324252627282930public void addObserver(@NonNull LifecycleObserver observer) &#123; //1. 生成ObserverWithState类 State initialState = mState == DESTROYED ? DESTROYED : INITIALIZED; ObserverWithState statefulObserver = new ObserverWithState(observer, initialState); //2.当前缓存中存在则返回已存在的，否则添加到缓存，并返回null ObserverWithState previous = mObserverMap.putIfAbsent(observer, statefulObserver); //这种情况是缓存中存在 if (previous != null) &#123; return; &#125; LifecycleOwner lifecycleOwner = mLifecycleOwner.get(); boolean isReentrance = mAddingObserverCounter != 0 || mHandlingEvent; State targetState = calculateTargetState(observer); mAddingObserverCounter++; // 保证observer的前序事件方法都执行 while ((statefulObserver.mState.compareTo(targetState) &lt; 0 &amp;&amp; mObserverMap.contains(observer))) &#123; pushParentState(statefulObserver.mState); statefulObserver.dispatchEvent(lifecycleOwner, upEvent(statefulObserver.mState)); popParentState(); targetState = calculateTargetState(observer); &#125; if (!isReentrance) &#123; sync(); &#125; mAddingObserverCounter--;&#125; 处理生命周期事件分发的方法是handleLifecycleEvent()，这个方法是在ReportFragment的dispatch()方法中调用的。1234567891011121314private void dispatch(Lifecycle.Event event) &#123; Activity activity = getActivity(); if (activity instanceof LifecycleRegistryOwner) &#123; ((LifecycleRegistryOwner) activity).getLifecycle().handleLifecycleEvent(event); return; &#125; if (activity instanceof LifecycleOwner) &#123; Lifecycle lifecycle = ((LifecycleOwner) activity).getLifecycle(); if (lifecycle instanceof LifecycleRegistry) &#123; ((LifecycleRegistry) lifecycle).handleLifecycleEvent(event); &#125; &#125;&#125; 我们可以看到实际上处理时间的方法是在sync()中。123456789101112131415161718public void handleLifecycleEvent(@NonNull Lifecycle.Event event) &#123; State next = getStateAfter(event); moveToState(next);&#125;private void moveToState(State next) &#123; if (mState == next) &#123; return; &#125; mState = next; if (mHandlingEvent || mAddingObserverCounter != 0) &#123; mNewEventOccurred = true; return; &#125; mHandlingEvent = true; sync(); mHandlingEvent = false;&#125; 所以我们还是来看看sync()。1234567891011121314151617181920private void sync() &#123; LifecycleOwner lifecycleOwner = mLifecycleOwner.get(); if (lifecycleOwner == null) &#123; return; &#125; while (!isSynced()) &#123; mNewEventOccurred = false; //举个栗子，Observer的State是ON_RESUME,现在Activity退到后台，生命周期组件的State变成ON_START，反向迭代调用Observer的事件方法，并更新Observer的State if (mState.compareTo(mObserverMap.eldest().getValue().mState) &lt; 0) &#123; backwardPass(lifecycleOwner); &#125; Entry&lt;LifecycleObserver, ObserverWithState&gt; newest = mObserverMap.newest(); //举个栗子，Observer的State是ON_CREATE,现在Activity走到OnResume，生命周期组件的State变成ON_RESUME，则正序迭代调用Observer的事件方法，并更新Observer的State if (!mNewEventOccurred &amp;&amp; newest != null &amp;&amp; mState.compareTo(newest.getValue().mState) &gt; 0) &#123; forwardPass(lifecycleOwner); &#125; &#125; mNewEventOccurred = false;&#125; backwardPass()和forwardPass()方法的处理逻辑是一样的，只是遍历顺序不一样而已。这里只看关键代码。123456while ((observer.mState.compareTo(mState) &lt; 0 &amp;&amp; !mNewEventOccurred &amp;&amp; mObserverMap.contains(entry.getKey()))) &#123; pushParentState(observer.mState); observer.dispatchEvent(lifecycleOwner, upEvent(observer.mState)); popParentState();&#125; 调用给ObserverWithState的dispatchEvent()，而这个方法是调用GenericLifecycleObserver的onStateChanged()方法，里面就会调用到对应的LifecycleObserver，这就是生命周期事件的调用走向。123456void dispatchEvent(LifecycleOwner owner, Event event) &#123; State newState = getStateAfter(event); mState = min(mState, newState); mLifecycleObserver.onStateChanged(owner, event); mState = newState;&#125; ObserverWithState 这是LifecycleRegistry里面定义的静态内部类。12345678910111213141516static class ObserverWithState &#123; State mState; GenericLifecycleObserver mLifecycleObserver; ObserverWithState(LifecycleObserver observer, State initialState) &#123; mLifecycleObserver = Lifecycling.getCallback(observer); mState = initialState; &#125; void dispatchEvent(LifecycleOwner owner, Event event) &#123; State newState = getStateAfter(event); mState = min(mState, newState); mLifecycleObserver.onStateChanged(owner, event); mState = newState; &#125;&#125; 那么LifecycleObserver是如何被转换成GenericLifecycleObserver的呢，我们追溯一下Lifecycling的getCallback()方法。123456789101112131415161718192021222324static GenericLifecycleObserver getCallback(Object object) &#123; //... final Class&lt;?&gt; klass = object.getClass(); //这个方法会找GenerateAdapter的type int type = getObserverConstructorType(klass); if (type == GENERATED_CALLBACK) &#123; List&lt;Constructor&lt;? extends GeneratedAdapter&gt;&gt; constructors = sClassToAdapters.get(klass); if (constructors.size() == 1) &#123; //这里通过createGeneratedAdapter方法获取到GeneratedAdapter GeneratedAdapter generatedAdapter = createGeneratedAdapter( constructors.get(0), object); //生成GenericLifecycleObserver return new SingleGeneratedAdapterObserver(generatedAdapter); &#125; GeneratedAdapter[] adapters = new GeneratedAdapter[constructors.size()]; for (int i = 0; i &lt; constructors.size(); i++) &#123; adapters[i] = createGeneratedAdapter(constructors.get(i), object); &#125; return new CompositeGeneratedAdaptersObserver(adapters); &#125; // 如果是REFLECTIVE_CALLBACK return new ReflectiveGenericLifecycleObserver(object);&#125; 来看看getObserverConstructorType()方法。1234567891011private static int getObserverConstructorType(Class&lt;?&gt; klass) &#123; //1.如果在map中有observer type的缓存，就直接返回 if (sCallbackCache.containsKey(klass)) &#123; return sCallbackCache.get(klass); &#125; //2.如果缓存中没有则调用resolveObserverCallbackType() int type = resolveObserverCallbackType(klass); //3.然后再将其添加到缓存中 sCallbackCache.put(klass, type); return type;&#125; sCallbackCache是一个map，value保存的是class对应的ObserverType。再看这个方法是不是很清晰了。 首先从sCallbackCache缓存中获取ObserverType，如果有则直接返回； 如果没有则调用resolveObserverCallbackType()； 最后再将生成的type存放到sCallbackCache缓存中。 那么resolveObserverCallbackType()又做了什么事情呢？1234567891011121314151617181920212223242526272829303132333435363738394041424344private static int resolveObserverCallbackType(Class&lt;?&gt; klass) &#123; //通过generatedConstructor生成适配器的构造器，典型的适配器模式 Constructor&lt;? extends GeneratedAdapter&gt; constructor = generatedConstructor(klass); if (constructor != null) &#123; //将GeneratedAdapter的构造器存放到缓存中 sClassToAdapters.put(klass, Collections .&lt;Constructor&lt;? extends GeneratedAdapter&gt;&gt;singletonList(constructor)); return GENERATED_CALLBACK; &#125; // 没有添加apt对应的compiler或者没有任何方法有OnLifecycleEvent注解 // 含有OnLifecycleEvent注解对应的方法 boolean hasLifecycleMethods = ClassesInfoCache.sInstance.hasLifecycleMethods(klass); if (hasLifecycleMethods) &#123; return REFLECTIVE_CALLBACK; &#125; Class&lt;?&gt; superclass = klass.getSuperclass(); List&lt;Constructor&lt;? extends GeneratedAdapter&gt;&gt; adapterConstructors = null; // 如果父类是LifecycleObserver的子类 if (isLifecycleParent(superclass)) &#123; if (getObserverConstructorType(superclass) == REFLECTIVE_CALLBACK) &#123; return REFLECTIVE_CALLBACK; &#125; adapterConstructors = new ArrayList&lt;&gt;(sClassToAdapters.get(superclass)); &#125; // 如果接口实现中有LifecycleObserver for (Class&lt;?&gt; intrface : klass.getInterfaces()) &#123; if (!isLifecycleParent(intrface)) &#123; continue; &#125; if (getObserverConstructorType(intrface) == REFLECTIVE_CALLBACK) &#123; return REFLECTIVE_CALLBACK; &#125; if (adapterConstructors == null) &#123; adapterConstructors = new ArrayList&lt;&gt;(); &#125; adapterConstructors.addAll(sClassToAdapters.get(intrface)); &#125; if (adapterConstructors != null) &#123; sClassToAdapters.put(klass, adapterConstructors); return GENERATED_CALLBACK; &#125;&#125; generatedConstructor()这个方法是生成GeneratedAdapter构造器的。1234567891011121314151617181920212223private static Constructor&lt;? extends GeneratedAdapter&gt; generatedConstructor(Class&lt;?&gt; klass) &#123; try &#123; Package aPackage = klass.getPackage(); String name = klass.getCanonicalName(); final String fullPackage = aPackage != null ? aPackage.getName() : ""; final String adapterName = getAdapterName(fullPackage.isEmpty() ? name : name.substring(fullPackage.length() + 1)); //找packageName.className_LifecycleAdapter类，这个类是由apt在编译的时候生成的。 @SuppressWarnings("unchecked") final Class&lt;? extends GeneratedAdapter&gt; aClass = (Class&lt;? extends GeneratedAdapter&gt;) Class.forName( fullPackage.isEmpty() ? adapterName : fullPackage + "." + adapterName); Constructor&lt;? extends GeneratedAdapter&gt; constructor = aClass.getDeclaredConstructor(klass); if (!constructor.isAccessible()) &#123; constructor.setAccessible(true); &#125; return constructor; &#125; catch (ClassNotFoundException e) &#123; return null; &#125; catch (NoSuchMethodException e) &#123; throw new RuntimeException(e); &#125;&#125; 这个类做的事情非常明确，就一件事情，找到apt生成的GenerateAdapter类的constructor。 这里值得说一下，arch库使用的是编译时注解，在编译的时候会对使用了OnLifecycleEvent注解的类自动生成一个ClassName_LifecycleAdapter的类，这个类可以在/app/build/generated/source/apt/packageName下面找到。 什么，你说你没有找到，那你看看是不是没有添加annotationProcessor在build.gradle文件中。12345/*Java*/AnnotationProcessor "android.arch.lifecycle:compiler:1.1.1"/*kotlin*/apply plugin: "kotlin-kapt"kapt "android.arch.lifecycle:compiler:1.1.1" 下面是笔者生成的GenerateAdapter类。123456789101112131415161718192021222324public class BatteryLifecycleObserver_LifecycleAdapter implements GeneratedAdapter &#123; final BatteryLifecycleObserver mReceiver; BatteryLifecycleObserver_LifecycleAdapter(BatteryLifecycleObserver receiver) &#123; this.mReceiver = receiver; &#125; @Override public void callMethods(LifecycleOwner owner, Lifecycle.Event event, boolean onAny, MethodCallsLogger logger) &#123; boolean hasLogger = logger != null; if (event == Lifecycle.Event.ON_RESUME) &#123; if (!hasLogger || logger.approveCall("register", 2)) &#123; mReceiver.register(owner); &#125; return; &#125; if (event == Lifecycle.Event.ON_PAUSE) &#123; if (!hasLogger || logger.approveCall("register", 2)) &#123; mReceiver.unRegister(owner); &#125; return; &#125; &#125;&#125; GenericLifecycleObserver 这个接口继承自LifecycleObserver，提供了一个方法，onStateChanged()。123public interface GenericLifecycleObserver extends LifecycleObserver &#123; void onStateChanged(LifecycleOwner source, Lifecycle.Event event);&#125; SingleGeneratedLifecycleObserver 这个类是GenericLifecycleObserver的子类。12345678910111213141516public class SingleGeneratedAdapterObserver implements GenericLifecycleObserver &#123; // 有一个GeneratedAdapter的成员 private final GeneratedAdapter mGeneratedAdapter; SingleGeneratedAdapterObserver(GeneratedAdapter generatedAdapter) &#123; mGeneratedAdapter = generatedAdapter; &#125; @Override public void onStateChanged(LifecycleOwner source, Lifecycle.Event event) &#123; //非onAny事件 mGeneratedAdapter.callMethods(source, event, false, null); //onAny事件 mGeneratedAdapter.callMethods(source, event, true, null); &#125;&#125; ReflectiveGenericLifecycleObserver 这个类也是GenericLifecycleObserver的子类，如果type是GENERATIVE_CALLBACK，则会使用到这个类。1234567891011121314class ReflectiveGenericLifecycleObserver implements GenericLifecycleObserver &#123; private final Object mWrapped; private final CallbackInfo mInfo; ReflectiveGenericLifecycleObserver(Object wrapped) &#123; mWrapped = wrapped; mInfo = ClassesInfoCache.sInstance.getInfo(mWrapped.getClass()); &#125; @Override public void onStateChanged(LifecycleOwner source, Event event) &#123; mInfo.invokeCallbacks(source, event, mWrapped); &#125;&#125; GeneratedAdapter 这也是只有一个方法的接口。123public interface GeneratedAdapter &#123; void callMethods(LifecycleOwner source, Lifecycle.Event event, boolean onAny, MethodCallsLogger logger);&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[简单的悬浮窗]]></title>
    <url>%2F2018%2F05%2F07%2F%E7%AE%80%E5%8D%95%E7%9A%84%E6%82%AC%E6%B5%AE%E7%AA%97%2F</url>
    <content type="text"><![CDATA[前言 前段时间学习了Window和WindowManager，但是并没有实际的用到它，只是简单的了解了其基本流程和功能，于是想写一个Demo来加深对Window以及WindowManager的理解，就有了这篇文章，写的比较粗糙。 项目地址 AssistiveTouch 实现type的选择 为了让其悬浮在桌面上，它必须有一个System Window的type类型。12345private fun getCompatWindowType(): Int = if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.O) &#123; WindowManager.LayoutParams.TYPE_APPLICATION_OVERLAY&#125; else &#123; WindowManager.LayoutParams.TYPE_SYSTEM_ALERT&#125; 这里会遇到一个问题，因为在Android6.0之后系统权限的限制，我们需要在6.0之后请求SYSTEM_ALERT_WINDOW权限。这里通过Settings的canDrawOverlays来做兼容处理。123456789101112131415161718192021222324private fun checkCompat() &#123; if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.M) &#123; if (Settings.canDrawOverlays(this)) &#123; openFloating() &#125; else &#123; toSettingActivity() &#125; &#125; else &#123; openFloating() &#125;&#125;private fun openFloating() &#123; val intent = Intent(this, AssistiveTouchService::class.java) startService(intent) finish()&#125;@RequiresApi(Build.VERSION_CODES.M)private fun toSettingActivity() &#123; val intent = Intent(Settings.ACTION_MANAGE_OVERLAY_PERMISSION) intent.data = Uri.parse("package:$packageName") startActivity(intent)&#125; 如果没有权限的情况下，通过Intent跳转到设置界面，让用户进行设置。 service 编写一个service，在service中对View进行添加，更新和删除操作，这里不和具体的Activity产生关联，所以onBind()返回null即可。12345678910111213141516171819class AssistiveTouchService : Service() &#123; private val assistiveTouch by lazy &#123; AssistiveTouch(this) &#125; override fun onBind(intent: Intent?): IBinder? &#123; return null &#125; override fun onStartCommand(intent: Intent?, flags: Int, startId: Int): Int &#123; assistiveTouch.addAssistiveTouch() return super.onStartCommand(intent, flags, startId) &#125; override fun onDestroy() &#123; assistiveTouch.removeAssistiveTouch() super.onDestroy() &#125;&#125; 记得在manifest.xml文件中进行配置。 拖拽和点击 因为要同时设置onTouchListener和onClickListener，我们知道onTouchListener是先于onClickListener的。所以onTouchListener需要返回false，但是这样每次移动之后都会触发onClickListener，所以我添加了一个isMoving的标记。123456789101112131415161718192021222324252627282930assistiveTouch.menuView.setOnTouchListener &#123; _, event -&gt; when (event.action) &#123; MotionEvent.ACTION_DOWN -&gt; &#123; scrollAnimator?.cancel() downX = event.rawX downY = event.rawY &#125; MotionEvent.ACTION_MOVE -&gt; &#123; val diffX = event.rawX - downX val diffY = event.rawY - downY downX = event.rawX downY = event.rawY lp.x = Math.floor(lp.x + diffX + 0.5).toInt() lp.y = Math.floor(lp.y + diffY + 0.5).toInt() adjustPositionWhenMove() assistiveTouchWindowManager.updateAssistiveTouch(assistiveTouch, lp) isMoving = true &#125; MotionEvent.ACTION_UP -&gt; adjustPositionWhenActionUp() &#125; false&#125;assistiveTouch.menuView.setOnClickListener &#123; if (!isMoving) &#123; assistiveTouch.menuView.visibility = View.GONE assistiveTouch.menuCl.visibility = View.VISIBLE &#125; else &#123; isMoving = false &#125;&#125; 弹性恢复 当拖拽到屏幕中央的时候取消拖拽，需要将View恢复到贴边状态，考虑到柔和，这里使用属性动画的方式进行处理。123456789101112131415161718192021222324252627282930313233private fun adjustPositionWhenActionUp() &#123; val left = lp.x val top = lp.y val right = assistiveTouchWindowManager.windowWidth - menuWidth - left val bottom = assistiveTouchWindowManager.windowHeight - menuHeight - top scrollAnimator = ObjectAnimator() when (mapOf(left to 0, top to 1, right to 2, bottom to 3).minBy &#123; it.key &#125;?.value) &#123; 0 -&gt; &#123; scrollAnimator?.propertyName = "layoutParamsX" scrollAnimator?.duration = left.toLong() scrollAnimator?.setIntValues(left, 0) &#125; 1 -&gt; &#123; scrollAnimator?.propertyName = "layoutParamsY" scrollAnimator?.duration = top.toLong() scrollAnimator?.setIntValues(top, 0) &#125; 2 -&gt; &#123; scrollAnimator?.propertyName = "layoutParamsX" scrollAnimator?.duration = right.toLong() scrollAnimator?.setIntValues(left, assistiveTouchWindowManager.windowWidth - menuWidth) &#125; 3 -&gt; &#123; scrollAnimator?.propertyName = "layoutParamsY" scrollAnimator?.duration = bottom.toLong() scrollAnimator?.setIntValues(top, assistiveTouchWindowManager.windowHeight - menuHeight) &#125; &#125; scrollAnimator?.target = this scrollAnimator?.interpolator = LinearInterpolator() scrollAnimator?.start()&#125; 余生没那么长，不要一味的付出去惯那些得寸进尺的人，请忠于自己，活得像最初的模样！]]></content>
  </entry>
  <entry>
    <title><![CDATA[git revert/reset]]></title>
    <url>%2F2018%2F04%2F27%2Fgit-revert-reset%2F</url>
    <content type="text"><![CDATA[前言 你是否也曾遇到版本回退的困扰，是否害怕使用版本回退，每次当错误提交之后，就惊的一身冷汗。很早以前，我就是这样子的。 场景一 提交了一个commit，发现修改了不该修改的内容，怎么办？在现有分支上修改完了之后再次提交？这样无疑是可以的，但是我们可以通过git revert命令优雅的解决这种问题。 提交一个commit 我们在A分支上提交一个commit。123$ vim a.txt$ git add .$ git commit -m "增加a.txt文件" revert最近一次commit 这个时候，我们使用revert命令将这次commit给重置。1$ git revert HEAD revert命令实际上做的事情就是重新生成一个commit覆盖掉之前的那个commit。这个时候git仓库的commit记录是这样的。 提交了多次commit才发现有问题 如果commit之后，你并没有发现问题，同时你又提交了多个commit，突然发现之前的commit有问题怎么办呢。123456789101112$ vim a.txt$ git add .$ git commit -m "增加a.txt文件"$ vim b.txt$ git add .$ git commit -m "增加b.txt文件"$ vim c.txt$ git add .$ git commit -m "增加c.txt文件"$ vim d.txt$ git add .$ git commit -m "增加d.txt文件" 发现a.txt的那次commit是不需要的。这个时候我们找到commit的唯一标识，然后使用revert将其废弃掉。123$ git log$ git revert be6afa6ee5 be6afa6ee5就是a.txt文件对应的commit唯一标识。这个时候git仓库的commit记录是这样的。 找不到parent 有时候你在revert的时候会出现如下的问题。 这个问题产生的原因是你revert的这个commit它是从两个不同的分支merge后产生的。所以它的parent有两个，你在revert的时候它不知道该revert到哪一个parent，所以就报错了。 这个时候你可以通过-m参数来指定你需要revert的parent。1$ git revert HEAD -m 1 上面的命令就表示你需要revert那个执行merge命令的分支。 场景二 一年以前，不是很懂git的我，每次版本上线之后都不会打入tag，也不会给每次上线的版本单独保存一个分支，所以就出现了这样的问题。当出现线上bug的时候，我需要找到上线的commit，然后将HEAD指向那个commit修改bug(当时的我是多么的智障啊，哈哈哈)。 版本上线后提交若干个commit 这里我们提交若干个commit。123456789101112$ vim a.txt$ git add .$ git commit -m "增加a.txt文件"$ vim b.txt$ git add .$ git commit -m "增加b.txt文件"$ vim c.txt$ git add .$ git commit -m "增加c.txt文件"$ vim d.txt$ git add .$ git commit -m "增加d.txt文件" 强制回退 线上出现问题，因为没有tag，也没有具体分支对应发布版本。我就copy了一份代码，然后reset强制回退后修改bug(千万不要学我，一年前的我就是这么做的)。123$ git log$ git reset --hard 01aa54f328 这样就将HEAD强制指向了之前发包的commit。 误操作reset 这尼玛就蛋疼了，你在开发过程中发现自己误操作使用了reset命令。卧槽，git log还没有之前的东西了，怎么办怎么办，大脑一片空白。不要慌不要慌，git还是有记录存在的。1$ git reflog 在我们reset –hard之后使用git log命令来查看得到如下结果。 而我们使用git reflog命令来查看可以得到如下结果。 看到这里我们就知道该怎么做了，我们可以直接通过reset命令再将HEAD指向对应的commit。1$ git reset --hard f06e667 这里千万不要用git reset –hard HEAD~1，因为你现在HEAD之前1个commit是init的那个commit。 无关联覆盖 前段时间，朋友遇到这样的问题。他在使用hexo做静态博客的过程中，repo仓库地址填写错误，导致hexo d命令执行后将原来一个项目的所有文件都被覆盖掉了。 其实解决是十分简单的，我们只需要强制覆盖掉远程仓库的代码就可以了。1$ git push origin -f master 但是我想说的并不是这个，因为这是两个完全没有关联的commit历史，执行pull命令的时候会报错。我们如果要pull远程仓库的代码就需要通过如下的命令了。1git pull origin master --allow-unrelated-histories 还可以这么用 比如你修改了若干个文件，但是你想将这些文件作为两次commit，而你又恰巧执行了git add .命令，这个时候该如何使用git reset命令呢？1234567$ vim a.txt$ vim b.txt$ git add .$ git reset HEAD b.txt$ git commit -m &quot;修改a.txt文件&quot;$ git add .$ git commit -m &quot;修改b.txt文件&quot; git reset命令添加–hard参数之后确实是一个很危险的命令，但是如果你只是使用git reset命令是并不危险的，因为它修改的仅仅是暂存区的内容，而不会修改到你工作目录的文件。 余生没那么长，不要一味的付出去惯那些得寸进尺的人，请忠于自己，活得像最初的模样！]]></content>
  </entry>
  <entry>
    <title><![CDATA[git cherry-pick]]></title>
    <url>%2F2018%2F04%2F27%2Fgit-cherry-pick%2F</url>
    <content type="text"><![CDATA[前言 前段时间，有位朋友在群里问了这样一个问题。他们开了两个分支在并行开发两个功能(以下记为A,B)，但是产品突然说A分支上的功能不上线，但是A分支上有部分东西的修改是本次迭代必须的。也就是说出现了需要部分合并的情况，当时我的反应就是使用cherry-pick命令。 举个栗子在A分支上开发功能 我们在A分支上提交若干个commit。123456$ vim a.txt$ git add .$ git commit -m "A分支提交"$ vim b.txt$ git add .$ git commit -m "A分支提交" 在B分支上开发功能 我们在B分支上提交若干个commit。123456$ vim c.txt$ git add.$ git commit -m "B分支提交"$ vim d.txt$ git add .$ git commit -m "B分支提交" 这个时候git仓库的commit记录是这样的。 部分合并 这个时候产品说A分支上的功能这个版本不上线。但是实际上A分支上的第一次commit是本次迭代所必须的。我们需要将其部分合并到B分支，我们需要找到这个commit的唯一标识。12345$ git checkout A$ git log$ git checkout B$ git cherry-pick d3088c71de2 这里的d3088c71de2是在A分支上通过git log命令查找的commit的唯一标识。这个时候我们就完成了将A分支上的功能部分合并到B分支，是不是很神奇呢？我们就可以继续B功能的开发了。 cherry-pick实际上做的事情是将指定的commit复制后拼接在当前分支的commit记录后。 余生没那么长，不要一味的付出去惯那些得寸进尺的人，请忠于自己，活得像最初的模样！]]></content>
  </entry>
  <entry>
    <title><![CDATA[git tag]]></title>
    <url>%2F2018%2F04%2F27%2Fgit-tag%2F</url>
    <content type="text"><![CDATA[平常在翻看书籍的时候，是不是经常的使用书签记录当前阅读的地方，方便下次接着阅读。其实，在git中，也有个类似的功能，就是tag。 场景 在手机app开发中，如果你没有使用热修复等功能，那么每次线上出现严重bug需要fix的时候，你就得check出发布的版本，然后修改bug之后发包上线，这是一个很麻烦的操作。 每个人的处理方式不一样，有些人会把每次发版的版本单独做一个分支，这是一个方法。但是版本迭代如此之快，岂不是会有若干个分支存在，你肯定会说，等后续版本发布之后就可以将前面的分支删除掉了。那么，这个时候，倘若产品需要以前的版本你该如何(我还真就遇到过)？ 实际上我们通过tag来管理每个版本十分方便。 举个栗子第一版开发 下面我们开始第一个版本的开发，提交若干个commit。1234567$ vim a.txt$ git add .$ git commit -m "第一次提交"$ vim b.txt$ git add .$ git commit -m "第二次提交"$ git push origin master 这个时候第一个版本迭代完成，我们可以发布上线。在发布上线的时候，我们使用tag记录当前版本最后的commit。123$ git tag --list$ git tag -a v1.0.0 -m "版本1.0.0上线"$ git push origin v1.0.0 这个时候git仓库的commit记录如下。 第二版迭代 发布上线之后，我们开始了第二版的迭代，再提交若干个commit。123456789$ vim c.txt$ git add .$ git commit -m "第二版开发"$ vim d.txt$ git add .$ git commit -m "第二版开发"$ vim a.txt$ git add .$ git commit -m "第二版开发" fix bug 这个时候，由用户反馈某个功能出现问题，需要修复重新打包上线。这个时候我们需要将tag来出来，然后修复bug。1$ git checkout v1.0.0 -b bugfix 这个时候我们将之前tag所对应的commit单独checkout出来为一个分支。然后在这个分支上进行bugfix。123$ vim a.txt$ git add .$ git commit -m "bug fix" 这个时候bug fix完成，然后我们需要将bug fix之后的代码merge到主分支，以保证主分支的代码也是bug fix的。这里a.txt文件是同时修改了，所以会有冲突，如果你知道如何解决冲突，请看git rebase/merge。1234$ git checkout master$ git merge bugfix$ git add .$ git commit -m "v1.0.0bug fix" 这个时候git仓库的commit是这个样子的。 重新打入tag 千万要记住，你bugfix之后要会从新打入tag，防止出现其他的问题。1234$ git checkout bugfix$ git tag --list$ git tag -a v1.0.1 -m "v1.0.1 bug fix"$ git push origin v1.0.1 余生没那么长，不要一味的付出去惯那些得寸进尺的人，请忠于自己，活得像最初的模样！]]></content>
  </entry>
  <entry>
    <title><![CDATA[git rebase/merge]]></title>
    <url>%2F2018%2F04%2F27%2Fgit-rebase-merge%2F</url>
    <content type="text"><![CDATA[之前git常用命令是放在一篇文章中的，但是学习的东西越来越多，导致文章的阅读行变差，于是决定将其拆分开。 场景 git rebase和git merge的作用有相似之处，在多分支开发中，经常会碰到分支代码合并的情况，而merge和rebase都可以实现这类需求。 举个栗子创建分支 接下来我们创建两个分支funA和funB。12$ git checkout -b funA$ git checkout -b funB 在A分支产生多次commit记录 然后我们再切回到A分支上，模拟产生多个commit。1234567$ git checkout funA$ vim a.txt$ git add .$ git commit -m "功能A第一次提交"$ vim a.txt$ git add .$ git commit -m "功能A第二次提交" 这个时候A分支上产生了2个commit记录。 在B分支产生多次commit记录 接着我们再切回到B分支上，模拟产生多个commit。1234567$ git checkout funB$ vim b.txt$ git add .$ git commit -m "功能B第一次提交"$ vim b.txt$ git add .$ git commit -m "功能B第二次提交" 这个时候B分支上也产生了2个commit记录。这个时候git仓库的commit记录是这个样子的。 接下来我们保持这个状态然后copy一份文件出来，分别测试git merge和git rebase两个命令。 git merge 我们将funB分支上的代码merge到funA分支上。12$ git checkout funA$ git merge funB merge操作产生了一个新的commit。这个时候git仓库的commit记录是这个样子的。 git rebase 看完了merge，我们再来将funA分支上的代码rebase到funB分支上。12$ git checkout funA$ git rebase funB rebase操作并不像merge操作产生一个新的commit，它会将某个分支上commit都复制一份然后拼接在指定分支后面。这个时候git仓库的commit记录是这个样子的。 冲突 上面只是简单的模拟了一下merge和rebase，但是实际开发过程中，肯定会遇到两个分支修改了相同文件的情况，这个时候我们就需要解决冲突。 git merge 我们来看看如果两个分支修改了相同的文件，在merge的时候会出现什么。 可以看到在终端中提示有冲突，这个时候我们打开a.txt文件进行查看。 这个时候我们需要将冲突的地方解决后重新提交就可以了。 git rebase 而git rebase对于解决冲突来说比merge要稍微复杂一点点。我们在两个分支上修改了同一个文件，然后执行rebase命令，发现终端有如下的提示。 而这个时候不在任何一个分支上，我们可以通过git branch查看当前的分支状态。 正如终端所说，你有两种选择 修改冲突文件，然后使用git rebase –continue继续rebase操作； 使用git rebase –abort终止rebase操作。 我们解决完冲突后，使用git add将修改添加，继续git rebase –continue操作，然后就rebase成功了。 异同 git rebase和git merge都可以将多个分支的commit合并到同一个分支上； rebase操作首先会复制当前分支上的每个commit，然后再拼接到另外的分支上；而merge会生成一个新的commit，它包含了待merge分支的所有commit，然后再拼接到分支上。更加复杂的场景 这里就不赘述了，直接给一张图自行理解提交记录，这里有三个分支master，server，client。 假设你希望将 client 中的修改合并到主分支并发布，但暂时并不想合并 server 中的修改，因为它们还需要经 过更全面的测试。 这时，你就可以使用 git rebase 命令的 –onto 选项，选中在 client 分支里但不在 server 分支里的修改(即 C8 和 C9)，将它们在 master 分支上重放。1$ git rebase --onto master server client 这个命令的意思是:“取出 client 分支，找出处于 client 分支和 server 分支的共同祖先之后的修改，然 后把它们在 master 分支上重放一遍”。 这理解起来有一点复杂，不过效果非常酷。 余生没那么长，不要一味的付出去惯哪些得寸进尺的人，请忠于自己，活的像最初的模样~]]></content>
  </entry>
  <entry>
    <title><![CDATA[设计模式-代理模式]]></title>
    <url>%2F2018%2F04%2F18%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言 前段时间我们分析了kotlin的委托，委托实际上有点类似于静态代理模式，趁着委托的记忆还没有消失(我的记忆力比鱼稍微好一丢丢(理直气壮))，我们来分析下代理模式。 静态代理 静态代理模式中，有3个重要的角色 协议，它抽离了代理类和真实类的共性； 代理类，直接与客户进行交互，在内部访问真实类，但同时又可以对真实类的访问附加额外的操作； 真实类，代理类中真正操作的。 协议 首先我们定义一个抽象接口，它有一个request方法。123interface IBase&#123; fun request() &#125; 真实类 然后，我们定义一个真实类，它实现了协议。12345class BaseImpl:IBase&#123; override fun request()&#123; //...request &#125;&#125; 代理类 最后，我们定义一个代理类，它同样也实现了协议，同时它包含了一个真实类的实例对象。12345678910class BaseImplProxy:IBase&#123; private val baseImpl:BaseImpl by lazy&#123; BaseImpl() &#125; override fun request()&#123; //这里实际调用真实角色的request() baseImpl.request() &#125;&#125; 写到这里，我们发现上面和kotlin的委托是一模一样的原理。但是静态代理中，我们可以在request()中做一些额外的操作。12345678910111213override fun request()&#123; preRequest() baseImpl.request() postRequest()&#125;private fun preRequest()&#123; //...请求前做的事情&#125;private fun postRequest()&#123; //...请求后做的事情&#125; kotlin的委托就不能做这些事情。 动态代理 Java中的动态代理，我们得认识两个玩意，一个是InvocationHandler，一个是Proxy，它们位于reflect包下面。 协议 动态代理中，我们同样需要定义协议。123interface IBase&#123; fun request()&#125; 真实类 然后我们定义一个真实类。1234class BaseImpl : IBase&#123; override fun request()&#123; &#125;&#125; 实现InvocationHandler 然后我们需要实现InvocationHandler接口，里面包含有一个BaseImpl的实例对象。1234567891011class InvocationHandlerImpl : InvocationHandler &#123; private val baseImpl:BaseImpl by lazy&#123; BaseImpl() &#125; override fun invoke(proxy: Any?, method: Method?, args: Array&lt;out Any&gt;?): Any? &#123; return method?.invoke(baseImpl, args) &#125;&#125; 创建代理类 一般我们会通过Proxy.newProxyInstance()创建代理类，它接受ClassLoader, Class&lt;?&gt;[]和一个InvocationHandler。12val clazz = IBaseImpl::class.javaval iBase:IBase = Proxy.newProxyInstance(clazz.classLoader, clazz.interfaces, object: InvocationHandlerImpl()&#123;&#125;) as IBase 这样我们通过iBase对象调用request()的时候实际上会被回调到InvocationHandler的invoke()，而我们在invoke()中调用了BaseImpl的request()。 Retrofit的动态代理 我们知道Retrofit里面使用了动态代理模式的。我们可以翻看它的源码，在Retrofit.java文件的create()中我们可以看到有动态代理的调用。12345678910111213141516171819202122public &lt;T&gt; T create(final Class&lt;T&gt; service) &#123; Utils.validateServiceInterface(service); if (validateEagerly) &#123; eagerlyValidateMethods(service); &#125; return (T) Proxy.newProxyInstance(service.getClassLoader(), new Class&lt;?&gt;[] &#123; service &#125;, new InvocationHandler() &#123; private final Platform platform = Platform.get(); @Override public Object invoke(Object proxy, Method method, Object... args) throws Throwable &#123; if (method.getDeclaringClass() == Object.class) &#123; return method.invoke(this, args); &#125; if (platform.isDefaultMethod(method)) &#123; return platform.invokeDefaultMethod(method, service, proxy, args); &#125; ServiceMethod serviceMethod = loadServiceMethod(method); OkHttpCall okHttpCall = new OkHttpCall&lt;&gt;(serviceMethod, args); return serviceMethod.callAdapter.adapt(okHttpCall); &#125; &#125;);&#125; 比如我们定义如下一个接口请求。12345678interface AdsService &#123; @POST("v4/client/ad/config") fun fetchAdsInfo( @Body reqBean: AdsReqBean ): Single&lt;Response&lt;BaseRespBean&lt;AdsRespBean&gt;&gt;&gt;&#125; 然后通过Retrofit的create()方法，我们就可以得到一个AdsService的代理对象了。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Window与WindowManager]]></title>
    <url>%2F2018%2F04%2F16%2FWindow%E4%B8%8EWindowManager%2F</url>
    <content type="text"><![CDATA[前言 日常开发过程中，接触更多的是View，对于Window却没有太多的接触，但实际上View都是通过Window来呈现的，而Window又是被WindowManager所管理的。这篇文章只是简单的介绍Window，WindowManager。 Window Window是一个抽象类，它的唯一实现是PhoneWindow。应用程序的启动流程中会调用ActivityThread的performLaunchActivity()，而在这个方法中会调用Activity的attach()，我们再来看看attach()。123456789101112131415161718192021222324252627282930313233final void attach(Context context, ActivityThread aThread, Instrumentation instr, IBinder token, int ident, Application application, Intent intent, ActivityInfo info, CharSequence title, Activity parent, String id, NonConfigurationInstances lastNonConfigurationInstances, Configuration config, String referrer, IVoiceInteractor voiceInteractor, Window window, ActivityConfigCallback activityConfigCallback) &#123; //1.创建PhoneWindow，并设置PhoneWindow的一些属性 mWindow = new PhoneWindow(this, window, activityConfigCallback); mWindow.setWindowControllerCallback(this); mWindow.setCallback(this); mWindow.setOnWindowDismissedCallback(this); mWindow.getLayoutInflater().setPrivateFactory(this); if (info.softInputMode != WindowManager.LayoutParams.SOFT_INPUT_STATE_UNSPECIFIED) &#123; mWindow.setSoftInputMode(info.softInputMode); &#125; if (info.uiOptions != 0) &#123; mWindow.setUiOptions(info.uiOptions); &#125; //2.给PhoneWindow设置WindowManager mWindow.setWindowManager( (WindowManager)context.getSystemService(Context.WINDOW_SERVICE), mToken, mComponent.flattenToString(), (info.flags &amp; ActivityInfo.FLAG_HARDWARE_ACCELERATED) != 0); if (mParent != null) &#123; mWindow.setContainer(mParent.getWindow()); &#125; mWindowManager = mWindow.getWindowManager(); mWindow.setColorMode(info.colorMode);&#125; Activity的attach()中主要做了两件事情 创建PhoneWindow； 给PhoneWindow设置WindowManager DecorView PhoneWindow中有一个成员变量。1private DecorView mDecor; 它是DecorView，它是一个FrameLayout，作为Window的顶层View。那么它是如何被创建的呢，这就要说到Activity的setContentView()了。追随源码。12345678public void setContentView(@LayoutRes int layoutResID) &#123; getWindow().setContentView(layoutResID); initWindowDecorActionBar();&#125;public Window getWindow() &#123; return mWindow;&#125; getWindow()只是简单的返回了mWindow这个成员，还记得前面的attach()吗，这个方法里面将mWindow初始化为PhoneWindow。也就是说setContentView()实际上调用了PhoneWindow的setContentView()方法。12345678910111213141516171819public void setContentView(int layoutResID) &#123; if (mContentParent == null) &#123; //1.创建decorView installDecor(); &#125; else if (!hasFeature(FEATURE_CONTENT_TRANSITIONS)) &#123; mContentParent.removeAllViews(); &#125; if (hasFeature(FEATURE_CONTENT_TRANSITIONS)) &#123; final Scene newScene = Scene.getSceneForLayout(mContentParent, layoutResID, getContext()); transitionTo(newScene); &#125; else &#123; //2.将传入的布局文件加载到mContentParent中 mLayoutInflater.inflate(layoutResID, mContentParent); &#125; //...&#125; 接下来我们来看看installDecor()里面做了什么事情。1234567891011121314151617private void installDecor() &#123; if (mDecor == null) &#123; //创建DecorView mDecor = generateDecor(-1); //... &#125; else &#123; mDecor.setWindow(this); &#125; if (mContentParent == null) &#123; mContentParent = generateLayout(mDecor); &#125; else &#123; //... &#125; //...&#125; installDecor()主要干了两件事情。 调用generator()方法创建DecorView； 调用generateLayout()加载布局。 generateDecor()就是创建DecorView。1234protected DecorView generateDecor(int featureId) &#123; //... return new DecorView(context, featureId, this, getAttributes());&#125; 我们再来看看generateLayout()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273protected ViewGroup generateLayout(DecorView decor) &#123; /** * 这里有一大段代码都是在设置属性信息，我就只粘贴关键代码 */ //...省略若干行代码 /** * 这里是根据feature找到加载进DecorView的布局文件 */ int layoutResource; int features = getLocalFeatures(); if ((features &amp; (1 &lt;&lt; FEATURE_SWIPE_TO_DISMISS)) != 0) &#123; layoutResource = R.layout.screen_swipe_dismiss; &#125; else if ((features &amp; ((1 &lt;&lt; FEATURE_LEFT_ICON) | (1 &lt;&lt; FEATURE_RIGHT_ICON))) != 0) &#123; if (mIsFloating) &#123; TypedValue res = new TypedValue(); getContext().getTheme().resolveAttribute( R.attr.dialogTitleIconsDecorLayout, res, true); layoutResource = res.resourceId; &#125; else &#123; layoutResource = R.layout.screen_title_icons; &#125; removeFeature(FEATURE_ACTION_BAR); &#125; else if ((features &amp; ((1 &lt;&lt; FEATURE_PROGRESS) | (1 &lt;&lt; FEATURE_INDETERMINATE_PROGRESS))) != 0 &amp;&amp; (features &amp; (1 &lt;&lt; FEATURE_ACTION_BAR)) == 0) &#123; layoutResource = R.layout.screen_progress; &#125; else if ((features &amp; (1 &lt;&lt; FEATURE_CUSTOM_TITLE)) != 0) &#123; if (mIsFloating) &#123; TypedValue res = new TypedValue(); getContext().getTheme().resolveAttribute( R.attr.dialogCustomTitleDecorLayout, res, true); layoutResource = res.resourceId; &#125; else &#123; layoutResource = R.layout.screen_custom_title; &#125; removeFeature(FEATURE_ACTION_BAR); &#125; else if ((features &amp; (1 &lt;&lt; FEATURE_NO_TITLE)) == 0) &#123; if (mIsFloating) &#123; TypedValue res = new TypedValue(); getContext().getTheme().resolveAttribute( R.attr.dialogTitleDecorLayout, res, true); layoutResource = res.resourceId; &#125; else if ((features &amp; (1 &lt;&lt; FEATURE_ACTION_BAR)) != 0) &#123; layoutResource = a.getResourceId( R.styleable.Window_windowActionBarFullscreenDecorLayout, R.layout.screen_action_bar); &#125; else &#123; layoutResource = R.layout.screen_title; &#125; &#125; else if ((features &amp; (1 &lt;&lt; FEATURE_ACTION_MODE_OVERLAY)) != 0) &#123; layoutResource = R.layout.screen_simple_overlay_action_mode; &#125; else &#123; layoutResource = R.layout.screen_simple; &#125; mDecor.startChanging(); //将找到的layoutResource添加到DecorView中 mDecor.onResourcesLoaded(mLayoutInflater, layoutResource); //找到id是android.R.id.content ViewGroup contentParent = (ViewGroup)findViewById(ID_ANDROID_CONTENT); if (contentParent == null) &#123; throw new RuntimeException("Window couldn't find content container view"); &#125; //... return contentParent;&#125; 可以看到这个方法的逻辑非常清晰。 设置属性信息； 根据feature找到layoutResource，用来加载进DecorView； 找到id为android.R.id.content的控件返回，这里就是赋给mContentParent的。 mDecor.onResourcesLoaded()里面就是将layoutResource加载进mDecorView中。1234567891011121314151617181920void onResourcesLoaded(LayoutInflater inflater, int layoutResource) &#123; //... final View root = inflater.inflate(layoutResource, null); //将root添加到DecorView中 if (mDecorCaptionView != null) &#123; if (mDecorCaptionView.getParent() == null) &#123; addView(mDecorCaptionView, new ViewGroup.LayoutParams(MATCH_PARENT, MATCH_PARENT)); &#125; mDecorCaptionView.addView(root, new ViewGroup.MarginLayoutParams(MATCH_PARENT, MATCH_PARENT)); &#125; else &#123; addView(root, 0, new ViewGroup.LayoutParams(MATCH_PARENT, MATCH_PARENT)); &#125; mContentRoot = (ViewGroup) root; initializeElevation();&#125; PhoneWindow的setContentView()主要做了两件事情 调用installDecor()创建DecorView； 通过LayoutInflater将我们setContentView()传入的布局加载到mContentParent中，也就是android.R.id.content中。 一般结构 这里我看了layoutResource的布局文件，发现大部分的布局都如下图所示。而我们的布局就是被放到这个android.R.id.content布局中的。到这里就差不多了，DecorView就这样加载完毕了。 Callback Window中定义了一个Callback接口，Activity实现了Window.Callback接口，所以Window可以将某些事情交给Activity处理，回调接口里面的方法目前用到的不是很多，以后有用到的时候再来更新下面的方法。12345678910111213141516171819202122232425262728293031//键盘事件分发public boolean dispatchKeyEvent(KeyEvent event);public boolean dispatchKeyShortcutEvent(KeyEvent event);//触摸事件分发public boolean dispatchTouchEvent(MotionEvent event);public boolean dispatchTrackballEvent(MotionEvent event);public boolean dispatchGenericMotionEvent(MotionEvent event);public boolean dispatchPopulateAccessibilityEvent(AccessibilityEvent event);public View onCreatePanelView(int featureId);public boolean onCreatePanelMenu(int featureId, Menu menu);public boolean onPreparePanel(int featureId, View view, Menu menu);//menu打开的时候public boolean onMenuOpened(int featureId, Menu menu);//menuitem 选中的时候public boolean onMenuItemSelected(int featureId, MenuItem item);public void onWindowAttributesChanged(WindowManager.LayoutParams attrs);public void onContentChanged();//Window焦点改变的时候public void onWindowFocusChanged(boolean hasFocus);public void onAttachedToWindow();public void onDetachedFromWindow();public void onPanelClosed(int featureId, Menu menu);public boolean onSearchRequested();public boolean onSearchRequested(SearchEvent searchEvent);public ActionMode onWindowStartingActionMode(ActionMode.Callback callback);public ActionMode onWindowStartingActionMode(ActionMode.Callback callback, int type);public void onActionModeStarted(ActionMode mode);public void onActionModeFinished(ActionMode mode);default public void onProvideKeyboardShortcuts( List&lt;KeyboardShortcutGroup&gt; data, @Nullable Menu menu, int deviceId) &#123; &#125;;default public void onPointerCaptureChanged(boolean hasCapture) &#123; &#125;; WindowManager WindowManager是一个接口，它继承自ViewManager，它的实现类是WindowManagerImpl。 ViewManager十分简单，只有添加，更新和删除三个方法。123456public interface ViewManager&#123; public void addView(View view, ViewGroup.LayoutParams params); public void updateViewLayout(View view, ViewGroup.LayoutParams params); public void removeView(View view);&#125; 它的具体实现是在WindowManagerImpl中。12345678910111213141516@Overridepublic void addView(@NonNull View view, @NonNull ViewGroup.LayoutParams params) &#123; applyDefaultToken(params); mGlobal.addView(view, params, mContext.getDisplay(), mParentWindow);&#125;@Overridepublic void updateViewLayout(@NonNull View view, @NonNull ViewGroup.LayoutParams params) &#123; applyDefaultToken(params); mGlobal.updateViewLayout(view, params);&#125;@Overridepublic void removeView(View view) &#123; mGlobal.removeView(view, false);&#125; 可以看到WindowManagerImpl中的方法调用都是委托给了mGlobal成员变量，它是WindowManagerGlobal的单例对象。1private final WindowManagerGlobal mGlobal = WindowManagerGlobal.getInstance(); WINDOW_SERVICE 在前面讲过的attach()中，我们还有一点没有分析，就是调用mWindow的setWindowManager()。这个方法的实现是在Window中。1234567891011public void setWindowManager(WindowManager wm, IBinder appToken, String appName, boolean hardwareAccelerated) &#123; mAppToken = appToken; mAppName = appName; mHardwareAccelerated = hardwareAccelerated || SystemProperties.getBoolean(PROPERTY_HARDWARE_UI, false); if (wm == null) &#123; wm = (WindowManager)mContext.getSystemService(Context.WINDOW_SERVICE); &#125; mWindowManager = ((WindowManagerImpl)wm).createLocalWindowManager(this);&#125; 我们来看看mContext.getSystemService()是如何获取到WindowManager的。Context的实现类是ContextImpl。1234@Overridepublic Object getSystemService(String name) &#123; return SystemServiceRegistry.getSystemService(this, name);&#125; SystemServiceRegistry是一个专门管理系统服务的类。1234public static Object getSystemService(ContextImpl ctx, String name) &#123; ServiceFetcher&lt;?&gt; fetcher = SYSTEM_SERVICE_FETCHERS.get(name); return fetcher != null ? fetcher.getService(ctx) : null;&#125; SYSTEM_SERVICE_FETCHERS是一个HashMap，通过Context.WINDOW_SERVICE可以获取到注册的WindowManagerImpl对象。在SystemServiceRegistry的静态代码块中我们可以找到注册WindowManager的代码。123456registerService(Context.WINDOW_SERVICE, WindowManager.class, new CachedServiceFetcher&lt;WindowManager&gt;() &#123; @Override public WindowManager createService(ContextImpl ctx) &#123; return new WindowManagerImpl(ctx); &#125;&#125;); 通过CachedServiceFetcher的get()我们可以获取到WindowManagerImpl对象。123456789101112131415public final T getService(ContextImpl ctx) &#123; final Object[] cache = ctx.mServiceCache; synchronized (cache) &#123; Object service = cache[mCacheIndex]; if (service == null) &#123; try &#123; service = createService(ctx); cache[mCacheIndex] = service; &#125; catch (ServiceNotFoundException e) &#123; onServiceNotFound(e); &#125; &#125; return (T)service; &#125;&#125; 然后我们再回过头看看Window的setWindowManager()里面的createLocalWindowManager()。123public WindowManagerImpl createLocalWindowManager(Window parentWindow) &#123; return new WindowManagerImpl(mContext, parentWindow);&#125; 这里创建一个新的WindowManagerImpl，并将PhoneWindow与之关联。 LayoutParams WindowManager中有个重要的内部类，它里面定义了Window的一些重要属性，比如Z-order，window样式等。 type 我们知道Window有很多种，比如Toast，PopupWindow，Dialog，Activity等，在使用手机的过程中经常会看到有很多的Window层叠显示，但是它们必然会存在覆盖关系，也就是说Window在Z轴上是有排列顺序的。而type这个字段实际上表示的是Window在z轴上的排列顺序，也就是我们说的Z-Order，type值越大，Window的显示越靠前。 在LayoutParams中定义了很多的常量，我们可以将Window的分为3类。 Application Window，type值在1-99之间，一般对应着一个Activity； Sub Window，type值在1000-1999之间，一般不能独立存在，需要依附在父Window上，比如Dialog； System Window，type值在2000-2999之间，一般需要声明权限才能够创建。 Application Window的常量定义如下。123456public static final int FIRST_APPLICATION_WINDOW = 1;public static final int TYPE_BASE_APPLICATION = 1;public static final int TYPE_APPLICATION = 2;public static final int TYPE_APPLICATION_STARTING = 3;public static final int TYPE_DRAWN_APPLICATION = 4;public static final int LAST_APPLICATION_WINDOW = 99; Sub Window的常量定义如下。12345678public static final int FIRST_SUB_WINDOW = 1000;public static final int TYPE_APPLICATION_PANEL = FIRST_SUB_WINDOW;public static final int TYPE_APPLICATION_MEDIA = FIRST_SUB_WINDOW + 1;public static final int TYPE_APPLICATION_SUB_PANEL = FIRST_SUB_WINDOW + 2;public static final int TYPE_APPLICATION_ATTACHED_DIALOG = FIRST_SUB_WINDOW + 3;public static final int TYPE_APPLICATION_MEDIA_OVERLAY = FIRST_SUB_WINDOW + 4;public static final int TYPE_APPLICATION_ABOVE_SUB_PANEL = FIRST_SUB_WINDOW + 5;public static final int LAST_SUB_WINDOW = 1999; System Window的常量定义比较多，这里只列举几个，具体的可以在LayoutParam中找到。123456789public static final int FIRST_SYSTEM_WINDOW = 2000;public static final int TYPE_STATUS_BAR = FIRST_SYSTEM_WINDOW;public static final int TYPE_SEARCH_BAR = FIRST_SYSTEM_WINDOW+1;public static final int TYPE_SYSTEM_DIALOG = FIRST_SYSTEM_WINDOW+8;public static final int TYPE_INPUT_METHOD = FIRST_SYSTEM_WINDOW+11;public static final int TYPE_INPUT_METHOD_DIALOG= FIRST_SYSTEM_WINDOW+12;public static final int TYPE_STATUS_BAR_PANEL = FIRST_SYSTEM_WINDOW+14;public static final int TYPE_SECURE_SYSTEM_OVERLAY = FIRST_SYSTEM_WINDOW+15;public static final int LAST_SYSTEM_WINDOW = 2999; softInputMode 这个东西我们在开发过程中经常用到，比如在manifest.xml文件中的activity中设置windowSoftInputMode属性，这就是在设置softInputMode值。softInputMode会影响两点内容 软键盘的显示状态，state； Window与软键盘之间的交互方式，adjust option。 软键盘的显示状态 softInputMode控制软键盘的显示状态的常量值有如下几种，在LayoutParams中都可以找到。12345678public static final int SOFT_INPUT_MASK_STATE = 0x0f;public static final int SOFT_INPUT_STATE_UNSPECIFIED = 0;public static final int SOFT_INPUT_STATE_UNCHANGED = 1;public static final int SOFT_INPUT_STATE_HIDDEN = 2;public static final int SOFT_INPUT_STATE_ALWAYS_HIDDEN = 3;public static final int SOFT_INPUT_STATE_VISIBLE = 4;public static final int SOFT_INPUT_STATE_ALWAYS_VISIBLE = 5; 下面我们来看看这些常量值会怎样影响软键盘的显示状态。 SOFT_INPUT_STATE_UNSPECIFIED，不设置任何显示状态； SOFT_INPUT_STATE_UNCHANGED，不改变软件盘的显示状态，举个栗子，现在有两个界面A和B，如果A界面的softInputMode设置为stateUnchanged，当你从A界面跳转到B界面再返回A界面的时候，软键盘的显示状态不会发生改变，也就是说，在B界面软件盘如果是显示，那么返回A的时候就是显示的；反之，如果B界面软键盘显示状态是隐藏的，那么返回A的时候就是隐藏的； SOFT_INPUT_STATE_HIDDEN，在合适的时候隐藏软键盘，比如用户导航到界面的时候； SOFT_INPUT_STATE_ALWAYS_HIDDEN，当Window获得焦点的时候总是隐藏软件盘，这个和stateHidden还是有区别的。举个栗子，同样有两个界面A和B，如果A的softInputMode设置的是stateHidden，当第一次导航到A界面的时候软键盘是隐藏的，当从A跳转到B界面，B界面将软键盘显示出来后再返回A界面，这个时候A界面软键盘保持显示状态；但是，如果A界面的softInputMode设置的是stateAlwaysHidden，同样的操作从B返回A界面的时候，软键盘会被隐藏掉； SOFT_INPUT_STATE_VISIBLE，在合适的时候显示软键盘，比如用户导航到界面的时候； SOFT_INPUT_STATE_ALWAYS_VISIBLE，当Window获得焦点的时候总是显示软键盘，这个和stateVisible的区别我就不举栗子了，与stateHidden，stateAlwaysHidden的区别一样。 Window和软键盘的交互方式 softInputMode控制Window和软键盘之间的交互方式的常量值有如下几种，同样定义在LayoutParams中。123456public static final int SOFT_INPUT_MASK_ADJUST = 0xf0;public static final int SOFT_INPUT_ADJUST_UNSPECIFIED = 0x00;public static final int SOFT_INPUT_ADJUST_RESIZE = 0x10;public static final int SOFT_INPUT_ADJUST_PAN = 0x20;public static final int SOFT_INPUT_ADJUST_NOTHING = 0x30; 同样我们再来看看这些常量值会如何影响Window和软键盘之间的交互方式。 SOFT_INPUT_ADJUST_UNSPECIFIED，不指定任何的交互方式； SOFT_INPUT_ADJUST_RESIZE，允许Window改变大小当软键盘显示的时候，这样能够保证Window不被软键盘所遮挡。前方高能，注意，如果Window的flag包含FLAG_FULLSCREEN，那这个值将被忽略，当软键盘显示的时候，Window依旧保持full screen； SOFT_INPUT_ADJUST_PAN，当软键盘显示的时候，设置一个窗口平移。这个值不需要处理Window的大小改变，而只需要通过framework层做一个平移保证当前的输入焦点相对于用户是可见的就可以了； SOFT_INPUT_ADJUST_NOTHING，当软键盘显示的时候不做任何调整。 flag 这个值主要设置的是Window的一些属性。这里列举一些比较有用的flags。123456789101112//隐藏所有的装饰窗口，比如statusbar等public static final int FLAG_FULLSCREEN = 0x00000400;//当前Window在前台会保持屏幕常亮public static final int FLAG_KEEP_SCREEN_ON = 0x00000080;//当前Window允许在锁屏之上显示，大概和那些锁屏软件有关系public static final int FLAG_SHOW_WHEN_LOCKED = 0x00080000;//当前Window在前台允许进行锁屏操作public static final int FLAG_ALLOW_LOCK_WHILE_SCREEN_ON = 0x00000001;//模糊所有在Window之下的东西public static final int FLAG_DIM_BEHIND = 0x00000002;//硬件加速public static final int FLAG_HARDWARE_ACCELERATED = 0x01000000; 其他 Window的left, top, right, bottom主要是由Gravity.apply()方法调用计算出来的。除了和Window的width，height有关外，还和以下几个值有关联x, y, verticalMargin, horizontalMargin。1public static void apply(int gravity, int w, int h, Rect container, int xAdj, int yAdj, Rect outRect) 这里的xAdj和yAdj的换算方式我们可以在WinodwState的applyGravityAndUpdateFrame()中找到。123Gravity.apply(mAttrs.gravity, w, h, containingFrame, (int) (x + mAttrs.horizontalMargin * pw), (int) (y + mAttrs.verticalMargin * ph), mFrame); 一般情况下x, y的值就是WindowManager.LayoutParams的x, y。 Window的操作 Window的操作分为添加，更新和删除。对于Window的操作，我们可以分为WindowManager对Window的操作，以及WindowManagerService对Window的操作。 Window的添加 我们来看看系统的StatusBar的添加流程。12345678private void addStatusBarWindow() &#123; //1.创建StatusBar makeStatusBarView(); mStatusBarWindowManager = Dependency.get(StatusBarWindowManager.class); mRemoteInputController = new RemoteInputController(mHeadsUpManager); //2.调用StatusBarWindowManager的add方法 mStatusBarWindowManager.add(mStatusBarWindow, getStatusBarHeight());&#125; 这个方法做了两件事情 makeStatusBarView()来创建StatusBar； 创建StatusBarWindowManager，然后调用其add()。 再来看看StatusBarWindowManager的add()。1234567891011121314151617181920212223242526public void add(View statusBarView, int barHeight) &#123; //1.构建WindowManager.LayoutParams mLp = new WindowManager.LayoutParams( ViewGroup.LayoutParams.MATCH_PARENT, barHeight, //还记得这个值吗，它是一个SystemWindow类型 WindowManager.LayoutParams.TYPE_STATUS_BAR, WindowManager.LayoutParams.FLAG_NOT_FOCUSABLE | WindowManager.LayoutParams.FLAG_TOUCHABLE_WHEN_WAKING | WindowManager.LayoutParams.FLAG_SPLIT_TOUCH | WindowManager.LayoutParams.FLAG_WATCH_OUTSIDE_TOUCH | WindowManager.LayoutParams.FLAG_DRAWS_SYSTEM_BAR_BACKGROUNDS, PixelFormat.TRANSLUCENT); //下面都是设置WindowManager.LayoutParams的一些参数 mLp.token = new Binder(); mLp.gravity = Gravity.TOP; mLp.softInputMode = WindowManager.LayoutParams.SOFT_INPUT_ADJUST_RESIZE; mLp.setTitle("StatusBar"); mLp.packageName = mContext.getPackageName(); mStatusBarView = statusBarView; mBarHeight = barHeight; //2.调用WindowManager的addView() mWindowManager.addView(mStatusBarView, mLp); mLpChanged = new WindowManager.LayoutParams(); mLpChanged.copyFrom(mLp);&#125; 这个方法做的事情也十分的明确 创建WindowManager.LayoutParams的对象，然后设置一些参数； 调用WindowManager的addView()，将StatusBar和LayoutParams对象传入。 前面我们分析过，WindowManager的addView()方法的实现是在WindowManagerImpl类中，但是这个类的方法实现都是委托给WindowManagerGlobal去做的，所以我们只需要查看WindowManagerGlobal的addView()即可。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public void addView(View view, ViewGroup.LayoutParams params, Display display, Window parentWindow) &#123; //1.校验参数 if (view == null) &#123; throw new IllegalArgumentException("view must not be null"); &#125; if (display == null) &#123; throw new IllegalArgumentException("display must not be null"); &#125; if (!(params instanceof WindowManager.LayoutParams)) &#123; throw new IllegalArgumentException("Params must be WindowManager.LayoutParams"); &#125; final WindowManager.LayoutParams wparams = (WindowManager.LayoutParams) params; if (parentWindow != null) &#123; //2.如果该Window作为一个子Window，就根据父Window来调整WindowManager.LayoutParams parentWindow.adjustLayoutParamsForSubWindow(wparams); &#125; else &#123; final Context context = view.getContext(); if (context != null &amp;&amp; (context.getApplicationInfo().flags &amp; ApplicationInfo.FLAG_HARDWARE_ACCELERATED) != 0) &#123; wparams.flags |= WindowManager.LayoutParams.FLAG_HARDWARE_ACCELERATED; &#125; &#125; ViewRootImpl root; View panelParentView = null; synchronized (mLock) &#123; //... //3.创建ViewRootImpl root = new ViewRootImpl(view.getContext(), display); view.setLayoutParams(wparams); mViews.add(view); mRoots.add(root); mParams.add(wparams); try &#123; //4.调用ViewRootImpl的setView() root.setView(view, wparams, panelParentView); &#125; catch (RuntimeException e) &#123; if (index &gt;= 0) &#123; removeViewLocked(index, true); &#125; throw e; &#125; &#125;&#125; 这个方法做了如下事情 首先会校验传入的参数，包括view，Display，LayoutParams； 然后根据LayoutParams的type值以及对Context设置的flag对LayoutParams做不同的调整； 创建ViewRootImpl对象； 调用ViewRootImpl的setView()。 很明显，我们的调用进一步有转给了ViewRootImpl的setView()，因为setView()中的代码比较多，这里我就只写出我们关心的代码片段。12345678public void setView(View view, WindowManager.LayoutParams attrs, View panelParentView) &#123; //... res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes, getHostVisibility(), mDisplay.getDisplayId(), mAttachInfo.mContentInsets, mAttachInfo.mStableInsets, mAttachInfo.mOutsets, mInputChannel); //...&#125; 可以看到，setView()会调用mWindowSession的addToDisplay()。到这里，WindowManager对Window的添加流程就结束了，后面的流程就通过Session与WindowManagerService进行通信了。 首先mWindowSession是一个IWindowSession的实现类。1final IWindowSession mWindowSession 但是你在framework层搜索不到这个类，因为它是一个aidl文件。在源码库中我们可以找到这个aidl的定义，IWindowSession。这里最终会调用给Session，它是IWindowSession.Stub的实现类，所以我们来看看Session的addToDisplay()。123456public int addToDisplay(IWindow window, int seq, WindowManager.LayoutParams attrs, int viewVisibility, int displayId, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, InputChannel outInputChannel) &#123; return mService.addWindow(this, window, seq, attrs, viewVisibility, displayId, outContentInsets, outStableInsets, outOutsets, outInputChannel);&#125; 这个方法实际上调用了mService的addWindow()，mService就是WindowManagerService的实例。1final WindowManagerService mService; 余生没那么长，不要一味的付出去惯那些得寸进尺的人，请忠于自己，活的像最初的模样。]]></content>
  </entry>
  <entry>
    <title><![CDATA[委托那点事]]></title>
    <url>%2F2018%2F04%2F13%2F%E5%A7%94%E6%89%98%E9%82%A3%E7%82%B9%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[前言 本来这篇文章只是想写写kotlin中的lateinit和by lazy之间的区别，但是发现内容太少了，于是乎就想着顺便将我自己对于委托的理解写出来。 属性 kotlin中的属性，天生就带有setter()/getter()方法，比如我们在某个类中定义一个属性1var name:String = "fxyan" 实际上它和下面的代码是等价的。12345var name:String = "fxyan" get() = field set(value)&#123; field = value &#125; 起初我看到这个的时候很纳闷，这个field是什么，其实field就是代表了这个域本身。我们可以通过AndroidStudio的kotlin bytecode工具将字节码反编译成Java文件来揭露它神秘的面纱。1234567891011121314public final class TestClass &#123; @NotNull private String name = ""; @NotNull public final String getName() &#123; return this.name; &#125; public final void setName(@NotNull String value) &#123; Intrinsics.checkParameterIsNotNull(value, "value"); this.name = value; &#125;&#125; lateinit 我们知道，如果一个类里面的某个属性定义成lateinit之后，在使用的时候如果这个属性没有被初始化，就会抛异常，通过上面对属性的讲解，我们不难推出lateinit关键字做了什么事情。1lateinit var name 我们可以看到一个有趣的现象，lateinit关键字修饰的属性不能够自定义getter()/setter()方法。 其实lateinit关键字无非就是重写了name属性的getter()/setter()方法，在里面做了空值的判断，如果为空则抛出异常。这点我们同样可以通过kotlin bytecode工具来查看。12345678910111213141516171819public final class TestClass &#123; @NotNull public String name; @NotNull public final String getName() &#123; String var10000 = this.name; if (this.name == null) &#123; Intrinsics.throwUninitializedPropertyAccessException("name"); &#125; return var10000; &#125; public final void setName(@NotNull String var1) &#123; Intrinsics.checkParameterIsNotNull(var1, "&lt;set-?&gt;"); this.name = var1; &#125;&#125; 所以我们可以很明显的知道一点，lateinit关键字不能修饰在可空的属性上，因为setter()方法中会校验，如果为空，则会抛出异常。 委托 下面我们来看看kotlin中的委托 类委托 类委托就是类中定义的方法实际上调用另外一个类的对象的方法。12345678910111213interface IBase &#123; fun print()&#125;class IBaseImpl( var name: String) : IBase &#123; override fun print() &#123; print(name) &#125;&#125;class Delegate(iBase: IBase) : IBase by iBase 我们执行下面的代码。1234fun main(args:Array&lt;String&gt;)&#123; val base:IBase = IBaseImpl("fxyan") Delegate(base).print()&#125; 得到了如下的运行结果。 通过运行结果我们大致上也能猜到它是怎么实现的。下面的代码不是通过反编译出来的，但是反编译出来的和下面的差不多。123456789101112131415161718192021222324252627282930313233343536373839public class DelegateTest &#123; public static void main(String[] args) &#123; IBase iBase = new IBaseImpl("fxyan"); new Delegate(iBase).print(); &#125;&#125;interface IBase &#123; void print();&#125;class IBaseImpl implements IBase &#123; private String name; public IBaseImpl(String name) &#123; this.name = name; &#125; @Override public void print() &#123; System.out.print(this.name); &#125;&#125;class Delegate implements IBase &#123; private IBase iBase; public Delegate(IBase iBase) &#123; this.iBase = iBase; &#125; @Override public void print() &#123; iBase.print(); &#125;&#125; 属性委托 定义一个委托属性很简单，只需要通过by关键字，by关键字后面就是属性委托。1var/val &lt;property name&gt;: &lt;Type&gt; by &lt;expression&gt; 首先我们先定义一个委托类Delegate123class Delegate&#123;&#125; 然后定义一个类拥有一个委托属性。123class DelegateProperty&#123; var property:String by Deletage()&#125; 编译器报错了，我们需要给Delegate类增加getValue()，setValue()方法。12345678910class Delegate &#123; fun getValue(d: DelegateProperty, p: KProperty&lt;*&gt;): String &#123; return "" &#125; fun setValue(d: DelegateProperty, p: KProperty&lt;*&gt;, newValue: String) &#123; &#125;&#125; 这个时候编译器仍然在报错Delegate类的getValue()，setValue()方法需要添加operator关键字。1234567891011class Delegate &#123; operator fun getValue(d: DelegateProperty, p: KProperty&lt;*&gt;): String &#123; return "$d 对象的$&#123;p.name&#125;属性的getter()被委托给Delegate对象的getValue()" &#125; operator fun setValue(d: DelegateProperty, p: KProperty&lt;*&gt;, newValue: String) &#123; println("$d 对象的$&#123;p.name&#125;属性的setter()被委托给Delegate对象的setValue()") &#125;&#125; 这样一个完整的委托类就编写完了，下面我们来进行一下测试。1234567fun main(args: Array&lt;String&gt;) &#123; val d = DelegateProperty() println(d.property) d.property = "fxyan" print(d.property)&#125; 可以得到如下的运行结果。通过上面一系列的介绍，我们大致上可以推断出，属性委托实际上就是将属性的getter()/setter()方法委托给委托类的getValue()/setValue()。这点我们通过kotlin bytecode工具得到了证实。12345678910111213141516public final class DelegateProperty &#123; @NotNull private final Delegate property$delegate = new Delegate(); static final KProperty[] $$delegatedProperties = new KProperty[]&#123;(KProperty)Reflection.mutableProperty1(new MutablePropertyReference1Impl(Reflection.getOrCreateKotlinClass(DelegateProperty.class), "property", "getProperty()Ljava/lang/String;"))&#125;; @NotNull public final String getProperty() &#123; return this.property$delegate.getValue(this, $$delegatedProperties[0]); &#125; public final void setProperty(@NotNull String var1) &#123; Intrinsics.checkParameterIsNotNull(var1, "&lt;set-?&gt;"); this.property$delegate.setValue(this, $$delegatedProperties[0], var1); &#125;&#125; lazy属性 lazy实际上是一个扩展函数，接受一个lambda表达式作为参数1public fun &lt;T&gt; lazy(initializer: () -&gt; T): Lazy&lt;T&gt; = SynchronizedLazyImpl(initializer) 同时我们看看SynchronizedLazyImpl()这个类。12345678910111213141516171819202122232425262728293031323334private class SynchronizedLazyImpl&lt;out T&gt;(initializer: () -&gt; T, lock: Any? = null) : Lazy&lt;T&gt;, Serializable &#123; private var initializer: (() -&gt; T)? = initializer @Volatile private var _value: Any? = UNINITIALIZED_VALUE private val lock = lock ?: this override val value: T get() &#123; val _v1 = _value if (_v1 !== UNINITIALIZED_VALUE) &#123; @Suppress("UNCHECKED_CAST") return _v1 as T &#125; return synchronized(lock) &#123; val _v2 = _value if (_v2 !== UNINITIALIZED_VALUE) &#123; @Suppress("UNCHECKED_CAST") (_v2 as T) &#125; else &#123; val typedValue = initializer!!() _value = typedValue initializer = null typedValue &#125; &#125; &#125; override fun isInitialized(): Boolean = _value !== UNINITIALIZED_VALUE override fun toString(): String = if (isInitialized()) value.toString() else "Lazy value not initialized yet." private fun writeReplace(): Any = InitializedLazyImpl(value)&#125; 我猜想，lazy实际上是在使用的时候调用这个类的get()方法，问了证实我的猜想，我在get()方法中断点了，同时我编写了如下几个类。1234567891011fun main(args: Array&lt;String&gt;) &#123; val d = Delegate() println(d.name) println(d.name)&#125;class Delegate &#123; val name: String by lazy &#123; "" &#125;&#125; 当执行val d = Delegate()这句话的时候并没有调用get()方法，当走到第二句话访问name属性的时候，走到了SynchronizedLazyImpl()类的get()方法，从SynchronizedLazyImpl类中，我们知道，第一次访问name属性的时候，value是一个单例类的对象private object UNINITIALIZED_VALUE。在get()方法中会走下面的分支，并使用lazy传入的lambda表达式赋值给value。123456789101112return synchronized(lock) &#123; val _v2 = _value if (_v2 !== UNINITIALIZED_VALUE) &#123; @Suppress("UNCHECKED_CAST") (_v2 as T) &#125; else &#123; val typedValue = initializer!!() _value = typedValue initializer = null typedValue &#125;&#125; 而且我们发现它使用了同步，在多线程中使用lazy也不会发生问题，这一点是值得称赞的。当第二次访问的时候value已经被lambda表达式赋值，所以会走前面的分支。12345val _v1 = _valueif (_v1 !== UNINITIALIZED_VALUE) &#123; @Suppress("UNCHECKED_CAST") return _v1 as T&#125; 至此我们总结下lazy的使用 1. lazy只能修饰val的变量； 2. lazy是线程安全的； 3. 创建对象时，lazy修饰的域不会被初始化，只有第一次访问域的时候会使用lazy后面的lambda表达式进行初始化，之后再访问则直接返回初始化后的值。 Observable属性 这玩意实际上就一观察者，有点类似于Android新出的arch库中的LiveData，但是又没有其功能强大(斜眼笑)。通过Delegate.observable()我们可以创建一个可被观察的属性。123456class ObservableDelegate &#123; var name: String by Delegates.observable("") &#123; _, oldValue, newValue -&gt; println("oldValue is $oldValue, newValue is $newValue") &#125;&#125; 很好理解，每当name属性的值发生变化的时候，都会执行lambda表达式。我们来看看这个方法做了什么事情。1234public inline fun &lt;T&gt; observable(initialValue: T, crossinline onChange: (property: KProperty&lt;*&gt;, oldValue: T, newValue: T) -&gt; Unit): ReadWriteProperty&lt;Any?, T&gt; = object : ObservableProperty&lt;T&gt;(initialValue) &#123; override fun afterChange(property: KProperty&lt;*&gt;, oldValue: T, newValue: T) = onChange(property, oldValue, newValue) &#125; 它接受一个初始值，和一个lambda表达式。然后我们看看ObservableProperty1234567891011121314151617181920public abstract class ObservableProperty&lt;T&gt;(initialValue: T) : ReadWriteProperty&lt;Any?, T&gt; &#123; private var value = initialValue protected open fun beforeChange(property: KProperty&lt;*&gt;, oldValue: T, newValue: T): Boolean = true protected open fun afterChange (property: KProperty&lt;*&gt;, oldValue: T, newValue: T): Unit &#123;&#125; public override fun getValue(thisRef: Any?, property: KProperty&lt;*&gt;): T &#123; return value &#125; public override fun setValue(thisRef: Any?, property: KProperty&lt;*&gt;, value: T) &#123; val oldValue = this.value if (!beforeChange(property, oldValue, value)) &#123; return &#125; this.value = value afterChange(property, oldValue, value) &#125;&#125; 每当给name属性赋值的时候都会调到这个类的setValue()，在里面检测是否发生了变化，如果变化了就会调用afterChange()，而这个方法在Delegate.observable()里面的实现就是直接调用我们传入的lambda表达式。 余生没那么长，不要一味的付出去惯那些得寸进尺的人，请忠于自己，活的像最初的模样~]]></content>
  </entry>
  <entry>
    <title><![CDATA[视图的载体View]]></title>
    <url>%2F2018%2F04%2F10%2F%E8%A7%86%E5%9B%BE%E7%9A%84%E8%BD%BD%E4%BD%93View%2F</url>
    <content type="text"><![CDATA[什么是View View是屏幕上的一块矩形区域，负责绘制和触摸反馈。 View的生命周期 View中有很多回调方法，它们在View的不同生命周期阶段调用，比较常用的方法有下面这些。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * View在xml文件中加载完成的时候调用 */fun onFinishInflate()/** * View关联的Window可视性发生变化的时候调用 */fun onWindowVisibilityChanged(visibility: Int)/** * View的可视性发生变化的时候调用 */fun onVisibilityChanged(visibility: Int)/** * View关联的Window获取焦点或者失去焦点的时候调用 */fun onWindowFocusChanged(hasWindowFocus: Boolean)/** * View获取焦点或者失去焦点的时候调用 */fun onFocusChanged(gainFocus: Boolean, direction: Int, previouslyFocusedRect: Rect?)/** * 测量View及子View的时候调用 */fun onMeasure(widthMeasureSpec: Int, heightMeasureSpec: Int)/** * 当View的大小发生变化的时候调用 */fun onSizeChanged(w: Int, h: Int, oldw: Int, oldh: Int)/** * 布局View及其子View的时候调用 */fun onLayout(changed: Boolean, w: Int, h: Int, oldw: Int, oldh: Int)/** * 绘制View及其子View的时候调用 */fun onDraw(canvas: Canvas)/** * View被关联到Window的时候调用 */fun onAttachedToWindow()/** * View从Window上分离的时候调用 */fun onDetachedFromWindow()/** * 触摸事件发生的时候调用 */fun onTouchEvent(event: MotionEvent?)/** * 物理按键事件发生的时候调用 */fun onKeyDown(keyCode: Int, event: KeyEvent)/** * 物理按键事件发生的时候调用 */fun onKeyUp(keyCode: Int, event: KeyEvent) 和Activity生命周期的关系 为了研究View生命周期和Activity生命周期之间的关系，我编写了一个CustomView类，下面我们就来看看究竟发生了什么有趣的事情。 onCreate 当Activity创建的时候。 onPause 当Activity退到后台的时候。 onRestart 当Activity从后台进入前台的时候。 onDestroy 当Activity销毁的时候。 有什么作用呢 那我们了解View的这些生命周期方法有什么作用呢？下面我就列举下我们经常遇见的问题。 在Activity中获取View的宽高 你是否也曾经在Activity的onCreate，onResume等方法中获取过View的宽高，是否也同样得到了0的结果。从View的生命周期方法调用我们可以看出，在Activity的onResume方法调用的时候，View还没有完成测量，当然获取到的是0了。我们可以在Activity的onWindowFocusChanged()方法中获取View的宽高。1234567override fun onWindowFocusChanged(hasFocus: Boolean) &#123; super.onWindowFocusChanged(hasFocus) if (hasFocus) &#123; Log.d("Amoryan", "$&#123;customView.width&#125;") Log.d("Amoryan", "$&#123;customView.height&#125;") &#125;&#125; 保存和恢复数据 在Activity的生命周期发生变化的时候，View有可能需要作出相应的相应，比如VideoView需要保存和回复当前进度。12345678override fun onWindowVisibilityChanged(visibility: Int)&#123; super.onWindowVisibilityChanged(visibility) if (visibility == View.VISIBLE)&#123; // Activity Resumed &#125; else &#123; //Activity Paused &#125;&#125; 释放资源 有时候我们需要在View从Window上分离的时候释放一些占用内存的资源，比如Bitmap的回收，线程的释放等。1234override fun onDetachedFromWindow()&#123; super.onDetachedFromWindow() //释放资源&#125; 测量流程 View在做测量的时候，measure()方法会被父控件调用，在measure()方法中调用自身的onMeasure()方法进行实际的测量。 View和ViewGroup的测量是有区别的，View的测量会计算自身的尺寸；但是ViewGroup会先遍历子View的，调用子View的measure()方法，最后再计算自身的尺寸。 ViewGroup的测量 我们打开ViewGroup.java的源码文件，找到measureChildren()。123456789101112protected void measureChildren(int widthMeasureSpec, int heightMeasureSpec) &#123; final int size = mChildrenCount; final View[] children = mChildren; //遍历子控件 for (int i = 0; i &lt; size; ++i) &#123; final View child = children[i]; //如果子控件的Visibility属性不是View.GONE，则进行测量 if ((child.mViewFlags &amp; VISIBILITY_MASK) != GONE) &#123; measureChild(child, widthMeasureSpec, heightMeasureSpec); &#125; &#125;&#125; 这个方法做的事情很明确，会遍历子控件，如果子控件的visibility属性不是View.GONE，则调用measureChild()方法。下面我们再来看看measureChild()方法做了什么事情。12345678910111213protected void measureChild(View child, int parentWidthMeasureSpec, int parentHeightMeasureSpec) &#123; //获取子控件的LayoutParams final LayoutParams lp = child.getLayoutParams(); //生成子控件width的MeasureSpec final int childWidthMeasureSpec = getChildMeasureSpec(parentWidthMeasureSpec, mPaddingLeft + mPaddingRight, lp.width); //生成子控件height的MeasureSpec final int childHeightMeasureSpec = getChildMeasureSpec(parentHeightMeasureSpec, mPaddingTop + mPaddingBottom, lp.height); //调用子控件的measure方法进行测量 child.measure(childWidthMeasureSpec, childHeightMeasureSpec);&#125; 从源码可以看出，这个方法做了如下几件事情 1. 会先获取子控件的LayoutParams； 2. 然后根据自身的MeasureSpec，和子控件的LayoutParams计算子控件的MeasureSpec； 3. 最后再调用子控件的measure()方法进行子控件的测量流程。 那么子控件的MeasureSpec是如何生成的呢，下面我们就来看看getChildMeasaureSpec()方法是如何计算的。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static int getChildMeasureSpec(int spec, int padding, int childDimension) &#123; //获取ViewGroup的specMode和specSize int specMode = MeasureSpec.getMode(spec); int specSize = MeasureSpec.getSize(spec); //计算当前能够给予的最大值(父控件给予的值减去ViewGroup的内边距) int size = Math.max(0, specSize - padding); int resultSize = 0; int resultMode = 0; switch (specMode) &#123; //根据ViewGroup的MeasureSpec和View的LayoutParams得到View的MeasureSpec case MeasureSpec.EXACTLY: if (childDimension &gt;= 0) &#123; //子控件的LayoutParams是具体值 resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; &#125; else if (childDimension == LayoutParams.MATCH_PARENT) &#123; //子控件的LayoutParams是MATCH_PARENT resultSize = size; resultMode = MeasureSpec.EXACTLY; &#125; else if (childDimension == LayoutParams.WRAP_CONTENT) &#123; //子控件的LayoutParams是WRAP_CONTENT resultSize = size; resultMode = MeasureSpec.AT_MOST; &#125; break; case MeasureSpec.AT_MOST: if (childDimension &gt;= 0) &#123; resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; &#125; else if (childDimension == LayoutParams.MATCH_PARENT) &#123; resultSize = size; resultMode = MeasureSpec.AT_MOST; &#125; else if (childDimension == LayoutParams.WRAP_CONTENT) &#123; resultSize = size; resultMode = MeasureSpec.AT_MOST; &#125; break; case MeasureSpec.UNSPECIFIED: if (childDimension &gt;= 0) &#123; resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; &#125; else if (childDimension == LayoutParams.MATCH_PARENT) &#123; resultSize = View.sUseZeroUnspecifiedMeasureSpec ? 0 : size; resultMode = MeasureSpec.UNSPECIFIED; &#125; else if (childDimension == LayoutParams.WRAP_CONTENT) &#123; resultSize = View.sUseZeroUnspecifiedMeasureSpec ? 0 : size; resultMode = MeasureSpec.UNSPECIFIED; &#125; break; &#125; //调用MeasureSpec的makeMeasureSpec方法生成子控件的MeasureSpec return MeasureSpec.makeMeasureSpec(resultSize, resultMode);&#125; 这个方法的逻辑也十分明了 1. 得到ViewGroup的specMode和specSize； 2. 获取ViewGroup能够给予子View的最大size； 3. 根据ViewGroup的specMode以及子View的LayoutParams得到子View的specMode和specSize； 4. 通过MeasureSpec的makeMeasureSpec()方法生成子View的MeasureSpec。 最后再来看看makeMeasureSpec()方法。1234567public static int makeMeasureSpec(int size, int mode) &#123; if (sUseBrokenMakeMeasureSpec) &#123; return size + mode; &#125; else &#123; return (size &amp; ~MODE_MASK) | (mode &amp; MODE_MASK); &#125;&#125; 虽然if-else分支计算的值是一样的，但是我还是好奇的看了看sUseBrokenMakeMeasureSpec这个成员变量。发现在View构造的时候会根据版本修改这个值。1sUseBrokenMakeMeasureSpec = targetSdkVersion &lt;= Build.VERSION_CODES.JELLY_BEAN_MR1 只是在API17之前使用旧的MeasureSpec计算方式。 View的测量 看完ViewGroup的测量之后，我们再来看看View的onMeasure()方法。1234protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) &#123; setMeasuredDimension(getDefaultSize(getSuggestedMinimumWidth(), widthMeasureSpec), getDefaultSize(getSuggestedMinimumHeight(), heightMeasureSpec));&#125; 来看看getSuggestedMinimumWidth()和getSuggestedMinimumHeight()方法。1234567protected int getSuggestedMinimumWidth() &#123; return (mBackground == null) ? mMinWidth : max(mMinWidth, mBackground.getMinimumWidth());&#125;protected int getSuggestedMinimumHeight() &#123; return (mBackground == null) ? mMinHeight : max(mMinHeight, mBackground.getMinimumHeight());&#125; 这个方法只是获取最小的宽度和高度。然后我们来看看getDefaultSize()方法。123456789101112131415161718public static int getDefaultSize(int size, int measureSpec) &#123; //先赋值为最小值 int result = size; //获取specMode和specSize int specMode = MeasureSpec.getMode(measureSpec); int specSize = MeasureSpec.getSize(measureSpec); //根据specMode得到最终size，如果MeasureSpec不是UNSPECIFIED，那么最终的size就是ViewGroup能给予的最大size switch (specMode) &#123; case MeasureSpec.UNSPECIFIED: result = size; break; case MeasureSpec.AT_MOST: case MeasureSpec.EXACTLY: result = specSize; break; &#125; return result;&#125; 可以看到这个方法会根据specMode得到View最终的size，但但是，AT_MOST表示LayoutParams是WRAP_CONTENT，从源码可以看出，如果设置为WRAP_CONTENT，最终计算的值实际上并不是包裹内容的，而是父控件能够给予的最大值，所所以，这就说明了为什么我们在自定义View的时候需要重写onMeasure方法给出specMode是AT_MOST的时候的实际size的计算方式了。 布局流程 View的布局流程主要是layout()和onLayout()方法，从ViewRootImpl的performLayout()中会调用根View的layout()方法，然后再逐层的遍历，在layout()中传入View的left, top, right, bottom值，并且调用onLayout()进行实际的布局。对于View，因为没有子控件，所以onLayout()什么也不做。12protected void onLayout(boolean changed, int left, int top, int right, int bottom) &#123;&#125; layout ViewGroup在onLayout()方法中会调用子View的layout()，告诉子View改如何进行布局。我们先来看看layout()方法做了一些什么事情。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public void layout(int l, int t, int r, int b) &#123; if ((mPrivateFlags3 &amp; PFLAG3_MEASURE_NEEDED_BEFORE_LAYOUT) != 0) &#123; onMeasure(mOldWidthMeasureSpec, mOldHeightMeasureSpec); mPrivateFlags3 &amp;= ~PFLAG3_MEASURE_NEEDED_BEFORE_LAYOUT; &#125; //先保存之前的left, top, right, bottom int oldL = mLeft; int oldT = mTop; int oldB = mBottom; int oldR = mRight; //setFrame()确定View的位置，changed表示View的矩阵是否发生了变化 boolean changed = isLayoutModeOptical(mParent) ? setOpticalFrame(l, t, r, b) : setFrame(l, t, r, b); if (changed || (mPrivateFlags &amp; PFLAG_LAYOUT_REQUIRED) == PFLAG_LAYOUT_REQUIRED) &#123; //调用onLayout() onLayout(changed, l, t, r, b); //是否需要绘制滚动条 if (shouldDrawRoundScrollbar()) &#123; if(mRoundScrollbarRenderer == null) &#123; mRoundScrollbarRenderer = new RoundScrollbarRenderer(this); &#125; &#125; else &#123; mRoundScrollbarRenderer = null; &#125; mPrivateFlags &amp;= ~PFLAG_LAYOUT_REQUIRED; //调用onLayoutChangeListener的方法 ListenerInfo li = mListenerInfo; if (li != null &amp;&amp; li.mOnLayoutChangeListeners != null) &#123; ArrayList&lt;OnLayoutChangeListener&gt; listenersCopy = (ArrayList&lt;OnLayoutChangeListener&gt;)li.mOnLayoutChangeListeners.clone(); int numListeners = listenersCopy.size(); for (int i = 0; i &lt; numListeners; ++i) &#123; listenersCopy.get(i).onLayoutChange(this, l, t, r, b, oldL, oldT, oldR, oldB); &#125; &#125; &#125; mPrivateFlags &amp;= ~PFLAG_FORCE_LAYOUT; mPrivateFlags3 |= PFLAG3_IS_LAID_OUT; if ((mPrivateFlags3 &amp; PFLAG3_NOTIFY_AUTOFILL_ENTER_ON_LAYOUT) != 0) &#123; mPrivateFlags3 &amp;= ~PFLAG3_NOTIFY_AUTOFILL_ENTER_ON_LAYOUT; notifyEnterOrExitForAutoFillIfNeeded(true); &#125;&#125; 我们可以看到layout()方法主要做了两件事情 1. 调用setFrame()确定View的四个顶点的位置； 2. 对于ViewGroup，调用onLayout()确定子View的位置。 setFrame12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849protected boolean setFrame(int left, int top, int right, int bottom) &#123; boolean changed = false; //View的矩阵是否发生了变化 if (mLeft != left || mRight != right || mTop != top || mBottom != bottom) &#123; changed = true; int drawn = mPrivateFlags &amp; PFLAG_DRAWN; //View之前的宽高 int oldWidth = mRight - mLeft; int oldHeight = mBottom - mTop; //父控件传入的宽高 int newWidth = right - left; int newHeight = bottom - top; //尺寸是否发生了变化 boolean sizeChanged = (newWidth != oldWidth) || (newHeight != oldHeight); invalidate(sizeChanged); //设置View的4个顶点 mLeft = left; mTop = top; mRight = right; mBottom = bottom; mRenderNode.setLeftTopRightBottom(mLeft, mTop, mRight, mBottom); mPrivateFlags |= PFLAG_HAS_BOUNDS; //如果View的尺寸发生了变化，则调用sizeChange() if (sizeChanged) &#123; sizeChange(newWidth, newHeight, oldWidth, oldHeight); &#125; if ((mViewFlags &amp; VISIBILITY_MASK) == VISIBLE || mGhostView != null) &#123; mPrivateFlags |= PFLAG_DRAWN; invalidate(sizeChanged); invalidateParentCaches(); &#125; mPrivateFlags |= drawn; mBackgroundSizeChanged = true; mDefaultFocusHighlightSizeChanged = true; if (mForegroundInfo != null) &#123; mForegroundInfo.mBoundsChanged = true; &#125; notifySubtreeAccessibilityStateChangedIfNeeded(); &#125; return changed;&#125; FrameLayout的onLayout ViewGroup的onLayout()是一个抽象方法，因为不同的ViewGroup有不同的逻辑，这里我们来看看FrameLayout的onLayout()。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667protected void onLayout(boolean changed, int left, int top, int right, int bottom) &#123; layoutChildren(left, top, right, bottom, false /* no force left gravity */);&#125;void layoutChildren(int left, int top, int right, int bottom, boolean forceLeftGravity) &#123; final int count = getChildCount(); //获取内边距 final int parentLeft = getPaddingLeftWithForeground(); final int parentRight = right - left - getPaddingRightWithForeground(); final int parentTop = getPaddingTopWithForeground(); final int parentBottom = bottom - top - getPaddingBottomWithForeground(); //遍历子控件 for (int i = 0; i &lt; count; i++) &#123; final View child = getChildAt(i); //如果子View的visibility属性不是View.GONE if (child.getVisibility() != GONE) &#123; final LayoutParams lp = (LayoutParams) child.getLayoutParams(); final int width = child.getMeasuredWidth(); final int height = child.getMeasuredHeight(); int childLeft; int childTop; //没有设置gravity，则默认为Gravity.LEFT|Gravity.TOP int gravity = lp.gravity; if (gravity == -1) &#123; gravity = DEFAULT_CHILD_GRAVITY; &#125; final int layoutDirection = getLayoutDirection(); final int absoluteGravity = Gravity.getAbsoluteGravity(gravity, layoutDirection); final int verticalGravity = gravity &amp; Gravity.VERTICAL_GRAVITY_MASK; //根据水平Gravity确定子View的left位置 switch (absoluteGravity &amp; Gravity.HORIZONTAL_GRAVITY_MASK) &#123; case Gravity.CENTER_HORIZONTAL://如果是水平居中 childLeft = parentLeft + (parentRight - parentLeft - width) / 2 + lp.leftMargin - lp.rightMargin; break; case Gravity.RIGHT://如果是靠右 if (!forceLeftGravity) &#123; childLeft = parentRight - width - lp.rightMargin; break; &#125; case Gravity.LEFT: default: childLeft = parentLeft + lp.leftMargin; &#125; //根据垂直Gravity确定View的top位置 switch (verticalGravity) &#123; case Gravity.TOP: childTop = parentTop + lp.topMargin; break; case Gravity.CENTER_VERTICAL://垂直居中 childTop = parentTop + (parentBottom - parentTop - height) / 2 + lp.topMargin - lp.bottomMargin; break; case Gravity.BOTTOM: childTop = parentBottom - height - lp.bottomMargin; break; default: childTop = parentTop + lp.topMargin; &#125; //调用子控件的layout() child.layout(childLeft, childTop, childLeft + width, childTop + height); &#125; &#125;&#125; 这个方法实际上做的事情非常简单 1. 它将gravity分为了水平方向和垂直方向； 2. 通过水平方向的gravity计算出子View的left值； 3. 通过垂直方向的gravity计算出View的top值； 4. 最后再调用子View的layout()方法。]]></content>
  </entry>
  <entry>
    <title><![CDATA[设计模式-单例模式]]></title>
    <url>%2F2018%2F03%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言 在windows系统中，我们可以发现无论我们如何去开启任务管理器，都只能打开一个窗口，因为每个窗口显示的数据，做的功能都是一样的。我们日常的编码中，经常会遇到这样的情况，某个类希望只存在一个实例，这就需要用到 单例模式了 。 饿汉式 饿汉式单例模式比较简单。1234567891011public class Singleton&#123; private static final Singleton instance = Singleton(); private Singleton()&#123;&#125; public static Singleton getInstance()&#123; return instance; &#125;&#125; 从上面的代码可以看出，在类加载的时候就会创建Singleton的对象。 懒汉式 懒汉式单例模式，就是讲对象的实例化放在使用的时候。1234567891011121314public class Singleton&#123; private static Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if (instance == null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 上面这串代码在单线程里面是能够保证只创建一个对象的。但是放到多线程里面就会出现创建多个对象的情况。所以我们如果要创建一个线程安全的单例，则需要加 synchronized 关键字。1234567891011121314public class Singleton&#123; private static Singleton instance; private Singleton()&#123;&#125; public synchronized static Singleton getInstance()&#123; if (instance == null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 但是加上同步之后又出现了另外一个性能问题，如果有很多个线程都在请求这个方法，而且这个方法里面要做很多的初始化操作，就会导致其他线程持续等待等情况，下面不使用方法锁的情况，但是需要加双重校验，因为有可能A线程走完第一层的判断后，CPU执行片给了B线程，然后B线程获取锁创建了对象，如果同步代码块里面不添加一层校验就会导致A线程也会创建对象。123456789101112131415161718public class Singleton &#123; private static Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; holder模式 饿汉式没有办法延时加载，而懒汉式的同步在高并发的情况下又会影响性能。那么有没有另外一种方式能够克服这两者的缺点呢？答案肯定是有的。1234567891011121314public class Singleton &#123; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; return Holder.instance; &#125; private static class Holder &#123; private static final Singleton instance = new Singleton(); &#125;&#125; 由于静态单例对象没有作为Singleton的成员变量直接实例化，因此类加载时不会实例化Singleton，第一次调用getInstance()时将加载内部类Holder，在该内部类中定义了一个static类型的变量instance，此时会首先初始化这个成员变量，由Java虚拟机来保证其线程安全性，确保该成员变量只能初始化一次。由于getInstance()方法没有任何线程锁定，因此其性能不会造成任何影响。 Kotlin下的单例模式饿汉式 kotlin下的饿汉式就有意思了，如下就是一个饿汉式的单例模式。1object Singleton 你没有看错，他就是一个饿汉式，我们通过工具可以看到它对应的java代码如下。1234567891011public final class Singleton &#123; public static final Singleton INSTANCE; private Singleton() &#123; INSTANCE = (Singleton)this; &#125; static &#123; new Singleton(); &#125;&#125; 懒汉式 kotlin里面是没有synchronized关键字的，如果要是用同步方法的形式，则需要使用 @Synchronized 注解。而同步代码块的方式是使用 synchronized() 方法。1234567891011121314151617181920class Singleton private constructor() &#123; companion object &#123; private var instance: Singleton? = null fun getSingleton(): Singleton &#123; if (instance == null) &#123; synchronized(Singleton::class.java) &#123; if (instance == null) &#123; instance = Singleton() &#125; &#125; &#125; return instance!! &#125; &#125;&#125; holder方式 再来看看holder方式如何通过kotlin来实现。123456789101112131415class Singleton private constructor() &#123; companion object &#123; fun getSingleton(): Singleton &#123; return Holder.instance &#125; &#125; private object Holder &#123; val instance: Singleton = Singleton() &#125;&#125; 毒鸡汤 日子还长，别太失望~]]></content>
  </entry>
  <entry>
    <title><![CDATA[关于ViewPager如何一屏多显]]></title>
    <url>%2F2018%2F03%2F05%2F%E5%85%B3%E4%BA%8EViewPager%E5%A6%82%E4%BD%95%E4%B8%80%E5%B1%8F%E5%A4%9A%E6%98%BE%2F</url>
    <content type="text"><![CDATA[前言 最近项目UI图上有个一屏显示多个Pager的控件，想了想直接通过ViewPager来实现。 实现方式 项目地址 getPageWidth 实际上PagerAdapter里面就提供了实现一屏多显的方法12345678910/** * Returns the proportional width of a given page as a percentage of the * ViewPager's measured width from (0.f-1.f] * * @param position The position of the page requested * @return Proportional width for the given page position */public float getPageWidth(int position) &#123; return 1.f;&#125; 这个方法返回的是 每个Pager的宽度 。然而，他的效果并不是我们想要的。来看看下面这段代码的运行效果。123override fun getPageWidth(position: Int): Float &#123; return 0.8f&#125; 它的效果如下所示，可以看到，默认每个pager都是 局左显示 的。 clipChildren 第二种实现方式就是通过控件的 clipChildren 属性，默认这个属性是true，我们需要将其设置为false，表示超出控件的内容范围也要显示出来。12345678910111213141516171819202122&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" xmlns:tools="http://schemas.android.com/tools" android:layout_width="match_parent" android:layout_height="match_parent" android:background="#bbbbbb" android:clipChildren="false" android:gravity="center" android:orientation="vertical" tools:context="com.yanfangxiong.multipagerdemo.MainActivity"&gt; &lt;android.support.v4.view.ViewPager android:id="@+id/viewPager" android:layout_width="match_parent" android:layout_height="180dp" android:layout_marginLeft="20dp" android:layout_marginRight="20dp" android:clipChildren="false" android:overScrollMode="never"/&gt;&lt;/LinearLayout&gt; 这里将ViewPager和LinearLayout的clipChildren属性都设置为了false。然后在java代码中做如下设置。123456//设置预加载的数量是3，这个值默认是1viewPager.offscreenPageLimit = 3//pageMargin设置页面之间的距离val metrics = DisplayMetrics()windowManager.defaultDisplay.getMetrics(metrics)viewPager.pageMargin = TypedValue.applyDimension(TypedValue.COMPLEX_UNIT_DIP, 8f, metrics).toInt() 效果图如下所示。 扩展 感觉好像有点单调哈。我也是这么觉得的，那么我们来加点有趣的东西吧。ViewPager有个PageTransformer接口。1234567891011public interface PageTransformer &#123; /** * Apply a property transformation to the given page. * * @param page Apply the transformation to this page * @param position Position of page relative to the current front-and-center * position of the pager. 0 is front and center. 1 is one full * page position to the right, and -1 is one page position to the left. */ void transformPage(View page, float position);&#125; 这里我就不写研究过程了，position的范围可以分为四段(通用的)，是当前page的左上角相对于ViewPager的位置。 position &lt; -1 -1 &lt;= position &lt; 0 0 &lt;= position &lt; 1 position &gt; 1 ScalePageTransformer 于是乎我写了一个切换尺寸变换的类ScalePageTransformer，如下。123456789101112131415class ScalePageTransformer( private var minScale: Float) : ViewPager.PageTransformer &#123; override fun transformPage(page: View?, position: Float) &#123; val size = when &#123; position &lt; -1 -&gt; minScale position &gt;= -1 &amp;&amp; position &lt; 0 -&gt; minScale + (1 - minScale) * (1 + position) position &lt; 1 -&gt; minScale + (1 - minScale) * (1 - position) else -&gt; minScale &#125; page?.scaleY = size &#125;&#125; 效果图如下，这样就比较有趣了，嗯，我是这么认为的。 RotatePageTransformer 旋转跳跃，我闭着眼~1234567891011121314151617181920212223242526272829303132333435class RotatePageTransformer( private var rotateDegree: Float) : ViewPager.PageTransformer &#123; override fun transformPage(page: View?, position: Float) &#123; if (page == null) return val tPivotX: Float val degree: Float when &#123; position &lt; -1 -&gt; &#123; tPivotX = page.width.toFloat() degree = -rotateDegree &#125; position &gt;= -1 &amp;&amp; position &lt; 0 -&gt; &#123; tPivotX = page.width.toFloat() degree = rotateDegree * position &#125; position &gt;= 0 &amp;&amp; position &lt; 1 -&gt; &#123; tPivotX = 0f degree = rotateDegree * position &#125; else -&gt; &#123; tPivotX = 0f degree = rotateDegree &#125; &#125; page.apply &#123; pivotX = tPivotX pivotY = if (rotateDegree &lt; 0) 0f else page.height.toFloat() rotation = degree &#125; &#125;&#125; 来看看这个旋转变换的效果图。 AlphaPageTransformer 再来个透明度变化的吧。123456789101112131415class AlphaPageTransformer( private var minAlpha: Float) : ViewPager.PageTransformer &#123; override fun transformPage(page: View?, position: Float) &#123; val alpha: Float = when &#123; position &lt; -1 -&gt; minAlpha position &gt;= -1 &amp;&amp; position &lt; 0 -&gt; minAlpha + (1 - minAlpha) * (1 + position) position &gt;= 0 &amp;&amp; position &lt; 1 -&gt; minAlpha + (1 - minAlpha) * (1 - position) else -&gt; minAlpha &#125; page?.alpha = alpha &#125;&#125; 效果图如下 毒鸡汤 日子还长，别太失望~]]></content>
  </entry>
  <entry>
    <title><![CDATA[设计模式-抽象工厂]]></title>
    <url>%2F2018%2F02%2F28%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%2F</url>
    <content type="text"><![CDATA[前言 不管是简单工厂还是工厂方法，每个工厂都只生产一种产品，而在现实生活中是会存在一个工厂生产多种商品的情况的。比如电器工厂，会生产电视机，电冰箱，空调等。 工厂方法 接下来我们使用工厂方法来实现上面的案例。 定义产品 现在有两种产品，冰箱和空调，有两个厂商(美的和海尔)都能够生产这两种产品。1234567891011121314151617interface IRefrigerator&#123;&#125;class HaierRefrigerator : IRefrigerator&#123;&#125;class MeidiRefrigerator : IRefrigerator&#123;&#125;interface IAirConditioner&#123;&#125;class HaierAirConditioner : IAirConditioner&#123;&#125;class MeidiAirConditioner : IAirConditioner&#123;&#125; 定义工厂 因为每个工厂只生产对应的产品，所以我们需要定义两个工厂接口。1234567891011121314151617181920212223interface IRefrigeratorFactory&#123; fun generateRefrigeratorImpl() : IRefrigerator&#125;class HaierRefrigeratorFactory : IRefrigeratorFactory&#123; override fun generateRefrigeratorImpl() : IRefrigerator = HaierRefrigerator()&#125;class MeidiRefrigerator : IRefrigeratorFactory&#123; override fun generateRefrigeratorImpl() : IRefrigerator = MeidiRefrigerator()&#125;interface IAirConditionerFactory&#123; fun generateAirConditionerImpl() : AirConditioner&#125;class HaierAirConditionerFactory : IAirConditionerFactory&#123; override fun generateAirConditionerImpl() : AirConditioner = HaierAirConditioner()&#125;class MeidiAirConditionerFactory : IAirConditionerFactory&#123; override fun generateAirConditionerImpl(): AirConditioner = MeidiAirConditioner()&#125; 生产产品 比如现在要生产美的的冰箱和空调。1234fun main(args : Array&lt;String&gt;)&#123; val refrigerator = MeidiRefrigeratorFactory().generateRefrigeratorImpl() val airConditioner = MeidiAirConditionerFactory().generateAirConditionerImpl()&#125; 思考 如果有N个产品需要生产，那么就需要扩展N个工厂。一旦工厂的数量变多，在调用的时候就很容易遗漏某些产品的生产，而且类的数量也会多很多，导致结构越来越复杂。 抽象工厂 像美的冰箱，美的空调是由相同的公司生产的，我们可以将其归为一个产品族，抽象工厂可以理解为一个工厂生产一个产品族的产品。现在我们来简化上面的代码。12345678910111213141516interface IFactory&#123; fun generateAirConditionerImpl() : IAirConditioner fun generateRefrigeratorImpl() : IRefrigerator&#125;class MeidiFactory : IFactory&#123; override fun generateAirConditionerImpl() : IAirConditioner = MeidiAirConditioner() override fun generateRefrigeratorImpl() : IRefrigerator = MeidiRefrigerator()&#125;class HaierFactory : IFactory&#123; override fun generateAirConditionerImpl() : IAirConditioner = HaierAirConditioner() override fun generateRefrigeratorImpl() : IRefrigerator = HaierRefrigerator()&#125; 生产产品 现在工厂定义好了，我们想要生产美的的产品就可以直接通过一个工厂生产了。12345fun main(args : Array&lt;String&gt;)&#123; val factory : IFactory = MeidiFactory() val airConditioner = factory.generateAirConditionerImpl() val refrigerator = factory.generateRefrigeratorImpl()&#125; 如果某个产品族新增加了某个产品，只需要在抽象工厂中新增加生产该产品的方法就可以了，这样就减少了工厂方法会导致的结构复杂性。 毒鸡汤 日子还长，别太失望~]]></content>
  </entry>
  <entry>
    <title><![CDATA[设计模式-工厂方法]]></title>
    <url>%2F2018%2F02%2F27%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前言 在设计模式－简单工厂文章中介绍的简单工厂，我们发现，如果在此基础上新增加一种图表的展示，那么就得修改静态工厂的generateChartImpl()方法。这无疑违反了开放封闭原则。 修改Factory 于是在简单工厂的基础上我定义了一个IChartFactory的接口，如下。12345interface IChartFactory &#123; fun generateChartImpl(): IChart&#125; 拆分Factory 然后将简单工厂的ChartFactory拆分成下面的类，如下。1234567891011121314151617class PieChartFactory : IChartFactory &#123; override fun generateChartImpl(): IChart = PieChart()&#125;class BarChartFactory : IChartFactory &#123; override fun generateChartImpl(): IChart = BarChart()&#125;class LinearChartFactory : IChartFactory &#123; override fun generateChartImpl(): IChart = LinearChart()&#125; 测试 使用起来只需要通过对应的Factory创建对应的IChart对象就可以了。如下1234fun main(args: Array&lt;String&gt;) &#123; val chartImpl = PieChartFactory().generateChartImpl() chartImpl.display()&#125; 并且我们还发现，如果需要增加一种图表的显示只需要增加IChart的子类和对应的IChartFactory的子类就可以了，而不需要去修改已有的代码，这样就不会违反开闭原则了，而且具有一定的扩展性。 总结 从上面的代码中我们看出，虽然工厂方法能够有很好的扩展性，但是缺点也显而易见，它会导致类的数量越来越多，这样反而会增加系统的复杂度。 毒鸡汤 日子还长，请别失望~]]></content>
  </entry>
  <entry>
    <title><![CDATA[关于京东open-api-sdk的那些坑]]></title>
    <url>%2F2018%2F02%2F27%2F%E5%85%B3%E4%BA%8E%E4%BA%AC%E4%B8%9Copen-api-sdk%E7%9A%84%E9%82%A3%E4%BA%9B%E5%9D%91%2F</url>
    <content type="text"><![CDATA[前言 近来有位朋友让我用java测试下京东的open-api-sdk的调用，对此记录下在测试过程中遇到的那些坑。 ClassNotFound 于是乎我将sdk下载下来集成到项目中，然后按照文档上的内容编写了下面的代码。12345678910111213141516171819202122WareWriteUpdateWareRequest request = new WareWriteUpdateWareRequest();Ware ware = new Ware();ware.setWareId(/*wareId*/);ware.setTitle(/*title*/);ware.setTransportId(/*transportId*/);request.setWare(ware);JdClient client = new DefaultJdClient( "serverUrl", "accessToken", "appKey", "appSecret");try &#123; WareWriteUpdateWareResponse execute = client.execute(request); if (execute.getSuccess()) &#123; System.out.println("请求成功:" + execute.getMsg()); &#125; else &#123; System.out.println("请求失败:" + execute.getMsg()); &#125;&#125; catch (JdException e) &#123; e.printStackTrace();&#125; 似乎是没有毛病的，然后我运行了代码，得到了下面的结果！你没有看错，wtf，找不到类，什么鬼哦。 NoSuchMethod 然后朋友给我发了一篇博客，按照里面的配置，我修改了项目配置为maven项目，然后添加了如下的依赖。1234567891011&lt;dependency&gt; &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt; &lt;artifactId&gt;jackson-core-asl&lt;/artifactId&gt; &lt;version&gt;1.8.11&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt; &lt;artifactId&gt;jackson-mapper-asl&lt;/artifactId&gt; &lt;version&gt;1.8.11&lt;/version&gt;&lt;/dependency&gt; 本以为这样就没有问题了。但是事不如己愿，哈哈，又出现了下面的问题。 解决 看到这个异常我的第一反应就是open-api-sdk中调用的jar包的版本一定比我配置的要高，于是我在mavenrepository里面搜索了最新的jackson-core-asl和jackson-mapper-asl的jar最新版本，并且修改了pom.xml中的version信息。如下所示：1234567891011&lt;dependency&gt; &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt; &lt;artifactId&gt;jackson-core-asl&lt;/artifactId&gt; &lt;version&gt;1.9.13&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt; &lt;artifactId&gt;jackson-mapper-asl&lt;/artifactId&gt; &lt;version&gt;1.9.13&lt;/version&gt;&lt;/dependency&gt; 然后，我再次运行了代码，得到以下结果。 吐槽 说实话，第一次见到sdk里面使用了三方的jar，但是又不在文档里面说明的，也是服气~ 毒鸡汤 日子还长，别太失望～]]></content>
  </entry>
  <entry>
    <title><![CDATA[设计模式-简单工厂]]></title>
    <url>%2F2018%2F02%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%2F</url>
    <content type="text"><![CDATA[前言 之前写代码从来都没有注重设计模式这一块，熟知的并且用的最多的就是单例模式，但是并没有什么卵用，现在项目越来越庞大，每次迭代都要改一堆东西，印象中重复的代码也越来越多，有时候迭代一个版本要改N多个地方的相同代码，如果哪个地方忘了就很蛋疼，但是让我去重构又不知道从何处下手，最近打算将设计模式的东西系统的学习一下，然后将自己写的代码好好的梳理一下。 举个栗子 现在产品经理需要一个图表展示的功能，包括折线图，饼图和柱状图等。于是我写了一个IChart的接口，只有一个display()方法。12345interface IChart &#123; fun display() &#125; 然后编写了几个IChart的子类，如下。1234567891011121314151617181920212223class PieChart : IChart &#123; override fun display() &#123; println("显示饼状图") &#125;&#125;class BarChart : IChart &#123; override fun display() &#123; println("显示柱状图") &#125;&#125;class LinearChart : IChart &#123; override fun display() &#123; println("显示折线图") &#125;&#125; 就这样写好了图表的相关类。然后就是如何根据不同的类型产生不同的类的对象。1234567891011class ChartFactory &#123; fun generateChartImpl(type: String): IChart &#123; return when (type) &#123; "bar" -&gt; BarChart() "linear" -&gt; LinearChart() else -&gt; PieChart() &#125; &#125;&#125; 最后我们来测试一下就可以了。1234fun main(args: Array&lt;String&gt;) &#123; val chartImpl = ChartFactory.generateChartImpl("linear") chartImpl.display()&#125; 运行结果如下所示，这就是简单的工厂模式。 毒鸡汤 日子还长，请别失望～]]></content>
  </entry>
  <entry>
    <title><![CDATA[mac插入U盘的只读问题]]></title>
    <url>%2F2018%2F02%2F21%2Fmac%E6%8F%92%E5%85%A5U%E7%9B%98%E7%9A%84%E5%8F%AA%E8%AF%BB%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[前言 最近帮我舅舅重装系统，因为要将我电脑上的系统镜像复制到U盘中， 然后发现我只能读取U盘里面的文件，而不能进行写入操作。 U盘文件系统格式 想要解决这个问题，首先你得了解U盘的文件系统格式。于是我将U盘插在windows电脑上进行格式化的时候，发现格式化的种类有3种，NTFS ， FAT32 ， exFAT 。那么我们来看看这几种格式的区别。 这里推荐一款免费的软件 Mounty11 。它支持在mac读写NTFS文件系统格式的U盘。 NTFS 它全称New Technology File System(新技术文件系统)。支持LZ77压缩、文件级加密、访问控制。主文件表(MFT)负责存储稳健的属性、位置、访问信息。这种格式在mac如果不使用工具是无法写入文件的，当然它还有一些弊端，比如最大分区，最大文件只支持2TB，（日常够用了）兼容范围不如FAT32，长时间使用会影响U盘寿命。所以这种文件系统格式肯定不是我们要的。 FAT32 它是1997年的Windows 95 OSR2，在第二版系统中首次引入的文件系统格式。 它有很好的兼容性，几乎所有主流系统都能对其格式写入读取 。既然有这么好的兼容性，那我们是不是就直接将U盘格式化为FAT32就可以了。当然不是，这种文件系统虽然有很好的兼容性，却有很多的弊端。 这种文件格式安全无保障，对于单个的文件移动，体积不能超过4G，并且文件名称长度不能超过255个字节 ，所以这不是最好的选择。 exFAT 微软专门为闪存设备设计的文件系统，高容量的SDXC卡默认都是这种格式。文件名最高可达65536个，分区和单个文件支持最大可达到16EB，写读取速度稳定。最主要的是它在mac和windows之间都可以进行读写操作。 解决 最终我并没有选择使用第三方工具在mac进行读写NTFS的U盘，而是将U盘格式化为exFAT的格式，然后再将文件拖放到U盘中，再制作启动盘。 总结 如果只是简单的拖放小文件，你完全可以选择使用FAT32文件系统格式，如果需要拖放大文件则可以考虑使用NTFS或者exFAT，当然不建议使用NTFS，因为它对U盘的使用寿命有影响。 毒鸡汤 日子还长，请别失望~ 祝大家新年快乐]]></content>
  </entry>
  <entry>
    <title><![CDATA[关于迅雷下载BT出现的版权方问题]]></title>
    <url>%2F2018%2F02%2F13%2F%E5%85%B3%E4%BA%8E%E8%BF%85%E9%9B%B7%E4%B8%8B%E8%BD%BDBT%E5%87%BA%E7%8E%B0%E7%9A%84%E7%89%88%E6%9D%83%E6%96%B9%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[前言 2月11号的动车从杭州回家，于是我为了打发在车上的5个多小时时间，2月10号的晚上准备下载一些电影在动车上看。当然是以前看过了的电影，哈哈。于是在google上搜索了速度与激情8和机器之血的BT文件，正当我准备通过迅雷下载这些文件的时候，发现任务的右下角显示 应版权方要求，该资源无法下载 。 WTF！！！ 原因 这个原因是版权方和迅雷交涉后，迅雷通过技术阻止了文件的下载。看到这里忍不住爆了一句粗口，mmp。 解决方案 作为一个程序猿怎么能够被这种问题影响而不看电影，是吧。于是我上google搜索了一些解决方案，找到了一个比较好的方法。 准备工作 首先你得有一个 百度网盘账号 ，因为接下来我们准备通过百度网盘来进行下载这些文件。 获取BT文件的下载地址 获取这个地址的方式比较简单，你只需要在迅雷的下载任务列表选择一个无法下载的文件，然后右键 复制文件下载链接 就可以了。 建立离线下载任务 然后，你就可以登录百度网盘，新建离线下载任务。如下图所示。 然后选择新建链接任务，将在迅雷上复制的链接粘贴上去，建立任务就可以了。 通过百度云盘app进行文件下载 最后你只需要通过百度云盘的app进行文件下载就可以了。 毒鸡汤 日子还长，请别失望~]]></content>
  </entry>
  <entry>
    <title><![CDATA[当Kotlin遇上Parcelable]]></title>
    <url>%2F2018%2F01%2F24%2F%E5%BD%93Kotlin%E9%81%87%E4%B8%8AParcelable%2F</url>
    <content type="text"><![CDATA[由来 因为现在项目里面都是用 kotlin 在编写项目，在跨界面传递数据的时候经常需要传递对象数据，这就需要使用到 对象的序列化 ，就难免和 Parcelable 打交道。 序列化的方式 在Android中，对象的序列化方式是有两种的，一种是Java中的 Serializable ，一种是Android特有的 Parcelable 。既然Google新增加了一种 Parcelable 的方式，那必然有它的道理，我们先来看看两者有啥不可告人的秘密。 Serializable的序列化方式 这种序列化方式给我们的第一印象就是 简洁 。因为你只需要实现 Serializable 接口就可以了。这是一个标识接口，你不需要实现任何方法，Java就会对其进行序列化操作。但但但是，这种序列化的方式使用了 反射，而且在序列化过程中产生很多的临时对象，造成过多的内存消耗 。1234567891011package com.yanfangxiong.kotlinparcelabledemoimport java.io.Serializable/** * @author fxYan */data class Person( var name: String?, var sex: String?) : Serializable Parcelable的序列化方式 这种序列化方式是Android所特有的。而且使用起来 比较复杂 ，我们先来举个栗子。12345678910111213141516171819202122232425262728293031323334353637package com.yanfangxiong.kotlinparcelabledemoimport android.os.Parcelimport android.os.Parcelable/** * @author fxYan */data class Person( var name: String?, var sex: String?) : Parcelable &#123; companion object CREATOR : Parcelable.Creator&lt;Person&gt; &#123; override fun createFromParcel(parcel: Parcel): Person &#123; return Person(parcel) &#125; override fun newArray(size: Int): Array&lt;Person?&gt; &#123; return arrayOfNulls(size) &#125; &#125; constructor(parcel: Parcel) : this( parcel.readString(), parcel.readString()) override fun writeToParcel(parcel: Parcel, flags: Int) &#123; parcel.writeString(name) parcel.writeString(sex) &#125; override fun describeContents(): Int &#123; return 0 &#125;&#125; 详解Parcelable writeToParcel() 通过这个方法你可以将对象的属性都写入到parcel中； describeContents() 这个方法一般情况下默认就好了。关于这个方法，API中是这么描述的，它表示这个Parcelable对象序列化内容的类别。举个栗子，如果你要序列化对象里面包含文件描述符，那么你需要将这个方法修改为返回 CONTENTS_FILE_DESCRIPTOR ； 编写一个类CREATOR继承自 Parcelable.Cretor ，这个接口包含两个方法，createFromParcel()从Parcel容器中值，newArray()这个方法是 供外部类反序列化本类数组使用的 。 从上面的代码我们就可以看出，如何序列化这个对象已经非常清楚的表现出来，根本不需要通过反射来知道来推断类型，所以能够更加高效的序列化对象。 区别与抉择 Serializable实现方式简单，但是比较消耗内存，一般建议在序列化对象保存到文件中的时候使用； Parcelable实现方式较为复杂，但是效率高，消耗内存小，在代码中建议使用这种方式。 问题所在 我们知道，在kotlin中伴生对象只能存在一个 ，一般一些在java中的静态常量我们可能会定义在伴生对象中，但是我们可以看上面的Person的Parcelable实现，系统默认给我们创建的CREATOR对象就直接指定为了伴生对象，这样虽然是没有问题的，但是你定义的一些常量就是属于CREATOR对象了，实际上这是不必要的，所以我们需要一种方式将伴生对象 “释放” 出来。 这里我们就直接上代码了。只需要使用 ＠JVMField 注解就可以解决这个问题。12345678910111213141516companion object &#123; @JvmField val CREATOR: Parcelable.Creator&lt;Person&gt; = object : Parcelable.Creator&lt;Person&gt; &#123; override fun createFromParcel(parcel: Parcel): Person &#123; return Person(parcel) &#125; override fun newArray(size: Int): Array&lt;Person?&gt; &#123; return arrayOfNulls(size) &#125; &#125;&#125; 但但但是，前面说了，使用Parcelable的序列化方式，类里面的方法会增加很多，所以我们打算来优化优化。 首先，kotlin像java 8一样，接口中的方法可以有默认的实现 ，于是我决定写一个KParcelable的接口，如下12345interface KParcelable : Parcelable &#123; override fun describeContents() = 0 override fun writeToParcel(dest: Parcel, flags: Int)&#125; 这样就减少了对象中的 describeContents 方法的实现。然后我们再来优化CREATOR的实现方式。对此我写了下面的函数123456inline fun &lt;reified T&gt; parcelableCreator(crossinline creator: (Parcel) -&gt; T) = object : Parcelable.Creator&lt;T&gt; &#123; override fun createFromParcel(source: Parcel): T = creator(source) override fun newArray(size: Int): Array&lt;T?&gt; = arrayOfNulls(size) &#125; 它接受一个名为 creator 的方法，然后返回一个 Parcelable.Creator 的实现类，这样我的Person类就可以简化为如下的方式。12345678910111213141516171819202122data class Person( var name: String?, var sex: String?) : KParcelable &#123; companion object &#123; @JvmField val CREATOR: Parcelable.Creator&lt;Person&gt; = parcelableCreator(::Person) &#125; constructor(parcel: Parcel) : this( parcel.readString(), parcel.readString()) override fun writeToParcel(dest: Parcel, flags: Int) = with(dest) &#123; writeString(name) writeString(sex) &#125;&#125; 这样看着就舒服多了，哈哈哈。 毒鸡汤 生活不如意时是上帝给你放的长假～]]></content>
  </entry>
  <entry>
    <title><![CDATA[Camera的使用]]></title>
    <url>%2F2018%2F01%2F10%2FCamera%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简介 Android的framework支持通过android.hardware.camera2API或者是过时的Camera来拍摄图片和视频。这篇文章讲解的是Camera的使用，后续会写一篇关于camera2使用的文章。当然，如果你等不及的话可以去看看google博客关于camera2的文章，camera2文章地址，请翻墙查看。 基础 android.hardware.camera2，这个包是控制设备相机的主要API，它可以被用来拍摄图片或者视频当你想构建一个相机app的时候； Camera，这个类也是用来控制设备相机的，但是在API21之后过时了； SurfaceView，这个类用来给用户呈现相机的预览； MediaRecorder，这个类通过相机来录制视频； Intent，如果你的目的仅仅只是简单的拍摄一张图片或者一段视频，你完全可以调用系统的相机让它来完成这些事情，而不需要直接操控系统相机。你可以使用MediaStore.ACTION_IMAGE_CAPTURE来调用系统相机来拍摄图片，或者通过MediaStore.ACTION_VIDEO_CAPTURE来调用系统相机来拍摄视频。 Manifest声明 当你使用Camera API进行开发的时候，你必须确保你的manifest文件中声明了相关的东西。 Camera Permission，当app需要使用设备相机的时候必须声明这个权限 1&lt;uses-permission android:name="android.permission.CAMERA" /&gt; Camera Features，同时得声明使用相机相关的特性，比如。关于camera features的列表，可以查看Features Reference。添加camera features到manifest文件中会导致Google Play防止你的应用安装在那些没有相机或者是不支持相机特性的设备上。如果你的app并不是一定需要camera，你可以在manifest中通过 android:required 来指定。 1&lt;uses-permission android:name="android.hardware.camera" android:required="false" /&gt; Storage Permission，如果应用程序需要将图片或者视频保存到external storage中，还需要声明这个权限； 1&lt;uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" /&gt; Audio Recording Permission，视频录制的过程中还需要录制音频，所以得添加音频录制的权限，音频录制在之前的文章中已经讲过，不懂的可以去 Android录制系列之音频录制进行查阅； 1&lt;uses-permission android:name="android.permission.RECORD_AUDIO" /&gt; Location Permission，如果app需要给图片打上GPS定位信息的tag，你需要申请 ACCESS_FINE_LOCATION 权限，这里需要注意，Android5.0及以上版本需要声明使用设备的GPS； 123&lt;uses-permission android:name ="android.permission.ACCESS_FINE_LOCATION" /&gt;&lt;!-- targetSdkVersion &gt;= 21 的需要添加 --&gt;&lt;uses-feature android:name="android.hardware.location.gps" /&gt; 如何使用访问相机 检索并访问相机，如果你的app没有在manifest文件中声明是否只能安装在有相机的设备上，那么在使用之前，请检测设备是否有相机的硬件支持。1fun hasFeatureCamera(context: Context) = context.packageManager.hasSystemFeature(PackageManager.FEATURE_CAMERA) Android2.3 之后你可以直接通过 Camera.getNumberOfCameras() 方法直接获取到设备上可用的相机数量。如果你非常清楚你app运行在有相机支持的设备上运行时，你可以直接通过 Camera.open() 方法去请求并获取一个Camera的实例，它会 访问设备上的第一个后置摄像头。12345678910fun getCamera(): Camera? &#123; var camera: Camera? = null try &#123; camera = Camera.open() &#125; catch (e: Exception) &#123; //如果不捕获异常，相机在被其他的app使用，或者设备上根本没有相机的时候，就会导致app crash Log.d("Amoryan", "open camera error!") &#125; return camera&#125; Android 2.3 之后你可以通过 Camera.open(int) 访问指定的相机。比如，你可以这么玩。123456789101112131415fun getCameraInfo() &#123; try &#123; for (i in 0 until Camera.getNumberOfCameras()) &#123; val cameraInfo: Camera.CameraInfo = Camera.CameraInfo() Camera.getCameraInfo(i, cameraInfo) if (cameraInfo.facing == Camera.CameraInfo.CAMERA_FACING_BACK) &#123; Log.d("Amoryan", "$i is back facing,orientation is $&#123;cameraInfo.orientation&#125;") &#125; else &#123; Log.d("Amoryan", "$i is front facing,orientation is $&#123;cameraInfo.orientation&#125;") &#125; &#125; &#125; catch (e: Exception) &#123; Log.d("Amoryan", "open camera error!") &#125;&#125; 设置预览 设置预览界面，你可以直接使用SurfaceView，或写一个SurfaceView的子类，然后实现SurfaceHolder.Callback的相关回调，这里我为了方便起见，直接在布局文件中使用SurfaceView了12345678&lt;SurfaceView android:id="@+id/surfaceView" android:layout_width="0dp" android:layout_height="0dp" app:layout_constraintBottom_toBottomOf="parent" app:layout_constraintLeft_toLeftOf="parent" app:layout_constraintRight_toRightOf="parent" app:layout_constraintTop_toTopOf="parent"/&gt; 然后实现相对应的回调接口12345678910111213141516171819class MainActivity : AppCompatActivity(), SurfaceHolder.Callback &#123; override fun onCreate(savedInstanceState: Bundle?) &#123; super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) surfaceView.holder.addCallback(this) &#125; override fun surfaceChanged(holder: SurfaceHolder?, format: Int, width: Int, height: Int) &#123; &#125; override fun surfaceDestroyed(holder: SurfaceHolder?) &#123; &#125; override fun surfaceCreated(holder: SurfaceHolder?) &#123; &#125;&#125; 拍摄图片 通过 takePicture 方法拍摄图片，这里只是简单的将拍摄的图片显示在ImageView上了。1234567891011captureTv.setOnClickListener &#123; camera?.safeTakePicture(null, null, pictureCallback) &#125;private val pictureCallback = Camera.PictureCallback &#123; data, camera -&gt; data?.apply &#123; releaseBitmap() bitmap = BitmapFactory.decodeByteArray(this, 0, this.size) previewImage.setImageBitmap(bitmap) camera?.safeStopPreview() setupCamera() &#125;&#125; 释放Camera Camera是设备上的共享资源，当app获取到Camera的实例后就可以使用它，但是在app不需要Camera或者当界面变得不可见的时候应该正确的释放。举个栗子，当界面变得不可见的时候，如果你没有正确的释放掉资源，就会导致接下来想要访问Camera的app获取失败，而没办法正常工作。12345override fun onPause() &#123; super.onPause() camera?.safeRelease() camera = null&#125; 完整代码 github项目地址1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798package com.yanfangxiong.camerademoimport android.Manifestimport android.content.pm.PackageManagerimport android.graphics.Bitmapimport android.graphics.BitmapFactoryimport android.hardware.Cameraimport android.os.Bundleimport android.support.v4.app.ActivityCompatimport android.support.v7.app.AppCompatActivityimport android.view.SurfaceHolderimport kotlinx.android.synthetic.main.activity_main.*class MainActivity : AppCompatActivity(), SurfaceHolder.Callback &#123; companion object &#123; val REQUEST_CAMERA_PERMISSION = 1 &#125; private var camera: Camera? = null private var bitmap: Bitmap? = null private val pictureCallback = Camera.PictureCallback &#123; data, camera -&gt; data?.apply &#123; releaseBitmap() bitmap = BitmapFactory.decodeByteArray(this, 0, this.size) previewImage.setImageBitmap(bitmap) camera?.safeStopPreview() setupCamera() &#125; &#125; override fun onCreate(savedInstanceState: Bundle?) &#123; super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) surfaceView.holder.addCallback(this) captureTv.setOnClickListener &#123; camera?.safeTakePicture(null, null, pictureCallback) &#125; &#125; private fun checkCameraPermission() &#123; val cameraPermissionStatus = ActivityCompat.checkSelfPermission(this, Manifest.permission.CAMERA) if (cameraPermissionStatus == PackageManager.PERMISSION_GRANTED) &#123; openCamera() &#125; else &#123; ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.CAMERA), REQUEST_CAMERA_PERMISSION) &#125; &#125; override fun onRequestPermissionsResult(requestCode: Int, permissions: Array&lt;out String&gt;, grantResults: IntArray) &#123; super.onRequestPermissionsResult(requestCode, permissions, grantResults) if (requestCode == REQUEST_CAMERA_PERMISSION &amp;&amp; grantResults[0] == PackageManager.PERMISSION_GRANTED) &#123; openCamera() &#125; &#125; private fun openCamera() &#123; camera = safeOpenCamera() setupCamera() &#125; private fun setupCamera() &#123; camera?.apply &#123; setDisplayOrientation(90) setPreviewDisplay(surfaceView.holder) safeStartPreview() &#125; &#125; override fun surfaceCreated(holder: SurfaceHolder?) &#123; if (camera == null) &#123; checkCameraPermission() &#125; else &#123; setupCamera() &#125; &#125; override fun surfaceChanged(holder: SurfaceHolder?, format: Int, width: Int, height: Int) &#123; camera?.safeStopPreview() setupCamera() &#125; override fun surfaceDestroyed(holder: SurfaceHolder?) &#123; &#125; override fun onPause() &#123; super.onPause() camera?.safeRelease() camera = null &#125; private fun releaseBitmap() &#123; bitmap?.recycle() bitmap = null &#125;&#125; 毒鸡汤 人生不如意的时候是上帝给的长假。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Android录制系列之视频录制]]></title>
    <url>%2F2018%2F01%2F09%2FAndroid%E5%BD%95%E5%88%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E8%A7%86%E9%A2%91%E5%BD%95%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言 视频录制使用的是 Camera 和前面讲过的 MediaRecorder。在视频录制的过程中你需要通过 Camera.unlock() 和 Camera.lock() 方法来允许MediaRecorder来访问硬件相机。和使用 Camera 拍摄图片不一样，拍摄视频有 严格的调用顺序。 如何使用 接下来我们就来看看该怎么玩这个玩意。 获取Camera 首先我们得获取到 Camera 。获取相机的方式这里就不在过多的说明了，如果你还是不知道可以去查看我的另外一个文章 Camera的使用。 设置预览界面 这里使用的是SurfaceView，你也可以去查看Camera的使用这篇文章。1234567891011121314151617181920212223242526override fun onCreate(savedInstanceState: Bundle?) &#123; //... surfaceView.holder.addCallback(this) //...&#125;override fun surfaceChanged(holder: SurfaceHolder?, format: Int, width: Int, height: Int) &#123; try &#123; camera?.stopPreview() &#125; catch (e: Exception) &#123; Log.d("Amoryan", "stop preview error!") releaseCamera() &#125; setupCamera()&#125;override fun surfaceDestroyed(holder: SurfaceHolder?) &#123;&#125;override fun surfaceCreated(holder: SurfaceHolder?) &#123; checkCameraPermission()&#125; 开始录制 相机的准备工作做好之后就可以开始录制了。 通过 Camera.unlock() 允许MediaRecorder访问Camera； 通过 MediaRecorder.setCamera() 将MediaRecorder和Camera关联； 设置音频源，通过 MediaRecorder.setAudioSource() 设置音频源为 MediaRecorder.AudioSource.CAMCORDER； 设置视频源，通过 MediaRecorder.setVideoSource() 设置视频源为 MediaRecorder.VideoSource.CAMERA； 设置输出格式和编码方式，不过在 Android2.2 之后你就可以通过 MediaRecorder.setProfile() 方法来设置一个录制视频的配置； 通过 MediaRecorder.setOutputFile() 设置录制视频后保存的文件路径； 通过 MediaRecorder.setPreviewDisplay() 设置预览界面是SurfaceView； 经过以上的配置之后MediaRecorder就已经准备完成，之后你就可以调用 MediaRecorder.prepare() 表示你已经准备完成了； 通过 MediaRecorder.start() 开始录制； 停止录制 当你录制完成之后，也需要正确的释放资源。 通过 MediaRecorder.stop() 停止当前的录制； 通过 MediaRecorder.reset() 重置当前的MediaRecorder配置，以便之后其他app的使用； 通过 MediaRecorder.release() 将MediaRecorder释放； 通过 Camera.lock() 将相机资源锁住，方便其他的app进行使用； 通过 Camera.stopPreview() 停止相机的预览； 通过 Camera.release() 释放相机的资源，方便其他的app进行使用。 小技巧 如果你使用Camera来录制视频，你可以通过 setRecordingHint() 在开启预览前设置为true，这个方法能够减少开始录制的时间。 项目地址 github项目地址 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212package com.yanfangxiong.mediarecorderdemoimport android.Manifestimport android.content.Contextimport android.content.Intentimport android.content.pm.PackageManagerimport android.hardware.Cameraimport android.media.CamcorderProfileimport android.media.MediaRecorderimport android.os.Bundleimport android.os.Environmentimport android.support.v4.app.ActivityCompatimport android.support.v7.app.AppCompatActivityimport android.util.Logimport android.view.SurfaceHolderimport android.view.Viewimport android.widget.Toastimport kotlinx.android.synthetic.main.activity_video_recorder.*import java.io.File/** * @author fxYan */class VideoRecorderActivity : AppCompatActivity(), View.OnClickListener, SurfaceHolder.Callback &#123; companion object &#123; const val REQUEST_CAMERA_PERMISSION = 1 const val REQUEST_RECORD_AUDIO_PERMISSION = 2 fun jumpToActivity(context: Context) &#123; val intent = Intent(context, VideoRecorderActivity::class.java) val queryIntentActivities = context.packageManager.queryIntentActivities(intent, PackageManager.MATCH_DEFAULT_ONLY) if (queryIntentActivities != null &amp;&amp; queryIntentActivities.isNotEmpty()) &#123; context.startActivity(intent) &#125; &#125; &#125; private var camera: Camera? = null private var mediaRecorder: MediaRecorder? = null private var isRecording = false override fun onCreate(savedInstanceState: Bundle?) &#123; super.onCreate(savedInstanceState) setContentView(R.layout.activity_video_recorder) surfaceView.holder.addCallback(this) controlIv.setOnClickListener(this) &#125; override fun onClick(v: View?) &#123; when (v?.id) &#123; R.id.controlIv -&gt; &#123; if (camera == null) &#123; return &#125; if (isRecording) &#123; //如果在录制中 try &#123; mediaRecorder?.stop() &#125; catch (e: Exception) &#123; Log.d("Amoryan", "stop media recorder error!") &#125; releaseMediaRecorder() &#125; else &#123; //开启录制 checkRecordAudioPermission() &#125; &#125; &#125; &#125; override fun surfaceChanged(holder: SurfaceHolder?, format: Int, width: Int, height: Int) &#123; try &#123; camera?.stopPreview() &#125; catch (e: Exception) &#123; Log.d("Amoryan", "stop preview error!") releaseCamera() &#125; setupCamera() &#125; override fun surfaceDestroyed(holder: SurfaceHolder?) &#123; &#125; override fun surfaceCreated(holder: SurfaceHolder?) &#123; checkCameraPermission() &#125; private fun checkCameraPermission() &#123; when &#123; ActivityCompat.checkSelfPermission(this, Manifest.permission.CAMERA) == PackageManager.PERMISSION_GRANTED -&gt; &#123; openCamera() &#125; else -&gt; &#123; ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.CAMERA), REQUEST_CAMERA_PERMISSION) &#125; &#125; &#125; private fun checkRecordAudioPermission() &#123; when &#123; ActivityCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) == PackageManager.PERMISSION_GRANTED -&gt; &#123; startRecord() &#125; else -&gt; &#123; ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.RECORD_AUDIO), REQUEST_RECORD_AUDIO_PERMISSION) &#125; &#125; &#125; private fun openCamera() &#123; try &#123; camera = Camera.open() setupCamera() &#125; catch (e: Exception) &#123; Log.d("Amoryan", "open camera error!") &#125; &#125; private fun setupCamera() &#123; try &#123; camera?.apply &#123; parameters.focusMode = Camera.Parameters.FOCUS_MODE_AUTO setPreviewDisplay(surfaceView.holder) setDisplayOrientation(90) startPreview() autoFocus(null) &#125; &#125; catch (e: Exception) &#123; Log.d("Amoryan", "set up camera error!") releaseCamera() &#125; &#125; private fun releaseCamera() &#123; try &#123; camera?.stopPreview() camera?.release() &#125; catch (e: Exception) &#123; Log.d("Amoryan", "release camera error!") &#125; camera = null &#125; private fun startRecord() &#123; try &#123; mediaRecorder = MediaRecorder() mediaRecorder?.apply &#123; reset() camera?.unlock() setCamera(camera) setAudioSource(MediaRecorder.AudioSource.CAMCORDER) setVideoSource(MediaRecorder.VideoSource.CAMERA) setProfile(CamcorderProfile.get(CamcorderProfile.QUALITY_1080P)) val file = File(getExternalFilesDir(Environment.DIRECTORY_MOVIES), "videoRecorder.mp4") setOutputFile(file.absolutePath) setPreviewDisplay(surfaceView.holder.surface) prepare() start() isRecording = true Toast.makeText(this@VideoRecorderActivity, "开启录制...", Toast.LENGTH_SHORT).show() &#125; &#125; catch (e: Exception) &#123; Log.d("Amoryan", "mediaRecorder error!") releaseMediaRecorder() &#125; &#125; private fun releaseMediaRecorder() &#123; try &#123; mediaRecorder?.apply &#123; reset() release() &#125; &#125; catch (e: Exception) &#123; Log.d("Amoryan", "release media recorder error!") &#125; camera?.lock() mediaRecorder = null isRecording = false &#125; override fun onRequestPermissionsResult(requestCode: Int, permissions: Array&lt;out String&gt;, grantResults: IntArray) &#123; super.onRequestPermissionsResult(requestCode, permissions, grantResults) if (requestCode == REQUEST_CAMERA_PERMISSION &amp;&amp; grantResults[0] == PackageManager.PERMISSION_GRANTED) &#123; openCamera() &#125; else if (requestCode == REQUEST_RECORD_AUDIO_PERMISSION &amp;&amp; grantResults[0] == PackageManager.PERMISSION_GRANTED) &#123; startRecord() &#125; &#125; override fun onPause() &#123; super.onPause() releaseMediaRecorder() releaseCamera() &#125;&#125; 毒鸡汤 走过一些弯路，也好过原地踏步～]]></content>
  </entry>
  <entry>
    <title><![CDATA[Android录制系列之音频录制]]></title>
    <url>%2F2018%2F01%2F06%2FAndroid%E5%BD%95%E5%88%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E9%9F%B3%E9%A2%91%E5%BD%95%E5%88%B6%2F</url>
    <content type="text"><![CDATA[简介 Android的多媒体框架包含并支持录制和解码多种多样的音视频格式。如果设备支持，你可以使用MediaRecorder来进行这些操作。( Android模拟器无法录制音频 ) MediaRecorder的使用权限 如果你想进行音频录制，你必须添加RECORDER_AUDIO的权限，这是一个 危险权限 ，如果你不知道如何请求权限，你可以查看之前的一篇文章 Android运行时权限的处理。1&lt;uses-permission android:name="android.permission.RECORD_AUDIO" /&gt; 配置MediaRecorder 配置一个MediaRecorder你只需要简单的几步就可以了。 首先，我们得创建一个 MediaRecorder 的实例对象； 1val mediaRecorder = MediaRecorder() 通过 setAudioSource() 方法设置音频源，音频源的取值你可以直接查看 MediaRecorder.AudioSource，一般情况下我们会选择 MIC 也就是麦克风作为音频源； 1mediaRecorder.setAudioSource(MediaRecorder.AudioSource.MIC) 通过 setOutputFormat() 方法设置输出格式，输出格式的取值你可以直接查看 MediaRecorder.OutputFormat； 1mediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP) 通过 setAudioEncoder() 方法设置音频解码方式，解码方式的取值你可以直接查看 MediaRecorder.AudioEncoder 1mediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC) 通过 setOutputFile() 方法设置保存文件的路径， 12val file = File(getExternalFilesDir(Environment.DIRECTORY_MOVIES), "audioRecorder.3gp")mediaRecorder.setOutputFile(file.absolutePath) 完成初始化配置后，你就可以调用 prepare()方法 ；然后调用 start() 你就可以开始录制了。 12mediaRecorder.prepare()mediaRecorder.start() 值得注意的 大部分(包括DEFAULT)的音频源 都会对音频信号做处理 ，如果你想录制原始的音频，你可以选择MediaRecorder.AudioSource.UNPROCESSED(当然你也可以选择AudioRecorder这个更接近底层的类，后面会找时间写一篇关于AudioRecorder录制的文章)。 有些设备是不支持录制未处理的音频，你可以通过下面的这种方式来获取设备是否支持录制原始音频。1234567val audioManager: AudioManager? = getSystemService(Context.AUDIO_SERVICE) as? AudioManagervar isSupportedRawAudioInput = "false"audioManager?.apply &#123; if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.JELLY_BEAN_MR1) &#123; isSupportedRawAudioInput = getProperty("android.media.property.SUPPORT_AUDIO_SOURCE_UNPROCESSED") &#125;&#125; 嗯~what，我相信你也发现了，这个方法是 API 17 才出现的。目前公司项目的最低支持是16，所以得找一种方式在 API 16 上也能够获取到这个属性。结合之前的一些经验，我最初的想法是先看看API16的AudioManager的源码，希望这个方法是本身存在的，只是被隐藏了，这样我就可以直接通过反射的方式去调用，但是事实不是如此，在API16中，AudioManager确实是没有getProperty()方法 ；于是，本着学习的态度，我翻看了更高版本的AudioManager的源码，发现它的调用链是这个样子的。123if (PROPERTY_SUPPORT_AUDIO_SOURCE_UNPROCESSED.equals(key)) &#123; return String.valueOf(getContext().getResources().getBoolean(com.android.internal.R.bool.config_supportAudioSourceUnprocessed));&#125; 仿佛抓到一颗救命稻草，于是我想我直接在代码里面获取这个属性不就好了，这里给你萌看一张图吧，上面代码是这个样子的，找不到com.android.interal.R。 然后，我去google上搜索了关于如何引用这个资源文件，首先，通过反射是肯定可以获取到的，但是google会有一个警告告诉你 通过反射的方式访问内部APIs可能会在某些设备上不支持 ，所以还是用下面这个安全的方式吧。1resources.getBoolean(Resources.getSystem().getIdentifier("config_supportAudioSourceUnprocessed", "bool", "android")) 嗯哼，高兴的太早了，于是乎我就开启了API16的模拟器运行了起来，当走到这一行代码的时候，就出现了下面的结果，好吧，这个属性的判断似乎只能是API17才能用，所以还是用官方推荐的那种方式吧。 如果不支持的情况下，你可以尝试使用 MediaRecorder.AudioSource.VOICE_RECOGNITION 。它不使用AGC(Auto Gain Control，自动增益控制，当信号源较强的时候，使其增益自动降低；当信号源较弱的时候，使其增益自动增高)，并且不会做降噪处理。当然，即使设备不支持UNPROCESSED，你仍旧可以设置为这个，只是这样你就不知道音频信号有没有被处理了。 MediaRecorder的状态 这里直接使用官方的状态图了，如下 事件监听 MediaRecorder提供了两个监听事件的接口，一个是MediaRecorder.OnInfoListener，另一个是MediaRecorder.OnErrorListener。 OnInfoListener 可以用来监听MediaRecorder的一些状态，比如最大录制事件到了等等。12345678910111213141516mediaRecorder.setOnInfoListener&#123; _,what,_-&gt; when(what)&#123; MediaRecorder.MEDIA_RECORDER_INFO_MAX_DURATION_REACHED-&gt;&#123; //这个枚举值对应mediaRecorder.setMaxDuration()，当设置的最大录制时间到了后，会回调这个 &#125; MediaRecorder.MEDIA_RECORDER_INFO_MAX_FILESIZE_APPROACHING-&gt;&#123; //这个枚举值对应setMaxFileSize()，当录制文件大小快接近最大值的时候会回调这个，这个是API26新增 &#125; MediaRecorder.MEDIA_RECORDER_INFO_MAX_FILESIZE_REACHED-&gt;&#123; //当录制文件大小达到最大文件大小的时候会回调这个 &#125; MediaRecorder.MEDIA_RECORDER_INFO_NEXT_OUTPUT_FILE_STARTED-&gt;&#123; //这个方法对应的是setNextOutputFile()，当录制视频超过指定大小后保存到next文件中的时候就会回调这个值，这个是API26新增 &#125; &#125;&#125; OnErrorListener 监听Error信息，12345678mediaRecorder.setOnErrorListener&#123;_, what, _ -&gt; when(what)&#123; MediaRecorder.MEDIA_RECORDER_ERROR_UNKNOWN-&gt;&#123; &#125; MediaRecorder.MEDIA_ERROR_SERVER_DIED-&gt;&#123; &#125; &#125;&#125; 举个栗子 布局文件就不细说了，只有一个录制按钮和一个停止按钮。我们来看看Activity中核心的的代码。 请求权限123456789101112131415161718192021222324252627282930override fun onClick(v: View?) &#123; when (v?.id) &#123; R.id.startRecorderTv -&gt; checkRecordAudioPermission() R.id.stopRecorderTv -&gt; stopRecorder() &#125;&#125;private fun checkRecordAudioPermission() &#123; val hasRecordAudioPermission = ActivityCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) when &#123; hasRecordAudioPermission == PackageManager.PERMISSION_GRANTED -&gt; startRecorder() ActivityCompat.shouldShowRequestPermissionRationale(this, Manifest.permission.RECORD_AUDIO) -&gt; AlertDialog.Builder(this) .setCancelable(false) .setMessage("请求音频录制权限，否则无法录制音频") .setNegativeButton("取消") &#123; _, _ -&gt; &#125; .setPositiveButton("确定") &#123; _, _ -&gt; requestRecordAudioPermission() &#125; .show() else -&gt; requestRecordAudioPermission() &#125;&#125;private fun requestRecordAudioPermission() &#123; ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.RECORD_AUDIO), REQUEST_RECORD_AUDIO_PERMISSION)&#125;override fun onRequestPermissionsResult(requestCode: Int, permissions: Array&lt;out String&gt;, grantResults: IntArray) &#123; if (requestCode == REQUEST_RECORD_AUDIO_PERMISSION &amp;&amp; grantResults[0] == PackageManager.PERMISSION_GRANTED) &#123; startRecorder() &#125;&#125; 开始录制123456789101112131415161718private fun startRecorder() &#123; if (!isRecording) &#123; mediaRecorder = MediaRecorder() mediaRecorder?.apply &#123; setAudioSource(MediaRecorder.AudioSource.MIC) setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP) setAudioEncoder(MediaRecorder.AudioEncoder.AAC) val file = File(getExternalFilesDir(Environment.DIRECTORY_MOVIES), AUDIO_RECORDER_FILE_NAME) setOutputFile(file.absolutePath) try &#123; prepare() &#125; catch (e: Exception) &#123; &#125; start() isRecording = true &#125; &#125;&#125; 停止录制12345678910private fun stopRecorder() &#123; if (isRecording) &#123; mediaRecorder?.apply&#123; stop() release() &#125; isRecording = false mediaRecorder = null &#125;&#125; 项目地址github地址 官方文档 官网的Guide也是给出了MediaRecorder的详细使用，以及在 API 26 中新增的 MediaMuxer to record multiple channels 。 毒鸡汤 将来的你一定会感谢现在拼命的自己～]]></content>
  </entry>
  <entry>
    <title><![CDATA[选择列表请对CheckBox说No]]></title>
    <url>%2F2018%2F01%2F05%2F%E9%80%89%E6%8B%A9%E5%88%97%E8%A1%A8%E8%AF%B7%E5%AF%B9CheckBox%E8%AF%B4No%2F</url>
    <content type="text"><![CDATA[由来 我记得刚学习Android的时候，有个需求是这个样子的，做一个单选或者多选的选择列表。然后那个时候懂得不是很多，就用CheckBox去做。做来做去，发现很多的坑，比如控件会被重用，导致选中的状态也被重用了。后来随着自己接触的东西变多，想到用另外一种方式来实现选择列表，但是这并不是我写这篇文章的原因。主要原因是最近在看同事写的代码(我们是两个人在开发)的时候，发现选择列表还是用的CheckBox，我觉得有必要分享下自己的实现方式，当然如果你们有什么好的建议记得及时告诉我。 实现方式 接下来我就说一下我是如何实现选择列表的(欢迎大家来吐槽)。先来一张效果图，比较简单。github项目地址 level-list 官方文档的介绍请戳这里。它可以通过一些值来管理一系列的图片，然后通过level属性修改这些值后就会显示对应的图片。 举个栗子 因为是选择列表，那必然会有两张图片，一张是未选中的，我们记为ic_select_off，一张是选中的，我们记为ic_select_on。然后我们可以在drawable文件夹下新建一个level_list_common_select.xml的资源文件。具体代码如下123456789101112&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;level-list xmlns:android="http://schemas.android.com/apk/res/android"&gt; &lt;item android:drawable="@mipmap/ic_select_off" android:maxLevel="0"/&gt; &lt;item android:drawable="@mipmap/ic_select_on" android:maxLevel="1"/&gt;&lt;/level-list&gt; 布局文件 接下来，我们说说布局文件，我们不会用到CheckBox，这里我们用ImageView来顶替CheckBox，大致如下所示。123456789101112131415161718192021222324252627282930&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:layout_width="match_parent" android:layout_height="50dp" android:background="#ffffff" android:orientation="horizontal" android:paddingLeft="12dp" android:paddingRight="12dp"&gt; &lt;ImageView android:id="@+id/selectStatusIv" android:layout_width="wrap_content" android:layout_height="wrap_content" android:layout_gravity="center_vertical" android:src="@drawable/level_list_common_select"/&gt; &lt;TextView android:id="@+id/selectTitleTv" android:layout_width="match_parent" android:layout_height="match_parent" android:ellipsize="end" android:gravity="center_vertical" android:lines="1" android:paddingLeft="12dp" android:singleLine="true" android:textColor="#333333" android:textSize="16sp"/&gt;&lt;/LinearLayout&gt; 这里并没有太多花里胡哨的东西，只是用一个ImageView替换掉了CheckBox。 核心逻辑 你需要找一个能够唯一标记这个选项的字段，比如id，这个字段一般都会有。然后我们的适配器里面会存放一个selectId，在渲染View的方法中校验当前项的id是否和选中的id是一致的，如果一致，则将level设置为1，否则设置为0就可以了。12345678910111213141516171819202122232425262728package com.yanfangxiong.levellistimplementselectlistimport android.content.Contextimport android.view.Viewimport com.guoshujinfu.mobile.gscloud.migration.adapter.CommonListAdapterimport kotlinx.android.synthetic.main.listitem_select.view.*/** * @author fxYan */class SelectListAdapter( context: Context, resId: Int, data: List&lt;SelectBean&gt;) : CommonListAdapter&lt;SelectBean&gt;(context, resId, data) &#123; private var selectId: Long? = null fun setSelected(selectId: Long) &#123; this.selectId = selectId &#125; override fun bindData(view: View, position: Int, data: SelectBean) &#123; view.selectStatusIv.drawable.level = if (data.id == selectId) 1 else 0 view.selectTitleTv.text = data.title &#125;&#125; 这里用的kotlin编写的，CommonListAdapter可以去看之前写的用kotlin封装的适配器。这样这个单选的逻辑就写完了。嗯，就是这么简单，不用关心CheckBox重用导致的状态复用问题。 总结 如果我不去思考该如何简化，那我永远都只是死板的用CheckBox来完成选择列表。所以，要学会思考，只根据产品给的需求完成相应的任务那是一个初级程序猿做的事情。日子还长，别太失望~]]></content>
  </entry>
  <entry>
    <title><![CDATA[kotlin之集合的惰性操作]]></title>
    <url>%2F2017%2F12%2F16%2Fkotlin%E4%B9%8B%E9%9B%86%E5%90%88%E7%9A%84%E6%83%B0%E6%80%A7%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言 最近在学习kotlin的时候，发现了一个 骚操作 ，它叫集合的惰性操作。什么，你问我为什么称它 骚 ？我也不知道，反正脑海中就浮现了这么个词语！可能是贫穷限制了我的想象力！ 举个栗子 比如有这么一个场景，你是一家猎头公司的人员(别问我为什么是猎头，因为我看完猎场了)。然后你需要从一批人员中筛选符合条件的人选。123456data class Person(var name: String, var age: Int = 0, var workYear: Int = 0, var mail: String?)val persons = listOf(Person("Tom", 20, 2, "Tom@mail.com"), Person("Mike", 22, 3, "Mike@mail.com"), Person("Jerry", 21, 3, "Jerry@mail.com"), Person("Atom", 22, 2, "Atom@mail.com")) 你需要筛选出工作年限不小于３年的人的联系方式，然后联系他们准备进行面试。1234567println(persons.filter &#123; println("filter operate!") it.workYear &gt;= 3&#125;.map &#123; println("map operate!") it.mail&#125;) 上面的代码会输出如下的结果，这样你就成功的筛选出了Mike和Jerry。 如果你不了解 filter 和 map 两个扩展函数，可以查看源码中的这两个扩展函数是怎么写的 _Collections.kt。从输出结果上我们也可以看出它的流程是这样的，先对persons集合的每一个元素调用filter，然后会产生一个新的集合，然后对新的集合调用map，这样就得到了所有符合条件人员的联系方式。 Sequence序列 上面已经说明了这段代码的执行流程，倘若你要从你们成百上千万的人才库中筛选这些人员，执行效率是不是就非常低下了，而且如果变换操作过多的时候，你会创建很多个临时的集合。这时候，惰性操作就出来的，解释排后，代码先行！12345678910println("result is:" + persons.asSequence() .filter &#123; println("filter operate!") it.workYear &gt;= 3 &#125; .map &#123; println("map operate!") it.mail &#125; .toList()) 上面这段代码输出结果是这样的。 我们很容易就能够看出，它会对persons中的每一个元素先调用filter，如果满足条件再调用map；它是一个元素操作完之后再对另外一个元素做操作。我们再来看看一个神奇的现象，先把toList()删除掉，它会输出这个结果。 很神奇吧，它没有对persons中的元素做任何操作，只是单纯的返回了一个TransformingSequence的对象。 序列的操作 我们可以将序列的操作分为两类，intermediate operation 和 terminal operation 。看下面这张图你就明白了。 intermediate operation是惰性的。从上面的代码我们可以看出，只有当terminal operation执行的时候，intermediate operation才会执行。 总结 序列是对集合的每一个元素做所有的操作，而没有使用序列的时候是对一个集合做完某个操作后再对新的集合做后续操作； 序列只有在terminal operation调用的时候才会执行所有的操作。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Android运行时权限的处理]]></title>
    <url>%2F2017%2F12%2F14%2FAndroid%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9D%83%E9%99%90%E7%9A%84%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[前言 Android运行时权限机制 是在 API 23(Android M) 中提出来的，今年已经发布了API 26、27(Android O)，已经过去几个版本了，但是为什么我要写这个东西。首先，以前在开发的过程中，为了图方便，只是 简单的将build.gradle 中的 targetSdkVersion 设置为 22，所以基本上没有太多的和运行时权限打交道，但是随着这个人啊越来越老( 帅 )，觉得不应该躲避新的东西，而应该正视它，不然自己的技术永远都不会得到提高。所以最近打算将targetSdkVersion逐渐升上去，玩点新东西。 这是什么 在 API 23 以前，如果用户在安装应用后，默认是同意了应用所需要的权限(但是Android厂商众多，也有很多手机会弹窗提示用户是否授予权限)。而运行时权限的加入，简化了应用的安装过程，因为用户在安装的过程中不需要授予权限，而在应用的运行过程中，可以选择是否授予应用相关的权限。举个简单的例子，用户可以为相机提供相机访问权限，但是不提供位置的访问权限。 权限分类 系统权限分为两类：Normal Permission 和 Dangerous Permission” ，前者 不会直接给用户的隐私带来风险 ，所以如果你的app在Manifest文件中列出了应用需要这些权限，系统会自动赋予该权限。后者 会赋予app访问用户隐私数据的权限，是有可能对用户隐私造成风险的 。所以如果你的app在Manifest文件中列出了这些权限，则这些 权限的授予是由用户决定的 。 如何使用 接下来，我们就要开始来玩运行时权限了。 检测权限 如果你的app需要 Dangerous Permission ，则每次执行需要这一权限操作的时候都应该检测自己是否具有该权限，因为用户始终可以自由的调用此权限。检测的方法有两种，但是源码是一样的，只是穿了个不同的外套而已。12345678int cameraPermissionState = ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA);cameraPermissionState = ActivityCompat.checkSelfPermission(this, Manifest.permission.CAMERA);//判断权限是否授予if (cameraPermissionState == PermissionChecker.PERMISSION_GRANTED) &#123; //...已经具有该权限，你可以做一些羞羞的事情了&#125; else &#123; //...没有权限，这个时候你需要获取该权限了&#125; 请求权限 Android提供了多种权限请求方式，调用这些方法将会显示一个无法自定义的Android对话框。你可以调用 requestPermission() 方法来请求你所需要的权限。1ActivityCompat.requestPermissions(this, new String[]&#123;Manifest.permission.CAMERA&#125;, REQUEST_CAMERA_PERMISSION); 处理权限请求响应 当用户响应权限弹窗的时候，系统将回调 onRequestPermissionsResult() 方法，告知用户的响应情况。所以我们必须重写这个方法，如下。1234567if (requestCode == REQUEST_CAMERA_PERMISSION) &#123; if (grantResults.length == 1 &amp;&amp; grantResults[0] == PermissionChecker.PERMISSION_GRANTED) &#123; //...用户允许相机访问权限，你可以做一些羞羞的事情了 &#125; else &#123; //...用户拒绝了相机访问权限 &#125;&#125; 注意，系统显示的权限弹窗是对于 权限组 而言的，它不会列出app需要的具体权限。比如，app想要READ_CONTACTS权限，系统会告诉用户app想要访问设备的联系人。同时，用户只需要为每个权限组授予一次权限，如果应用请求该权限组中的任何其他权限，系统将自动授予应用这些权限 。具体过程是你在 requestPermissions() 方法之后，系统会自动回调 onRequestPermissionsResult() 方法，并传入 PERMISSION_GRANTED 。 权限组 你可能会询问权限组又是什么东西，是的，我也问过自己。所有的Dangerous Permission都属于权限组。 如果应用请求其清单中列出的危险权限，而应用目前在权限组中没有任何权限，则系统会向用户显示一个对话框，描述应用要访问的权限组。对话框不描述该组内的具体权限。例如，如果应用请求 READ_CONTACTS 权限，系统对话框只说明该应用需要访问设备的联系信息。如果用户批准，系统将向应用授予其请求的权限。 如果应用请求其清单中列出的危险权限，而应用在同一权限组中已有另一项危险权限，则系统会立即授予该权限，而无需与用户进行任何交互。例如，如果某应用已经请求并且被授予了 READ_CONTACTS 权限，然后它又请求 WRITE_CONTACTS，系统将立即授予该权限。 任何权限都可属于一个权限组，包括正常权限和应用定义的权限。但权限组仅当权限危险时才影响用户体验。可以忽略正常权限的权限组。任何权限都可属于一个权限组，包括正常权限和应用定义的权限。但权限组仅当权限危险时才影响用户体验。可以忽略正常权限的权限组。您可以查看官方文档 。 我就知道你懒，给你截图了。如果你想看官方文档，就看看下面的图。 告诉用户你为什么需要这个权限 当用户选择单次拒绝权限的时候，你再次请求该权限，可以告知用户为什么你的app需要这些权限，以便让用户理解这些权限的作用。系统也提供了对应的方法 ActivityCompat.shouldShowRequestPermissionRationale() 。如果app之前请求过此权限，并且用户拒绝了请求这个方法就会返回true。如果app之前请求过此权限，并且用户勾选了”禁止后不再询问”，这个方法将返回false。 一次完整的权限请求 动态权限的相关其实并没有多少，来看看一段完整的请求CAMERA权限的示例。123456789101112131415161718192021222324252627282930313233343536private void checkPermission()&#123; if (ActivityCompat.checkSelfPermission(this, Manifest.permission.CAMERA) == PermissionChecker.PERMISSION_GRANTED) &#123; //...开始做羞羞的事情 &#125; else &#123; requestCameraPermission(); &#125;&#125;private void requestCameraPermission() &#123; if (ActivityCompat.shouldShowRequestPermissionRationale(this, Manifest.permission.CAMERA)) &#123; new AlertDialog.Builder(this) .setMessage("需要请求相机访问权限以便进行预览，拍摄") .setPositiveButton("好的", new DialogInterface.OnClickListener() &#123; @Override public void onClick(DialogInterface dialog, int which) &#123; ActivityCompat.requestPermissions(MainActivity.this, new String[]&#123;Manifest.permission.CAMERA&#125;, PERMISSION_REQUEST_CAMERA); &#125; &#125;) .create() .show(); &#125; else &#123; ActivityCompat.requestPermissions(this, new String[]&#123;Manifest.permission.CAMERA&#125;, PERMISSION_REQUEST_CAMERA); &#125;&#125;@Overridepublic void onRequestPermissionsResult(int requestCode, String[] permissions, int[] grantResults) &#123; if (requestCode == PERMISSION_REQUEST_CAMERA) &#123; if (grantResults.length == 1 &amp;&amp; grantResults[0] == PermissionChecker.PERMISSION_GRANTED) &#123; //...又可以做羞羞的事情了 &#125; &#125;&#125; 你该知道的 1. 当系统要求用户授予权限时，用户可以选择指示系统不再要求提供该权限 。这种情况下，无论应用在什么时候使用 requestPermissions() 再次要求该权限，系统都会立即拒绝此请求。系统 会调用您的 onRequestPermissionsResult() 回调方法，并传递 PERMISSION_DENIED ，如果用户再次明确拒绝了您的请求，系统将采用相同方式操作。 2. 要活用 shouldShowRequestPermissionRationale() 方法。这个方法是在用户拒绝过某个权限的请求(但不是禁止后不再询问)后会返回true，然后你可以在这个方法中做一些对该权限的解释，以便用户更了解为什么需要授予该权限。]]></content>
  </entry>
  <entry>
    <title><![CDATA[致敬2017，关于以后]]></title>
    <url>%2F2017%2F12%2F14%2F%E8%87%B4%E6%95%AC2017%EF%BC%8C%E5%85%B3%E4%BA%8E%E4%BB%A5%E5%90%8E%2F</url>
    <content type="text"><![CDATA[由来 今天从人事那里要到了年会拍摄的全部照片，看到自己的照片已经可以弄成一个表情包还是挺意外的。不过更让我意外的是，有些照片我竟然一点记忆片段都没有，为什么，因为喝醉了，喝醉了，喝醉了！！！是的，你没有猜错，写这篇文章只是想告诉自己以后不能胡来，有些事情该做，但是也要有底线。 关于2017 自2016年6月大学毕业以来，这是我工作的第一个完整年头，从16年8月23号从1号店辞职，9月8号来到杭州，到10月17日入职果树以来，已经过去1个多年头，在此经历了很多有意思的事情，遇到了很多有意思的人，也做了人生第一次表白！嗯，是的，第一次，你没听错。虽然讲给朋友听的时候，他们说我很蠢，表白这种事情应该当面说，怎么能够在手机上说呢，哈哈，但是对于我来说，至少是跨出过第一步！嗯，这是一个值得回忆的事情(虽然有时候我确实不太会表达自己内心的想法)。这一个年头，自己的技术虽然没有得到突飞猛进的增长，但是多多少少还是有一定的提高的。 反思 1. 喝酒误事，这句话你已经体验过两次了；一次是在16年的一次公司聚会上，红酒掺杂着啤酒和白酒，导致再次醒来的时候躺在医院的病床上挂着葡萄糖；一次是刚刚过去的的年会，但是这次却没有上次那样的安静，做了很多 不可描述 的事情。虽然在同事看来可能并没有什么，但是我觉得，有些事情能避免发生就应该把它扼杀在萌芽处。俗话说 “事不过三” ，时刻告诫自己，喝酒既伤身，又误事！！！ 2. 熬夜，2017年马上就要过去了，但是这个坏习惯还是一直伴随着自己，每次并不是不想睡觉，而是强行找点事情来做，我也不知道为什么，就是不想那么早的睡着，可能我有点“黑暗恐惧症”(可能吧，哈哈)。在今后的日子里，尽量早点休息，不要熬夜； 3. 充实自己，是的，每次空闲的时间不是拿来玩游戏，就是拿来玩游戏！导致自己不太善于与人交谈；其次导致自己很宅，这也是自己一直是单身的原因之一吧！哈哈哈。所以，2018，努力改变自己，充实自己，多多接触外面的世界，外面的人，找点摆脱单身的生活。 关于博客 时刻记住自己创建这个博客的初衷！生活，不管有意思没意思，只要是值得回味的事情，都可以记录下来；技术，不管简单或是困难，只要是有自己的感悟，就值得分享出来，因为它是你成长的路程。 关于自己 我竟然对自己无话可说，哈哈哈！！！但记住，时刻做好自己，做好自己经手的每一件事情！相信你会成长为一位优秀的人员！]]></content>
  </entry>
  <entry>
    <title><![CDATA[hexo d引发的思考]]></title>
    <url>%2F2017%2F12%2F07%2Fhexo-d%E5%BC%95%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[引发思考的导火索 最近用github pages和hexo搭建了自己的博客，每次本地写好后，需要同步到github上，这需要执行下面一系列的命令123$ hexo clean$ hexo g &amp;&amp; gulp$ hexo d 为了图个方便，于是我写了一个blog.sh的脚本文件，将上面的命令添加在脚本中，每次想要更新博客的时候直接执行脚本文件就可以了。但是令我很烦恼的是每次执行到hexo d的时候就需要输入密码，对于我这个懒癌深入骨髓的人来说是无法容忍的。 问题出在哪里 我也这么问过自己。但是对于被git工具惯坏的我来说，对于git的一些命令行着实不太会玩。我在google上搜索了相关的问题，得到的答案都是不要使用https的方式，使用ssh的方式，然后再将生成的ssh公钥配置在github上就不用每次输入密码了，但实际上我就是这么做的。于是我去询问了八哥，他说你是不是给ssh设置了密码，仔细一想，好像还真是，生成ssh的时候，我还确实设置过密码。于是我重新生成了ssh，然后将公钥更新到github上，再次执行blog.sh脚本文件的时候就没有出现过需要输入密码的情况了。 好奇心驱使 这个简单的问题确实是很快得到了解决，但是好奇心驱使的我还有几个问题需要弄明白。 ssh的密码是否是必要的？ https方式和ssh方式的区别？ ssh的密码是否是有必要的 当我们通过ssh的方式试图建立连接的时候，如果客户端的私钥和服务端的公钥能够匹配上，那么这个客户端才会被授予访问权限。ssh公钥可以确保在没有密码的情况下安全的使用，但是如果你的电脑被黑了，别人就可以不受限制的通过你的电脑和服务端进行通信，所以如果你不觉得麻烦的话，最好还是给ssh设置一个密码吧。 如何生成ssh 在此记录下如何生成ssh密钥，免得每次都得google。1$ ssh-keygen -t rsa -C "你的邮箱" 执行上面的脚本，如果你嫌麻烦就一路回车就好，生成的ssh密钥是没有密码的。这样就保证每次提交git的时候不用输入密码。1$ pbcopy &lt; ~/.ssh/id_rsa.pub 然后通过上面的命令，将ssh的公钥copy出来，最后将其粘贴到github上就可以了。 https方式和ssh方式的区别 这个问题产生是我发现github上clone代码的地方有两种方式，一种是https，一种是ssh。于是我尝试用https的方式clone了代码，然后修改了代码再push到github上，但是发现每次提交代码的时候我都需要输入用户名和密码，而通过ssh的方式我什么都不用管了。 因为使用https的时候，服务器是不知道这个请求由谁发起的，所以得每次输入用户名和密码进行验证，这样服务器才能知道执行push操作的是谁，有没有权限进行push。 而使用ssh方式服务器可以根据私钥和公钥是否匹配来知道你是谁，是否有权限进行push操作。 打破砂锅问到底 那我有没有一种方式是在使用https的时候也不用输入账户名和密码呢？其实也是有方式的，将用户名和密码保存在本地。1$ git config credential.helper store 当我们再提交代码的时候，会将repo的url和用户名密码以 明文 的方式保存在根目录下面的 .git-credentials 文件中，你可以通过下面这种方式打开这个文件。1$ open ~/.git-credentials 那么问题又来了，有没有加密方式去保存这个东西，嗯，于是我又去google了下，找到如下的命令1$ git config --global credential.helper osxkeychain 这会告诉git用 osxkeychain 这种方式进行保存。可以参考这个链接 总结 这确实是一个简单的问题，但是让我明白了很多新东西。怀揣着疑问的态度去看待事情，你会发现很多有趣的东西。同时告诫自己以后要多用命令行，不能被工具惯坏了！！！！！！]]></content>
  </entry>
  <entry>
    <title><![CDATA[留下成长的足迹]]></title>
    <url>%2F2017%2F12%2F06%2F%E7%95%99%E4%B8%8B%E6%88%90%E9%95%BF%E7%9A%84%E8%B6%B3%E8%BF%B9%2F</url>
    <content type="text"><![CDATA[来杭州不知不觉已经过去一年之久，发现自己变得越来越阳(臭)光(不)帅(要)气(脸)了。 一年来，绝大部分的时候都是在撸代码，但是却没有静下心来认真的思考和总结过，以至于有些技术一段时间后就遗忘掉了。很早以前，就想着搭一个属于自己的博客，但是由于各种原因一直没有实际行动过。刚好前段时间，看到挚友自己搭的博客，于是又燃起了这份冲动。 感谢HeZhou的帮助，我不是一个前端开发人员，很多东西都是在这位挚友不辞辛劳的指导下弄好的。 其实搭建这个博客不单单只是想做技(吹)术(牛)上的总结，同时还想着有意思的事情记录下来。若干年后回首，不悔当初的选择。 如果您在阅读文章的过程中觉得有些地方写的不对，或者没有写清楚的，欢迎留下您宝贵的意见，我会认真分析并改正，谢谢！]]></content>
  </entry>
</search>
